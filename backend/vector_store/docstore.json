{"docstore/ref_doc_info": {"c4265ab6-05ed-4395-a546-5f1ee91f4f1a": {"node_ids": ["6f440d16-2431-41f4-877c-ad898350deae"], "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}}, "e48f2d73-47ba-4340-8c98-0d6111cb4385": {"node_ids": ["7003b41e-20e0-42ab-843e-a271be0e924f"], "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}}, "8abedc4c-dac1-4e56-8f97-49c469ebfabc": {"node_ids": ["86e55fac-da13-4cc0-952b-b42d884098c6"], "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}}, "6de2692d-6f77-411b-9d34-4ff57a9f487f": {"node_ids": ["0c2e4a27-aa8c-45f9-99ab-17147d2a04d8"], "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}}, "f0f40196-a659-466c-a28a-b6b64a25be2a": {"node_ids": ["f7f2539c-b3e6-43ce-ac64-3384afb003d4", "2019d7ef-2e72-43a9-902c-84165d1deba7", "e8617c0f-f6e5-4c98-bdf3-27fa71b2618f", "9a342988-b3b6-4b39-8946-5338c3a2ed25", "c417ce99-4fc9-4d11-9ec1-f4164c276b0f", "ebee8422-9689-4833-b9b3-0d286c8f8fe1", "5c4d6d39-20ca-4a8a-b995-5932eb940fb3", "7cf1f99a-fee7-4a5d-a06a-8aad46a7244d", "8c93bffe-d77e-429f-ad1a-420fec555002", "b36ee1e1-e379-42a4-8288-aed0bcd8176e", "279db839-6723-4de9-ab33-4981b1fd019a", "2c15ca1a-6ff8-4c3b-aa9f-64612f7628fb", "6ee032cc-ad33-4562-a00d-58f3706107c9"], "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}}, "ce000b18-e86a-4418-8240-8b7779fb0411": {"node_ids": ["3655e5af-c111-4716-97dd-083e09278ff0", "5787f5e6-7229-4a94-8af4-b8cce7de27a1", "0f4b023d-91fa-42ce-9d83-a43adb2beefb", "4232ecb5-0f02-4c22-905d-17dfa3dab83c", "132dad29-60f0-4e9f-a1a6-16810e9ac804", "bb20f6c6-9134-47fa-bba7-c586c497b183", "6b162950-280a-48c2-b2e9-62de59c18016", "a6bbdbaa-e091-4351-ac23-e38bbbc671fe", "ff5b4e40-acf6-4130-98f5-b0e1a580c413", "a3c125e6-af0b-4556-bac8-f4fcc93a3d65", "8aa6d737-eb01-421e-896c-5969cfb6601b"], "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}}, "080a2c8d-8a7b-4159-8258-e093b9765f96": {"node_ids": ["a01fa895-5f83-46af-9fc3-bbd26f899a45", "ba7060b2-c1c4-48c8-967f-acb5a5e228f5", "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "0b203616-3a2a-4b73-b264-44ae27413c5a", "518bbff6-f700-466e-ae5e-151ca9c45c9a", "f8949761-d7ef-452b-b6d0-0d1f4c571764", "5815e249-b092-433f-be95-f8cbe0b3daab", "b1166cfc-d3a5-4815-acd0-2407106e63f1", "5077d32d-8eb7-4a7e-b626-3736f5ea976e", "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8", "a3c375a8-9dc5-4a67-b9af-514b1f764e59", "2c71a4ba-fb61-4962-bc10-e322980ec04a", "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "0718afa5-46ea-4eda-8c4d-a57fd276fa0f", "5dfdb998-f423-445d-8bfc-a68a110eb2db", "b915ffc9-8d12-45df-9dcd-6789cf6d0126", "e96a93da-42b0-486f-921a-eaefd380df59", "22b58cc1-4f09-4bcd-ae98-ca507709fa3a", "9ab2e3f1-f9ff-4080-915a-0444f695af0d", "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5", "c66f7c50-d609-4182-af3b-864ded6b5b70", "eb5d3a53-a45e-4097-845b-a18ce54f9cec", "c3852fdd-7c7c-4592-bf72-0a655646bec5", "540c70b6-2abc-4c67-9556-0c10b87b742a", "a166db30-c2e0-4ee6-961d-c55174141f73", "2ba5b336-cde8-49ef-a2f5-c655bbf4b151", "ad3be8a6-aac9-451d-8483-8b16fc4671ff", "11edbd09-dceb-4d7a-936d-c5b63e1320cb", "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f", "55f139d1-e089-4158-875f-be649f023996", "edf14a7e-432c-4aab-a664-7a0b40a5e13e", "56dc8265-cdb6-46d9-9ee5-d6c9dc798056", "72e13c48-1857-4244-900f-9e7a1f7e6763", "204c3fb6-154c-4508-9774-68fd1f274e01", "65f85521-e243-4b44-842b-bfebfce7cc2a", "f67a7758-7358-4539-828e-a06cc05e491d", "d7d3a8d2-696e-44de-9b80-a9a04b798420", "72ca9d2d-0c71-4ccb-bfe0-7db20c790544", "57b31622-1557-422e-bbd7-e9e6ea16b735", "1254c435-fbf0-4649-a7d6-f158fc8b1213", "e75d4856-4cdb-4b2f-b492-784e59799624", "1560e316-0278-4e30-b751-ec24ef3deac7", "05c7e783-1c8e-46fa-89b0-e577ecc3ba69", "7e983058-8495-42d0-b7ea-72bbc288957b", "b5edf441-b4e6-4d88-b1ab-b6be5e840ff2", "5d8327e8-0269-48cc-82ba-d0a56cba74d6", "b1972c46-76a6-4b05-ac48-9fa83e86489e", "6d937604-5db8-47cc-a662-2b0aa94f3a68", "fef62cd4-9e15-440e-b235-9327c4f3726d", "cbf9cf49-855f-454b-822f-a0c688c91f33", "ef0843ca-0e39-44c4-8f16-d294697f54e7", "b2aa2894-fbb5-490f-9cc2-b42016adc155", "d8af5298-de5f-499a-9e8b-9df15181ae20", "ff9fe6e1-300e-4238-b879-c00fae44e746", "e8a717d8-1720-4376-956f-aed5bc62ae9c", "887ef03b-8d4d-463f-a102-2c7f116ace6a", "cc5a5b22-3ae4-45ad-9cc9-f870fd194fe8", "5b2a83f0-a1cc-48ed-8191-6eb8d509bd8d", "ef6402f4-f7a3-4388-956f-5735811f42b8", "fef29f8b-d5d5-4f02-9fe9-9e0ac18bddaf", "e896a32e-f3b1-4a3d-9e7e-b44a246a9069", "6838372f-1425-4c57-aa9f-c3950828e2c8", "e2477c6f-c898-452f-966a-287b2097bd04", "f7afb3af-75f4-40bf-9bf6-97c2be306db0", "81a9dff0-d2c8-4e19-b34a-ea54ec89aff4", "1342e88d-46cb-41fb-a360-5c984b7e4b07", "98c4dc26-0fbe-4670-b1b5-d9353b1b19f6", "58e79da7-7039-4fe9-93c8-9a4d2119cd19", "d67f47ce-3ca9-4035-95fd-50d76bc5d27a", "5aefaae7-5438-4d76-aa50-cea746c00f8c", "bb510eef-d5a7-4b09-9fc6-e91155bceef7", "e939d74a-1846-4c73-8f6b-9fb5a08e23d5", "a898fed2-472f-49f3-99ac-8fe6cc78117c", "1793f7cf-183e-4a98-8174-074bc48152bf", "f9b28e53-7b26-4e01-8e4a-45beb13cc969", "fe584ebf-1e0d-4439-980f-d6d31f5bfb96", "cff87716-9c31-4efa-977a-57da71ea9caf", "82aece2a-57f3-40a3-b965-c1a79180d271", "c0daad12-ed76-45a9-b2ce-079e4927cd52", "d88747cc-f81d-4571-94b7-4d32f89e6187", "d1b99fcd-e0b6-4bc4-b874-e503548a1b2a", "134ca2a5-6721-444f-8735-3fcbd4279912", "c067d04b-7966-4862-9d67-714264a9ba14", "c6fc1767-9a71-474d-a95d-eec42bfdd67d", "a74a2647-c490-4d09-abaa-43f16952b578", "61f3dbfa-f6f5-4bfb-bcd4-767a0322452a", "659aa38f-8022-4a40-9cb2-48e544b37d93", "17410a37-262c-4bb4-ac80-3131cf1cefbe", "6fca940a-7f41-4c2d-a5d3-f69b3d1ed098", "6fec6105-9b7d-470c-a6ce-36ceea0d2491", "91c5d9fe-99e9-4d58-99df-b4bb9029619e", "4c8596f3-16b6-4ab3-b9da-f34b710cd6e9", "10d56503-07e6-427f-ab7c-06fe148afc35", "89bb33ac-a79e-44c8-8f66-e0df0fa73c3c", "90b2626b-b05b-4bc3-b0ab-93d0759e23be", "07ed3ee9-c6a3-4b5c-98ca-b3d9014df619", "07b5a9e0-bf5e-4da4-9dcf-ba10e87175fb", "8fe56c3d-194d-4903-a3ac-371944c5bf77", "0b09c21d-c881-40b8-b873-b0e20d7730d9", "9d8d8f57-95d1-49c8-87e8-fe37cca7127e", "df241559-7c56-43f4-b0c2-7b44caf4371b", "2179b319-ddfd-43e5-a6b6-67880b53a055", "0886f1ee-01f2-4054-a49d-a30f2462ed9f", "2c8822af-79f7-435b-bac6-e77a454e835e", "9b243eda-64b3-4ebe-890e-e2cf7da7d4fb", "807a94fc-2c07-4fa5-9b7c-f6a16d40b8e1", "bf2a084c-54e7-4747-8e04-f4827636db70", "fe5f80a4-4584-4cb4-a0f6-c5539025c6bd", "b94fe5c1-8fa1-43b7-9893-b830fcfab3de", "4ac0b80f-b80e-489c-b8de-d9856894aa8c", "f1c38983-8d4e-43fd-ae0c-bf32163cd896", "adf5011f-2293-4bd2-8a97-4b361b4bb6c3", "7999f46f-e821-46e3-b203-d074345239e1", "e7e6f438-3001-43e9-85ce-4c954cc42ad9", "cafb6e9c-8ab2-4de0-97e0-52c4f5f873c3", "1566bd9d-d0bc-4db5-b348-ff0f2b1504cd", "c3ace333-fec2-436f-b687-5f84638c3bf9", "01506521-f1d3-4197-a64f-34c6dbe53b75", "8db70806-7aec-4ea4-9ebe-a055a49be4cc", "5c73fba3-4b69-4c3c-bffd-da0e146648d1", "51fe30d5-c30f-4e90-8ccd-170665aa548b", "d88b291d-e7e2-472e-a1cd-d8528e7b87c4", "1de52656-dd9a-45c2-80ea-b3a7aad79d8f", "70e3e75a-5eef-4a6c-b798-fa0f3ce85172", "dc04308a-3eea-4418-ae92-d30d753a0d0d", "1fe3ce0b-d366-4501-987a-4bfdf3acf64c", "c11f5be5-32c5-44b8-b3aa-869d75bd0a34", "7d49b8f5-ab44-472e-90f5-ac68db726b50", "a50b5997-c789-484c-892b-ca34806fd4b4", "6c2e8972-8180-4956-8458-2f5e2a3ae9fe", "7ca6856e-1e79-4780-9597-b70d983ccc81", "c8470257-32dc-40c2-84af-1ce80a7b2311", "3bf34f78-400a-4357-817e-ccbd99fabf43", "f456e7c2-6ee0-4349-a699-3d591248fe77", "69f22d16-cb3b-4044-833d-88b59cc6c693", "1b42ec54-8165-4702-bbca-52099bdf3c4f", "ef7c8c26-2e41-4bb4-a26e-50570b057687", "0e246a18-28de-48c0-a966-d09a06822fd5", "fc174872-b179-44c1-8143-c7e59c96be01", "f184f6e9-9f46-4a2d-a412-9b8e398f2b00", "dacb713e-5773-4425-bb40-0accaaa094be", "1cb9fe24-627d-40fa-8b2c-4d5734d2eee0", "4980577f-97d2-41ef-a27a-761f41225875", "89ca1f59-64b8-4a3f-a0bd-1dc4c18b9c51", "7412b6d1-756e-41ee-91d3-0f62943e3d09", "ac94e726-9fc9-4598-866c-be5eeb8a19e8", "533b5dd0-38da-4d13-9304-7938b016c0da", "e29b52c9-9060-40ab-adb4-31d7d30491a9", "10cb0e8f-2c50-402c-b7b4-0a46cd655ba2", "5e7c3a27-ab1d-4162-8c57-410c678dc6de", "f5128987-775b-480e-a9b5-7f162afd1132", "7bbd5992-de2a-4648-8c84-c9ee77eeee49", "dc34b97a-ab03-4082-8cff-a6445520e426", "e27f06d3-38b6-4362-bd97-8436a55a2414", "5ae7250c-3613-4177-bd2e-498eb743de05", "b52683be-a1cd-40d4-861e-fd619d8b79f5", "f79e69c1-9bac-4083-92a2-1c0e6bf0ee3f", "4442f3a1-3dfb-449c-a15d-852e24414c41", "02668298-18e8-44bb-93d7-19da4b9b3790", "55b09120-0922-4df4-ad14-50ae22a2f0e2", "26e4455f-0d4e-488e-a544-9f5625380731", "509b1e58-b476-4a27-9ded-777abf739514", "33348eb5-0677-4387-b789-c9ff60480007", "ff062373-d901-443d-b8e2-7171d9d6fab4", "3771e800-f5e0-468b-bf9e-66c996acd849", "337584ff-0a73-48fb-98ef-48c0246e2518", "2f780ae3-b5b8-4fab-ba53-5bc0e811f981", "f77e394c-7c29-4b63-81dc-af15bd0e66f3", "c4b2c7ef-1930-4255-acf6-bc1f652dafdc", "13883121-5801-4bbc-84bf-5d235841e0fa", "6fc6cc15-ff76-46c1-bbd1-3e9458afb757", "ac8c847f-de9b-4eab-a8f0-66c4cd60c4e3", "7877ca51-85bd-40d2-96f7-2e6f9f2383b1", "46ab98fc-8d19-47df-9741-ecb36253fde1", "6bda768b-04d6-42e0-a0e0-61b6c2846b7a", "ae37413a-987a-45f1-ac83-85e86906dc24", "3cec132b-2354-471e-b143-28f66c24ffda", "784e4f95-3d47-4c94-8bcb-b3ffc2b20b99", "78b4572e-8d75-486c-b0cc-d001f906f947", "9a3e3c8f-fbba-4417-8877-018258745278", "ab98e195-eb5e-4ed6-9a70-d344757e63bf", "d85a4458-1a16-4407-ade7-3c2b5aa33bdb", "7952f00d-bbc1-4a84-9017-c477ea9100bc", "e4ed83f7-38fa-4f45-9736-8eca5668e997", "b1d619cb-53e3-46f0-b0ad-a4372afa43d0", "8916e982-5a90-4d15-969c-65e7f0e0a16c", "0ae4b470-79c3-4f69-bdac-bd5915ee5223", "d638a830-8ac5-4174-82a7-be5eaf341ee4", "8605bedc-51ff-4e99-b9f0-86888e23332d", "f05a8110-c1e8-44c1-8148-cf387813423c", "e426f93a-2cdd-4643-a68e-aed3ac84197f", "39f03018-d143-4b90-96e0-1c72f0a252fd", "d31452c3-fad9-4265-a515-982d866fe71f", "c8a98fbf-eb5b-49cf-ae46-79e8fa49ad83", "8275affe-d885-49c8-8008-fa2f9a85e949", "99e02a18-40e1-41b6-96cf-c723ea00d9eb", "f5130f5e-b5f9-4e70-b3f0-9f2013d4e2af", "2f705498-ca27-4f7c-9fd5-5f770ca72e64", "e66b0dee-d1fd-4330-9d19-def6628417b8", "73c3b4ce-76eb-412d-a7a7-a138434ac2eb", "46c2615c-9ce0-4efa-96fa-3678f0edf050", "728835ac-2a2d-4994-87c0-9468e82f4dba", "139e6c95-59e4-4b78-9e3e-9549c1d0722b", "fbe01bbb-ff31-4480-84cf-3dae7be082dd", "c30e5b3e-2ae3-4737-8921-3f3ea68877f1", "97678d71-ea37-4e77-bb46-cdcf6b3bef75", "4901693c-df30-4c8c-ab43-417154ba1e05", "a8b484a1-2343-493a-9b2c-50c2ebb5ec4b", "0f5b974e-f657-4360-8ea7-6bd11d43c8e6", "38717897-3269-43f2-973e-540622079d25", "e6e7ca7d-bacf-44d9-9ca9-5923dffdfe93", "0d6eb3be-a4ef-43dc-ba46-72e04779a732", "22abeffe-1304-407e-beb1-44c3a9fd4fa7", "20c5ad66-47b2-4351-a2d0-b2c4042f2ff5", "78bc3360-41e9-4d3e-a816-7e5d7914eabf", "0d804174-3b08-4fd1-ac1d-eac32cc650f9", "2a85ef71-2638-4918-9650-1ab5cdff23c8", "8b85f05c-56eb-43f6-8072-33bc9783a316", "558be939-068f-4390-945a-28cef910cbff", "ffda4781-e364-49ad-9903-36dec832e44e", "b9741048-0bcf-49fa-b8ee-ce7f6cea6a81", "810c43b0-cfca-4998-8584-bb70ee120696", "ff63f380-3595-4180-b636-5a380e924651", "47e1d198-bb83-44b4-b265-a42a3583f23f", "13814057-a813-48ef-88a5-4ac5616376c8", "18abf32b-3d18-4271-9924-c50acf8154a6", "7d8532ed-9156-4344-8487-a8afb326ea52", "ebafaaf0-1b03-42af-b797-ac464052d90d", "e237093e-779e-4c5b-9b17-93a82b6575dd", "9cddb9dd-5b78-4d09-9172-3fa43c4dcd17", "d3182eb9-b7ca-4419-aed0-c1ed4b717f6d", "b655faac-56fc-4430-99cc-da0a5388efc8"], "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}}, "b75d0f2c-5cb0-44a5-838f-13f96df62c58": {"node_ids": ["db249a26-87b5-4afb-a1b8-a2e030b78e56", "cc630bfb-bac1-40b2-87e0-7d7500de63c5", "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "88e12252-5fec-46c2-a2ae-6fc241f89a76", "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de", "bb7534db-e25f-428a-8778-6cb5b6f5ad95", "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "0b48d73f-7b7d-48ee-b07c-c7803a538edd", "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd", "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5", "2855e277-9266-4da9-a41b-62970f13924a", "8401cdeb-6662-48aa-beae-b4bb5f06a885", "14effdc0-fe79-40b8-ae47-1d97a86b2018", "9322dd63-adad-4546-91dc-b82fb1ea8fef", "76a288f9-53f4-4e84-8d97-b368d41bd698", "a513b767-e451-410c-b79a-380601bc5888", "9eaef3ff-f04f-444b-bb7f-84ada902b046", "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc", "70a88b27-013f-479f-b346-c5064d447678", "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b", "73b29e23-6efb-440b-858d-7846dd96e398", "d82c7612-c14c-464f-8df9-eb86619797d9", "627ef3fc-ccd5-4dc6-b333-7648af9b7bc1", "b4ea218f-14e7-45ab-97c2-840461bf59e8", "1acd86c1-984e-4c83-ac55-164400eade2b", "32b0ab75-2189-4d14-9ca8-12078565de81", "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "6366440f-4e3c-497d-972e-42a02ac199a7", "251a9d11-5ba7-4233-bf7a-46e9b4bd0325", "e98eac31-9c3c-4ebe-8f13-59e55f710d10", "fdb2e7f0-24e9-407c-8cf9-52243751ad4e", "2db9fece-00a1-4a6f-aaae-6a4933998147", "66256c0e-8c94-488e-bf00-1da903703df0", "e90dcff2-5517-43c2-a6a1-4ba1d21a4656", "5693045b-afdf-4a0e-9505-33be4be69a3c", "44085962-76ba-48da-90ee-697d9e7fc54a", "2673e9dd-96d1-42f5-903c-bf289afc91a0", "36f1afb1-b558-4531-9cdc-616558dcfaee", "65eb96c0-affd-4497-9c15-0272053042e2", "a1ca29c1-9e8d-484b-9415-dc3107357580", "e4dc984c-e3f2-4923-8645-5fcb9ab3e78e", "017ffcb0-64fd-4717-bfb4-dd0029d24a77", "a0c428d4-9bdb-4837-84c4-0e4d1cc8c134", "d938c1e9-40cf-4541-8f86-471f4f006481", "5da3506c-fac9-4eb3-8288-0998c9026a57", "1a93036f-9a6b-49b8-8e4e-85375e507a10", "f19243eb-b1ce-4903-b5a3-284412d9e872", "e7cfb727-258a-4e21-a9c5-0e0ae4195c18", "18d5406c-5efd-4928-845a-25db3d586722", "257f60ef-b0ad-4fbc-b605-6d181656a11a", "f4e57e09-98a3-45cf-9ebf-1c9897d4370b", "55086b99-4947-4d9e-abb2-c96ba69ff0dd", "ebf6015f-27fd-481d-aa92-de46f7f861e3", "267f4c36-c2e6-42f9-8915-8ea6c18fed83", "93c2b70a-135f-496e-b14e-45caa053bf73", "67e94527-9263-4837-b131-a4799f7e51e9", "62923145-ce3a-40a8-b0c4-c499785f29a6", "00cd7f5b-7518-4ade-81a2-63ab6f97aabc", "8038baa3-f888-4c86-9e5d-fb963c4ce5fd", "61c8cea0-fafd-48a7-874d-f597795d15a8", "d5781ced-bcdf-46e5-8e63-877991d14207", "8af3a283-7382-4582-b416-6d0cef2edfa6", "51918c55-025f-4906-bfb0-b0bfe491171c", "870c0c78-3dc0-438e-a7c3-01243e73e58a", "d8d747b8-d81a-419d-8083-7f8523d53feb", "a8f1e88e-ff95-496f-81d6-17e468412c91", "2b0058fc-1a45-474e-9544-ec4e9faae58c", "96bdd5d3-a773-482d-a30d-06d7d77395aa", "ef94c2bc-3eb7-4146-85bc-5713adff1302", "c05bca4c-5716-479f-9d85-6b9593fd13d8", "d3739567-9d85-4d3e-b562-9b18a0fe7718", "81b11a8d-9cd6-4b83-9dfd-d06fb630e5f3", "47a07172-514d-4d6d-8d70-98c529ca03e7", "49f949a8-0735-49af-870e-1ffde8de81c9", "eedc9a90-b5d5-4912-9092-9d2490f79c24", "7ab2825a-5f7c-4550-afe8-901081e154f6", "62c5299b-1bf0-4bf1-8c51-116c95825420", "164847cd-f3fe-4ff4-a218-4c3272542352", "7171672f-3d76-4671-b19a-0d002c808b11", "07364ea6-e560-49e5-8f36-3d64a72d9f38", "36cbc85e-6884-415e-8239-c4ad7ac472e1", "04c2eed4-7b4c-46e4-a197-0a22bf5357eb", "71aa0155-3650-424b-80d3-d39b8c47f0f5", "e66d8f48-4744-4c7c-af37-f336f2106dc0", "271872ae-f2e5-43c7-9ede-e4a01d149ada", "3d234c0b-4bc1-4565-8944-328cf3c2c90e", "67614e3e-03e1-4acb-adaf-edb0c6b8f21b", "217fb68d-c222-405e-9cc5-530acc1d60cb", "4b6e2f0c-cd70-401d-9c38-e4dd4a510006", "03872e73-1622-4624-9157-0cf489f0e13d", "cd528d2d-349b-4636-951e-7c63480b6a20", "a44a846e-1368-4dcf-b24e-cb249e06d290", "fef7d2f7-47b0-4201-b0cd-bc66f8b983d4", "f21d4276-a6c9-48b9-8169-ea1da2252944", "10beae5b-b1a9-488e-a38e-d20cf0f57c3a", "0f0324ce-b500-483f-8127-4ab86cd0b517", "b0412f56-acb4-40b4-bb73-3eac0d4655fd", "0d008531-2a6c-4491-96b9-f8230675d5b3", "d33b4179-66f9-4811-91c5-b2a7efd792ab", "9d1a25ea-00c8-4605-9954-1c1323e22e4b", "c0a2b1ba-261c-4c16-b2ec-c27f47dd37d8", "fc34b30e-072c-4512-8b77-e266c67ffeb4", "1f3039bb-27da-4e34-b4e7-3b14bd2483e1", "4a409ce0-60b0-46a7-aac9-e0069a1d1a45", "7ba4d891-959f-449e-8179-f1521d58278b", "464a52ee-13cc-4b31-a684-7d9d56b077f4", "f268ff23-4ef0-40d4-8930-334329d426ff", "5cf8fd08-0342-48d7-be27-4435c1996190", "50efc748-fd69-4dc4-b5e9-67712fc6c1a1", "3065ba83-65ce-469a-9bc9-569c22f7502b", "3cb07a26-fdd1-4774-b0f8-29aa21e8fb76", "2d95dc7b-2b64-4bb0-b581-6f0bb18ae0bd", "3e23d28c-240e-4d79-8cd6-4781172dfa54", "7c440d64-bcd6-4811-9a1f-f70a29f65c0d", "35d04f89-ee46-445b-8cc5-daf903360930", "1cff163b-f8d9-49bf-8ec0-0c03e7994dd1", "15199290-499d-482f-be5d-8846ec3f1177", "84a1c9a3-0caa-42e1-961d-1d0e470a190c", "7d225255-9701-49d2-ba99-d2880e6fe9af", "bcca71aa-7fe8-4348-bb1e-dfcb91db8b11", "73a668b8-64b4-41bc-b4a8-add81af6742e", "997170d1-de96-48cf-872a-a344552bf671", "e1ad7bd8-097a-4a7a-b6e4-e2376ae31287", "a3a3f326-5eda-4989-a0db-fa043196b4b1", "0c9ac0ae-2d00-411b-a304-afe28d16351c", "0be360c5-d140-4c86-9e9e-a91262c29e37", "c6276074-770d-4609-983f-48d70e22f1a2", "8496b7a0-8a46-41d8-9b48-77e0ff368d7d", "bd6ba406-0e33-4804-ac5b-d803b83b7056", "5aa8a48e-ae16-45bd-a590-70eac1aff32a", "a0058833-5ffc-4def-a6a3-10f5b4b8e3d9", "b1646404-4baa-4590-8141-d7b263da37c3", "d87ab588-a219-4943-b295-6d08dd265695", "d63182ae-cbbc-48bc-bee4-84141e90a007", "b69109bd-c8b2-4edd-b897-8e87f4471990", "887cb2e6-de01-4bb8-bc57-4d41ac5b0ba0", "3e470344-905e-404c-be6f-00abe4d2b2b6", "e465497f-d5ce-4507-97c9-54f6f97de1aa", "55ce4f5c-a49c-4a26-a4bc-8c8b6b707819", "f1478900-5b0a-4bd4-9d85-abc424f26e07", "b42e1405-b66a-479b-a50d-5bea7c67af17", "a1ea30e4-5351-450b-b44e-73c76ffd7ebe", "4187a558-80a6-4b38-816b-4cac854fa588", "7023420d-97a2-4e64-a5bf-9f8439a64480", "17a841ee-8d41-49e6-83d7-7805e0dd04f0", "0d7eef55-7570-4adf-93e0-3d06c2e67332", "2f943d51-eb6d-4848-8089-c0a0e28601fa", "9acf4a38-5d34-4bca-a295-89c9a9090a4a", "11773835-8293-4686-9553-d6da84a99592", "30797ee6-2932-4473-80c3-2e8d1208e985", "0b57821d-7219-42b0-83c2-ff0325a4c990", "4ca57500-07b5-4caf-9a39-3f64fa046102", "c73260f9-0170-4dce-acbb-736406103253", "b666278d-7080-4b1b-9cd7-012832fb4da6", "d400e284-1968-4a56-b582-1a7ea915454b", "99e6e0f4-ae35-4739-b72a-d33e07a14980", "5531d320-981a-45f3-8f77-66230ff82fa8", "3e836fb6-91d6-42df-b944-3da794785511", "8dad0787-2ae6-4bef-9005-66adcdc84994", "8e804274-1d30-47bb-b4a5-8b0a89e03a62", "a771935f-a85c-494c-97d3-a661f287022e", "6156d81a-4ba3-4105-8b9f-518ef11f9afa", "297b007f-5406-4c7f-8487-a28c962f0327", "8a744631-c44b-46a3-aac3-3eccf8b259f6", "0195271e-8992-41c3-a61b-4c63fbd03001", "ea125a9d-c4e2-45af-a637-1a75ee96d2ca", "33696f3a-b4ce-48c1-ae8e-080dfce4e3cf", "3e635e3b-99e8-4feb-b52b-b18aba01f8b3", "9154054b-d97a-4a29-8150-47cc4cf374ab", "dd2a5a00-5308-443c-867b-b9546f0db6e4", "7f8e0652-c27c-4561-8ab8-b898f10adaf4", "1c2e12c4-c6be-422f-b12c-46b753d6a1b0", "5b0449d7-0e10-45af-87da-d7fe1a5218cf", "4b4da0ab-e078-4eaa-bcf5-fe5eeb4fbf83", "480ca554-3a44-4f15-8e9a-ce28ddce9817", "1cf8f0db-ab6f-47cd-9406-0dd2f3071d2d"], "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}}}, "docstore/data": {"6f440d16-2431-41f4-877c-ad898350deae": {"__data__": {"id_": "6f440d16-2431-41f4-877c-ad898350deae", "embedding": null, "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c4265ab6-05ed-4395-a546-5f1ee91f4f1a", "node_type": "4", "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}, "hash": "08d69440988ca63ee177f2e7a57e2249476e57361123ce8ee608bc4e5df26f26", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 6, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7003b41e-20e0-42ab-843e-a271be0e924f": {"__data__": {"id_": "7003b41e-20e0-42ab-843e-a271be0e924f", "embedding": null, "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e48f2d73-47ba-4340-8c98-0d6111cb4385", "node_type": "4", "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}, "hash": "08d69440988ca63ee177f2e7a57e2249476e57361123ce8ee608bc4e5df26f26", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 6, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "86e55fac-da13-4cc0-952b-b42d884098c6": {"__data__": {"id_": "86e55fac-da13-4cc0-952b-b42d884098c6", "embedding": null, "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8abedc4c-dac1-4e56-8f97-49c469ebfabc", "node_type": "4", "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}, "hash": "08d69440988ca63ee177f2e7a57e2249476e57361123ce8ee608bc4e5df26f26", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 6, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0c2e4a27-aa8c-45f9-99ab-17147d2a04d8": {"__data__": {"id_": "0c2e4a27-aa8c-45f9-99ab-17147d2a04d8", "embedding": null, "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6de2692d-6f77-411b-9d34-4ff57a9f487f", "node_type": "4", "metadata": {"arxiv_id": "", "title": "", "authors": [], "published_date": "", "categories": [], "pdf_url": "", "browser_url": "", "source": "arxiv"}, "hash": "08d69440988ca63ee177f2e7a57e2249476e57361123ce8ee608bc4e5df26f26", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 6, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f7f2539c-b3e6-43ce-ac64-3384afb003d4": {"__data__": {"id_": "f7f2539c-b3e6-43ce-ac64-3384afb003d4", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2019d7ef-2e72-43a9-902c-84165d1deba7", "node_type": "1", "metadata": {}, "hash": "d38d64412e4e7bba5df45d97d0b56a5cbd78280bdfbe287523471c05ba05ba8f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts\n\nAuthors: Sang-Woo Lee, Sohee Yang, Donghyun Kwak, Noah Y. Siegel\n\nAbstract: Many recent papers have studied the development of superforecaster-level\nevent forecasting LLMs. While methodological problems with early studies cast\ndoubt on the use of LLMs for event forecasting, recent studies with improved\nevaluation methods have shown that state-of-the-art LLMs are gradually reaching\nsuperforecaster-level performance, and reinforcement learning has also been\nreported to improve future forecasting. Additionally, the unprecedented success\nof recent reasoning models and Deep Research-style models suggests that\ntechnology capable of greatly improving forecasting performance has been\ndeveloped. Therefore, based on these positive recent trends, we argue that the\ntime is ripe for research on large-scale training of superforecaster-level\nevent forecasting LLMs. We discuss two key research directions: training\nmethods and data acquisition. For training, we first introduce three\ndifficulties of LLM-based event forecasting training: noisiness-sparsity,\nknowledge cut-off, an\n\nFull Text: Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts Sang-Woo Lee\u2217sangwoolee.cs@gmail.com Independent Sohee Yang\u2020soheeyang@google.com Google Deepmind Donghyun Kwak donghyun.kwak@navercorp.com NAVER Cloud Noah Y. Siegel\u2020siegeln@google.com Google Deepmind Abstract Many recent papers have studied the development of superforecaster-level event forecasting LLMs. While methodological problems with early studies cast doubt on the use of LLMs for event forecasting, recent studies with improved evaluation methods have shown that state-of- the-art LLMs are gradually reaching superforecaster-level performance, and reinforcement learning has also been reported to improve future forecasting. Additionally, the unprecedented success of recent reasoning models and Deep Research-style models suggests that technology capable of greatly improving forecasting performance has been developed. Therefore, based on these positive recent trends, we argue that the time is ripe for research on large-scale training of superforecaster-level event forecasting LLMs. We discuss two key research directions: training methods and data acquisition. For training, we first introduce three difficulties of LLM-based event forecasting training: noisiness-sparsity, knowledge cut-off, and simple reward structure problems. Then, we present related ideas to mitigate these problems: hypothetical event Bayesian networks, utilizing poorly-recalled and counterfactual events, and auxiliary reward signals. For data, we propose aggressive use of market, public, and crawling datasets to enable large-scale training and evaluation. Finally, we explain how these technical advances could enable AI to provide predictive intelligence to society in broader areas. This position paper presents promising specific paths and considerations for getting closer to superforecaster-level AI technology, aiming to call for researchers\u2019 interest in these directions. 1 Introduction Future event forecasting is a task of predicting whether specific events will happen in the future, or what the probability of occurrence is, based on information up to a certain point in time (Jin et al., 2021; Zou et al., 2022; Halawi et al., 2024). For example, consider the question: \u201cToday is December 31st, 2023. Will SpaceX successfully complete an orbital flight\u2014reaching space and circling the Earth\u2014before June 2024?\u201d When solving this task with Large Language Models (LLMs), the widely used approach is Retrieve-Augmented Generation (RAG) (Lewis et al., 2020), whereby relevant news articles and related information are first retrieved, followed by reasoning processes that derive the final answer (Halawi et al., 2024). An important goal \u2217corresponding author \u2020Participated only in an advisory capacity.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4047, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2019d7ef-2e72-43a9-902c-84165d1deba7": {"__data__": {"id_": "2019d7ef-2e72-43a9-902c-84165d1deba7", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f7f2539c-b3e6-43ce-ac64-3384afb003d4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "ad9c95b2bb7e2b04b4508c3eeef35fd3f2e0f3999b4a304fdaa18a364474386b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e8617c0f-f6e5-4c98-bdf3-27fa71b2618f", "node_type": "1", "metadata": {}, "hash": "1064bd4a2947209a97a689928ee5eeddb3f8c76f902dd6c7809b9b40e409eb7d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1v1 [cs.LG] 25 Jul 2025in the future event forecasting field is to make LLMs perform as well as top-level human forecasting experts or collective intelligence of general experts, that is, to make models reach superforecaster-level (Tetlock and Gardner, 2016; Karger et al., 2025; Liptay, 2024a). Since ChatGPT was released (OpenAI, 2022), numerous studies have evaluated LLMs\u2019 event forecasting capabilities and compared them with human performance (Schoenegger et al., 2024; Hsieh et al., 2024). Initially, optimistic reports were shared that LLMs showed performance approaching superforecaster-level (Phan et al., 2024). However, subsequent analyses identified methodological issues including insufficient statistical significance, information leakage from data preceding the knowledge cut-off date, and contamination from post-resolution documents in search results, leading to criticism that LLMs\u2019 abilities were overestimated (Lopez-Lira et al., 2025; Bosse et al., 2024). These criticisms resulted in skepticism within the event forecasting community (Paleka et al., 2025a; Matthews, 2025). However, we argue that recent studies provide positive signals for event forecasting. A recent study using more rigorous evaluation methods (Karger et al., 2025) reports that LLM performance in event forecasting is steadily improving with generational advances, and they are getting closer to superforecaster-level. Additionally, recent reasoning models like OpenAI o1 and o3 (OpenAI, 2024; 2025a) have shown improved performance compared to previous models (Hickman, 2025), and performance improvements through reinforcement learning (RL) have also been reported (Turtel et al., 2025a;b). Furthermore, the unprecedented success of reasoning model with tool-use like OpenAI\u2019s and Gemini\u2019s Deep Research (Citron, 2024; OpenAI, 2025b; Anthropic, 2025) suggests that technology capable of greatly improving forecasting performance has been developed. Based on these recent positive trends, we argue that conditions are now favorable for research on large-scale training of event forecasting LLMs to approach superforecaster-level performance. This paper presents two key research directions for this purpose: training methodology (Section 4) and large-scale data acquisition (Section 5). For training methodology, we first introduce three unique difficulties in LLM-based event forecasting training. First is the noisiness and sparsity problem, which is the difficulty in learning due to inherent uncertainty in event forecasting outcomes and the sparsity of similar events. Second is the knowledge cut-off problem, where it is difficult to train or evaluate event forecasting questions about knowledge that LLMs already know internally, greatly limiting usable training data. Third is the simple reward structure problem, where models can obtain rewards more easily than in other RL tasks without developing proper reasoning capabilities, hindering actual prediction ability improvement. To mitigate these problems, we present several solutions. We provide theoretical grounds for various training label assignment strategies through hypothetical event Bayesian network modeling, introduce methods of utilizing poorly-recalled data and generating counterfactual events to tackle the knowledge cut-off problem, and discuss ways to solve the simple reward structure problem through auxiliary reward signals and subquestions. For large-scale data acquisition, we point out that previous research mainly relied on prediction markets and propose aggressive use of three data categories: (1) market dataset - data available from prediction markets like Polymarket and Metaculus, (2) public dataset - structured data available from public databases like GDP and economic indicators, and (3) crawling dataset - unstructured data collected and processed from the web like news. Using these diverse data sources will enable large-scale training and fast evaluation cycles, promoting model performance improvement and development of generalized event forecasting capabilities. Finally, we discuss the broad impacts these technical advances could have on society (Section 6). We examine promising applications, including expanding the scope of AI forecasting, AI-assisted trading systems, future simulation capabilities, and integrating probabilistic reasoning capabilities into general AI agents and AI scientists.", "mimetype": "text/plain", "start_char_idx": 4048, "end_char_idx": 8446, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e8617c0f-f6e5-4c98-bdf3-27fa71b2618f": {"__data__": {"id_": "e8617c0f-f6e5-4c98-bdf3-27fa71b2618f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2019d7ef-2e72-43a9-902c-84165d1deba7", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "27d53e8003fd8011531982961e84ca24e6fdc9cb16d02f8b551ff8c7f879154a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9a342988-b3b6-4b39-8946-5338c3a2ed25", "node_type": "1", "metadata": {}, "hash": "3ab78247f6d641ac2fed2bc5bc7c9b03290ede5564e402270ff89b6f96751303", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We also analyze key challenges, including assessing prediction confidence, user interface design, self-fulfilling prediction effects, and vulnerability to malicious attacks. This position paper provides a comprehensive review of event forecasting with LLMs, arguing that recent advances in LLM capabilities have created favorable conditions for large-scale training toward superforecaster- level AI systems. We identify and formalize the unique training challenges specific to event forecasting, propose methodological solutions to address these challenges, and develop strategies for performance enhancement 2Term Example Definition Question Today is Dec 12, 2023. Will SpaceX successfully launch and return a space- craft from Earth orbit by 2024 June?The question which asks about whether a specific event will happen by a certain time. Question date Dec 12, 2023 The date that the question is asked. LLM must utilize the knowledge before this date to answer the question. Therefore, this must be the \u201cevent knowledge cut-off date\u201d for the LLM. Resolution date Mar 14, 2024 The date that the outcome of the event is determined. In other words, the date that the outcome is resolved. Outcome Yes The outcome of the event known and finalized from the resolution date. It remains unknown before the resolution date, leaving the outcome unresolved. LLM knowledge cut-off dateNov 30, 2023 The latest date of the knowledge an LLM is trained on. Table 1: Examples and explanations of major terms. The event example is referenced from (Polymarket, 2023). through large-scale dataset expansion. In addition, we conduct a systematic analysis of the societal implications of event forecasting LLMs, examining both their potential for widespread adoption and associated risks. 2 Background This section provides background on event forecasting using established terminology in the field (Table 1). 2.1 Prediction market A prediction market is a platform where users bet on whether specific events will occur. Each market within prediction market platforms corresponds to a specific event and provides market predictions for outcomes at different time periods for that event (Pratt et al., 2024). Market predictions represent the aggregated probability estimates from participants regarding whether a specific event will occur before resolution. Representative prediction markets include Polymarket, Metaculus, and Manifold Markets. Polymarket uses real money, whereas Metaculus and Manifold Markets use virtual currency. These platforms democratize future knowledge by providing reliable probability estimates for significant global events through various mechanisms (Williams, 2025a; Chen, 2022). For example, Polymarket achieved recognition for delivering more accurate predictions for the 2024 U.S. presidential election compared to expert analysts and political forecasting platforms (Jones, 2024). Prediction markets play a significant role in the field of event forecasting AI. They are widely used as sources of both training and evaluation data for developing such systems. Moreover, matching the forecasting performance of prediction markets and scaling it to a wider range of prediction problems is one of the key motivations for event forecasting AI research. 2.2 Superforecaster Superforecaster (Tetlock and Gardner, 2016) is a term referring to top forecasters who have exceptional talent in prediction compared to the general public. The criteria for superforecaster-level vary slightly across different literature and experimental settings, but recent studies define it as the prediction level of collective intelligence of forecasting experts (Karger et al., 2025; Liptay, 2024a). Forecasting experts refer to professionals hired as forecasters, while collective intelligence represents the aggregated predictions from multiple experts. 3Karger et al. (2025) asked the general public and forecasting experts a total of 200 questions, with randomly selected 20 questions each, and used their combined answers for comparison with models. Metaculus AI Benchmarking (Liptay, 2024a; Hickman, 2025) hosted by Metaculus is also an active challenge in this field. In this challenge, the performance of AI systems is compared using approximately 300 questions.", "mimetype": "text/plain", "start_char_idx": 8447, "end_char_idx": 12705, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9a342988-b3b6-4b39-8946-5338c3a2ed25": {"__data__": {"id_": "9a342988-b3b6-4b39-8946-5338c3a2ed25", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e8617c0f-f6e5-4c98-bdf3-27fa71b2618f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "1d3c3086dea953f87ab6c82accbfe7343e3d40ef8848616fe24e249adbc439f2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c417ce99-4fc9-4d11-9ec1-f4164c276b0f", "node_type": "1", "metadata": {}, "hash": "8c5981f2ebe7f06f88827cd0af7a479c7b9677789b70cbee574d625f2885e738", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In this challenge, the performance of AI systems is compared using approximately 300 questions. Furthermore, the top-performing AI systems from previous competitions are combined into an ensemble, which is then evaluated against groups of approximately 10 expert forecasters using around 100 questions to assess the performance gap. This definition clarifies that, contrary to the common first impression of the term \u201csuperforecaster,\u201d superforecaster-level AI does not mean a prophet who predicts everything perfectly. Superforecaster-level simply means the top level of human expert forecasters or the collective intelligence level of expert forecasters. 2.3 Benchmark Static benchmark ForecastQA (Jin et al., 2021), AutoCastQA (Zou et al., 2022), and AutoCast++ (Yan et al., 2024) are early major event forecasting benchmark studies. These benchmarks can be classified as static benchmarks because they consist of data from specific periods in the past that have already been resolved (Ye et al., 2024). The main challenge of static benchmarks is that data contamination can easily occur due to the nature of future prediction. If an LLM is developed in 2024 but the evaluation data contains questions about events that occurred in 2023, it cannot be used for evaluation because it may already be contaminated through training. Therefore, static benchmarks soon become outdated and cannot be used to evaluate the latest LLMs. Dynamic benchmark In contrast to static benchmarks, dynamic benchmarks continuously update their question sets and resolution information from the latest databases. Here, models answer unresolved questions posted in the database at specific times, and when these questions are resolved after a certain period, the model receives a score based on the resolution outcome. Since previous static benchmarks created reliability issues related to contamination, dynamic benchmarks are considered a major advancement. Recently, dynamic benchmarks and related challenges continue to be shared (Karger et al., 2025; Paleka et al., 2025b; Liptay, 2024a). Recent dynamic benchmark studies use market data from prediction markets as a key source for performance evaluation. Metric Benchmarks compare the error between the model\u2019s probability predictions and the actual resolved results using various metrics. The Brier score is a commonly used metric. The Brier score is defined as (f\u2212o)2, wheref\u2208[0,1]is the probabilistic forecast and o\u2208{0,1}is the outcome after the event is resolved. Lower Brier scores indicate better performance, and a uniform prediction of 50% creates a Brier score of 0.25 (random baseline). Another metric is the logarithm score, defined as ologf+(1\u2212o)log(1\u2212f). The logarithm score is more sensitive to extreme errors in probability estimates. Expected Calibration Error (ECE) is a metric that measures whether the actual outcome resolution probability of questions the model predicted with probability pis close top. Generally, specific interval bins (e.g., 5%) are set, and the absolute difference between the actual outcome resolution probabilities for prediction data within that range is used as the average metric. The concurrent position paper by Paleka et al. (2025a) addresses the difficulties in event forecasting evaluation and provides detailed explanations of these metrics along with comprehensive comparisons of their limitations. 2.4 Inference Information retrieval Information retrieval plays an important role in event forecasting systems (Hsieh et al., 2024). The study by Halawi et al. (2024) provides foundational research for current event forecasting and information retrieval pipeline design. In this study, they used an appropriate LLM-RAG-based pipeline to significantly improve prediction performance compared to cases without search. First, the LLM generates search queries related to the question, which are then used to conduct news searches with the search period restricted to information available before the question date. Then, the retrieved documents are reranked. Finally, answers are generated based on the organized documents.", "mimetype": "text/plain", "start_char_idx": 12610, "end_char_idx": 16717, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c417ce99-4fc9-4d11-9ec1-f4164c276b0f": {"__data__": {"id_": "c417ce99-4fc9-4d11-9ec1-f4164c276b0f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9a342988-b3b6-4b39-8946-5338c3a2ed25", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "3d70c586e6a719207e545fddacc46179eec6a296409def5cb99cf44c08f36d94", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ebee8422-9689-4833-b9b3-0d286c8f8fe1", "node_type": "1", "metadata": {}, "hash": "41b121a16de5b4ca4e335b1d9845900dbc68c5e920274623f6c41f59762d5ec9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Finally, answers are generated based on the organized documents. Additionally, Metaculus (Hickman, 2025) 4now provides an integrated information retrieval system with commercial LLM APIs to support forecasting research and practice.1 In practice, ensuring temporal integrity in document retrieval remains a significant challenge in event forecasting systems, particularly when the question date differs from the current time point. It is difficult to guarantee that retrieved documents do not contain information published after the question date, which can lead to data leakage and overestimated performance. Therefore, additional research and system development on future information leakage are required. For example, Wildman et al. (2025) introduced a static benchmark with retrieved documents before the question date for each question using RetroSearch technique (Bosse et al., 2025). 20,000 documents are provided for each question on average. On the other hand, Turtel et al. (2025b) reported that they used a specific search API, Exa.ai API, which prevents information leakage. Ensemble Many forecasting studies employ LLM ensemble methods to enhance final performance (Halawi et al., 2024; Karger et al., 2025). This approach can involve generating multiple predictions from the same model using different prompts or ensembling predictions from multiple distinct models. Schoenegger et al. (2024) investigated ensemble effects using 12 models and compared their performance against human forecasters. Label type This paper explains event forecasting focusing on binary problems. Many event forecasting studies handle problems in binary classification form, or solve other types of problems by converting them to binary form. However, event forecasting can handle diverse problem types beyond binary classification. Multi-option, continuous (usually dates or numbers), entity-type open-ended (similar to multi-option but options are not given as choices), and sentence-type open-ended are problem types that can be handled in event forecasting (Wang et al., 2025). Most problem types can be relatively easily converted to binary problems. Multi-option or entity-type open-ended problems can be converted to binary problems for each individual option, and continuous problems can be converted to binary problems by dividing the range into appropriate intervals. LLMs can generally perform well across all of these problem types. For example, when asked to infer probabilities of specific dates or numbers (continuous), LLMs can approximate the probability distribution over continuous values by providing probability estimates at regular intervals (e.g., 5% intervals from the 5th to 95th percentile). While recent work on training (Halawi et al., 2024; Turtel et al., 2025a;b) for event forecasting have focused on binary outcomes, future work could investigate whether direct training on multi-option or continuous predictions outperforms binarization approaches. Consistency Many reports have mentioned that LLMs exhibit poor consistency in probabilistic reasoning. The prediction that a candidate will lose by April and the prediction that they will lose after April should sum to 100%, but LLMs often do not (Liptay, 2024b). Lyu et al. (2025) discussed that LLMs have poor probabilistic consistency ability, and suggested the possibility that probability estimation performance could improve if this is handled well. The winner of Metaculus AI Benchmarking 4Q tackled the consistency problem well to achieve results that surpassed other AI systems (Hickman, 2025). The winner improved model predictions by having the model consider additional related options beyond the two choices presented in binary problems, thereby improving performance in the challenge. For example, if asked whether there would be the first negative GDP growth in the fall, they also asked about growth in winter and summer at the same time. Paleka et al. (2025b), which deeply discussed consistency, not only pointed out existing problems in the event forecasting field but also proposed related datasets. In the proposed dataset, they evaluate whether LLMs follow probabilistic conditions that should be mathematically satisfied for 10 different consistency rules, including negation, paraphrasing, and consequence.", "mimetype": "text/plain", "start_char_idx": 16653, "end_char_idx": 20957, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ebee8422-9689-4833-b9b3-0d286c8f8fe1": {"__data__": {"id_": "ebee8422-9689-4833-b9b3-0d286c8f8fe1", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c417ce99-4fc9-4d11-9ec1-f4164c276b0f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "109ace0644510a427a56ebb6afe02e84c3549e453e5166d01ea5126380dd9c21", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5c4d6d39-20ca-4a8a-b995-5932eb940fb3", "node_type": "1", "metadata": {}, "hash": "b774ed7ccf48cb959bd62f1a6ce3dcd09639820360ed46af9fea7fe8b2c9906e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3 Past and current state of event forecasting Evaluation problems in previous studies Following the emergence of ChatGPT and similar models, numerous reports emerged claiming that LLM-based systems achieved near-superforecaster performance, 1https://github.com/Metaculus/metac-bot-template/ 5particularly throughout 2024 (Phan et al., 2024). However, subsequent analyses identified methodological flaws in these early optimistic analyses (Bosse et al., 2024; Paleka et al., 2025a). First, some studies drew excessive conclusions based on small samples that lacked sufficient statistical power to support their claims. Second, some studies erroneously used events that were resolved prior to the LLM\u2019s knowledge cut-off as evaluation instances, creating situations where models could simply recall memorized information (Lopez-Lira et al., 2025). Third, data contamination cases were also reported where documents from after the prediction resolution time were mixed into search results during web searches (Hendrycks and Mazeika, 2024). These methodological issues led to criticism that studies systematically overestimated LLM capabilities (Bosse, 2023a). However, Matthews (2025) present a balanced assessment of both promising developments and ongoing challenges in event forecasting, explaining that while there have been limitations in recent academic progress, there are still reasons to pay attention to AI prediction technology development. Recent AI performance advances Indeed, positive trends are being observed in recent developments in the event forecasting field, according to recent studies using rigorous evaluation with dynamic benchmarks. The ForecastBench paper (Karger et al., 2025) created a dynamic benchmark and evaluated various LLM systems in summer 2024. They showed that while LLMs are still far from reaching superforecaster-level, LLM performance in event forecasting develops along with LLM performance improvements. Specifically, the authors highlighted strong correlations between event forecasting Brier scores and both (a) Chatbot Arena (Chiang et al., 2024) scores and (b) estimates of pretraining compute, implying that increases in general LLM performance directly affect improvements in event forecasting performance. Compared to early open-source models like GPT-3.5-Turbo and Llama-2-70B which had Brier scores exceeding 0.2, recent high-performance models like GPT-4o (Brier score 0.133 in the paper) and Claude-3.5-Sonnet (Brier score 0.122) have significantly narrowed the gap to Superforecaster AI (Brier score 0.096). This analysis also evaluated the collective intelligence of the general public, finding that when aggregating forecasts from general public participants, the median prediction achieved a Brier score of 0.121, similar to the best AI level. Generally, collective median predictions offset individual participants\u2019 biases and errors, performing much better than individual predictions; at least in the paper\u2019s benchmark, AI performance has likely already significantly surpassed average individual performance. Furthermore, recent insightful reports on the Metaculus AI Benchmarking Series examine performance differences between evaluation experts and AI systems, sharing the trends that the latest models like OpenAI o1 and o3 (OpenAI, 2024; 2025a) consistently and significantly outperform previous models in these challenges (Liptay, 2024a; Hickman, 2025; Wilson and Bash, 2025; Williams, 2025b). Performance improvement through RL Recent achievements by Turtel et al. (2025a;b) regarding training are also noteworthy. These studies showed that reinforcement learning with verifiable rewards (RLVR) (Lambert et al., 2024; Guo et al., 2025) on outcomes can increase model performance. They conducted training and evaluation of the R1-14B model based on Polymarket datasets, showing that the R1-14B model with an original Brier score of 0.214 could reach OpenAI o1\u2019s 0.197 level through learning. Furthermore, they showed that additional data augmentation could further slightly improve performance, reduce algorithmic variance, and lower the model\u2019s overall ECE.", "mimetype": "text/plain", "start_char_idx": 20958, "end_char_idx": 25083, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5c4d6d39-20ca-4a8a-b995-5932eb940fb3": {"__data__": {"id_": "5c4d6d39-20ca-4a8a-b995-5932eb940fb3", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ebee8422-9689-4833-b9b3-0d286c8f8fe1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "569f7d93a1b1ed10c075d355906fa336bc08585b7faf1e8d7753f8655477e1df", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7cf1f99a-fee7-4a5d-a06a-8aad46a7244d", "node_type": "1", "metadata": {}, "hash": "97b7f5be86ce786dfe727bc8b82f9d1d585ad300c1f775d18605daf4ad8d6074", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Additionally, they showed in backtest experiments on Polymarket \u2014 experiments evaluating making money by betting on Polymarket\u2019s market in a virtual environment \u2014 that OpenAI o1 model and their trained algorithms could generate profits. They simulated trading by conducting trades when there were differences between the model\u2019s predicted values and market predicted values. While the long-term viability of LLM-based algorithmic trading in prediction markets requires further validation through real-world implementation, this result supports the argument that trained LLM models are getting closer to superforecaster-level AI. Deep Research Recent reasoning models with tool use like Deep Research (Citron, 2024; OpenAI, 2025b; Anthropic, 2025), o3, etc., also have the potential to be a major breakthrough for the event forecasting field. There are grounds to think their model structures could be suitable for event forecasting, especially when they are further trained with event forecasting-specific objective functions. They try various search and reasoning strategies on their own and attempt to solve problems by themselves, departing from the standardized prompt engineering-based or template-based reasoning used previously (Futuresearch, 2025). Furthermore, regression 6tests that infer current data values based on previous data are an important technique in event forecasting, and Deep research models have the capability to perform programming-based regression tests well (Liu et al., 2025). Therefore, using these models as a foundation model while incorporating event forecasting-specific training and inference strategies could yield substantial performance improvements. Proposal for large-scale training Based on these positive trends, we propose large-scale training for event forecasting LLM development. The current situation where model performance continues to improve and various training-related technologies are being developed suggests that opportunities have emerged to close the gap to superforecaster-level performance through comprehensive large-scale training. We address two key research directions for large-scale training in the next two sections: training (Section 4) and dataset (Section 5). Section 4 covers reward signal strategies and synthetic data generation methods to enhance efficiency within existing datasets, and Section 5 focuses on large-scale data collection. While these approaches can function independently, several algorithms from Section 4 create synergies with Section 5. In particular, solutions for the knowledge cut-off problem discussed in Section 4.2 enable models to effectively learn from historical patterns from the training instances before the knowledge cut-off, as discussed in Section 5. 4 Training algorithm improvements for future event forecasting In this section, we introduce three difficulties of event forecasting tasks that other AI tasks do not have when it comes to model training. Then, for the purpose of understanding these difficulties and enabling people to think about additional research directions based on this, we introduce several training ideas to mitigate these difficulties. The first training difficulty is the noisiness and sparsity problem of event forecasting outcomes (Kendall and Gal, 2017). For example, consider the problem of predicting the outcome of a US presidential election based on the initial situation. Since we can only make probabilistic inferences, not logical ones, based on information about the initial situation, the prediction label is noisy. Also, since presidential elections only occur once every four years, similar cases that can be used for training are sparse, making it difficult for models to learn sufficient patterns. We introduce the concept of hypothetical event Bayesian networks that can model this series of problems, and based on this, we discuss what kind of reward signals can be used for training. The second training difficulty is the knowledge cut-off problem, which is the difficulty of training or evaluating event forecasting questions about knowledge that LLMs already know internally. This greatly reduces the amount of data that LLMs can train on. As one approach to this problem, we introduce utilizing events that LLMs do not recall well, such as comparative outcomes between two items. As another approach, we present the idea of training counterfactual events together so that models can focus more on search and reasoning. The third training difficulty is the simple reward structure problem, where models can obtain rewards more easily than in other RL tasks without proper reasoning, hindering actual prediction ability improvement. To mitigate this problem, we propose auxiliary label training that can provide additional reward signals.", "mimetype": "text/plain", "start_char_idx": 25084, "end_char_idx": 29878, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7cf1f99a-fee7-4a5d-a06a-8aad46a7244d": {"__data__": {"id_": "7cf1f99a-fee7-4a5d-a06a-8aad46a7244d", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c4d6d39-20ca-4a8a-b995-5932eb940fb3", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "089a7e15f8ebf90326892271b58b15215fbdb2a00aa73991ba52b66b17d7c84d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8c93bffe-d77e-429f-ad1a-420fec555002", "node_type": "1", "metadata": {}, "hash": "2a774a8810ddbc605973aaa685768530bc082edd9e1d0ce95caac004dfe9ab51", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To mitigate this problem, we propose auxiliary label training that can provide additional reward signals. One example of auxiliary labels is evaluating the consistency of reasoning, and another is having the model answer additional questions related to the main question. 4.1 Modeling hidden probability of future event forecasting Let\u2019s say we want to train on whether \u201cToday is Dec 12, 2023. Will SpaceX successfully launch and return a spacecraft from Earth orbit by 2024 June?\u201d What should we use as the label for training and what training method should we use? Timeline: t0(Dec)\u2192t1(Feb)\u2192t2(Mar) Information: S0(initial situation) \u2192S1(intermediate update) \u2192S2(final result) Available: m0(market)\u2192m1(market)\u2192o(outcome) 7S0S1m0m1o Figure 1: A hypothetical event Bayesian network. The state S0at timet0changes to S1at timet1, and the probability of outcome ochanges. At time t0, we get market prediction value m0, and at time t1, we getm1. When training models, the natural and intuitive label in event forecasting is the outcome that can be known after the event is resolved. For example, since SpaceX successfully completed orbital flight on March 14, 2024, the actual outcome is 1.0 (success). However, if the prediction probability of a training instance becomes 1.0 during the actual training process, it suggests that the LLM may not be conducting good search and reasoning. Since the purpose of training is to generalize search and reasoning abilities, such extreme predictions hinder the development of core abilities in event forecasting. From the perspective of assigning appropriate probabilities to training instances, market prediction obtained from prediction markets would be a good estimate for that event through collective intelligence. However, if we train only on market predictions, it becomes difficult to create event forecasting prediction models that surpass market predictions. In this subsection, we first discuss the level of noisiness and sparsity of this problem to explain how this dilemma makes event forecasting problems difficult from a machine learning perspective. Then we introduce hypothetical event Bayesian networks that can theoretically understand this problem. Based on this conceptual analysis, we discuss how each approach to assigning labels in event forecasting can be explained and what label construction strategies and their variations can be used. 4.1.1 Noisiness and sparsity Event forecasting labels have two difficulties related to uncertainty built into them: the first is noisiness, and the second is sparsity. Regarding noisiness, consider the problem of predicting which candidate will win the 2024 US presidential election based on information available during the early stages of a competitive electoral campaign. No matter how much a smart expert analyzes available information from the early stages of the election, they cannot know for certain who will become president or what the probability is in percent. This means that the outcomes or market predictions we can use are inherently uncertain and noisy in explaining events. Regarding sparsity, US presidential elections are events that happen once every four years, making them very sparse events. Presidential elections exist for each country and each cycle, so we might be able to achieve generalization through this, but the context of presidential elections differs for each event, and it is difficult to generalize from one case to other cases. Although event frequency varies by domain, this illustrates the inherent sparsity of comparable training instances in event forecasting problems. From a traditional ML perspective, the former (noisiness) corresponds to aleatoric uncertainty, and the latter (sparsity) is related to epistemic uncertainty: events for which we have less data will have higher associated epistemic uncertainty (Kendall and Gal, 2017). The combination of these factors means that event forecasting faces higher uncertainty than many other ML problems. 4.1.2 Hypothetical event Bayesian networks We posed the question of what should be used as labels for event forecasting problems at the beginning of this subsection. As a conceptual framework for understanding this problem, let\u2019s construct a simple hypothetical event Bayesian network.", "mimetype": "text/plain", "start_char_idx": 29773, "end_char_idx": 34058, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8c93bffe-d77e-429f-ad1a-420fec555002": {"__data__": {"id_": "8c93bffe-d77e-429f-ad1a-420fec555002", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7cf1f99a-fee7-4a5d-a06a-8aad46a7244d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "b0f64c53674749bf09673fc7f345b64d2a9c3ba64c7671ba051e55378ade08a4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b36ee1e1-e379-42a4-8288-aed0bcd8176e", "node_type": "1", "metadata": {}, "hash": "0dbb2b009cd2a9218ed21f4ed1d8b27916bbb8de1a2d2a9084c65505b6a38879", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "As a conceptual framework for understanding this problem, let\u2019s construct a simple hypothetical event Bayesian network. Using the SpaceX example mentioned earlier, we model a situation where there is intermediate information in February ( t1)\u2014the success or failure of initial tests and reports\u2014between the question date t0in December and the resolution date t2in March. In our model, we define three core probabilities: \u03b1: final success probability when initial test fails (negative), \u03b2: final success probability when initial test succeeds (positive), \u03c0: probability that initial test succeeds (positive). Figure 1 is a diagram of our 8hypothetical event Bayesian network. Equations are as follows: \u03b1=P(o= 1|S1=negative ) \u03b2=P(o= 1|S1=positive ) \u03c0=P(S1=positive|S0=initial ) We seek to estimate an accurate probability for this question. Since the question date is t0, we need to estimate the probability that the outcome will occur at the S0point. We refer to this probability we are interested in as \u201chidden probability.\u201d The hidden probability Phiddenat the question date is as follows: Phidden =P(o= 1|S0=initial ) = (1\u2212\u03c0)\u03b1+\u03c0\u03b2 To estimate Phidden, we cannot observe these underlying probabilities \u03b1,\u03b2, and\u03c0directly, and instead need to infer these probabilities. One good estimate for Phiddenis a market prediction obtained through the collective intelligence of human forecasters. Market predictions m0andm1are estimates of P(o= 1|S0)and P(o= 1|S1), respectively, and we can assume they estimate values based on noisy observation of the actual parameters \u03b1,\u03b2, and\u03c0. In this hypothetical modeling, we can analyze how the accuracy of Phiddenestimation differs according to noise level and Nby sampling m0,m1,o Ntimes each (i.e., we simulate Nsimilar events, yielding {m0,n,m1,n,on}n=1,\u00b7\u00b7\u00b7,N).Nrepresents the number of hypothetical simulation trials. For example, in each trial,S1is sampled as positive with probability \u03c0. We can then compute separate estimates of Phidden by averaging the m0values,m1values, and ovalues, respectively (i.e.,1 N/summationtextN n=1m0,n,1 N/summationtextN n=1m1,n, and 1 N/summationtextN n=1on). How does the relative accuracy of each estimate differ at different Nvalues? First, let\u2019s think about the case whereN= 1. Sinceohas values of 0.0 or 1.0, there will be a considerable gap from Phidden. In this case, m0 is likely to be a much stronger estimate than o. However, let\u2019s think about the case where Nis sufficiently large. The estimation of m0contains prediction uncertainty noise, and this noise will slow convergence to Phidden. In this case, owill be a better estimate compared to m0. Can we use m1to estimate Phidden? Market predictions at the intermediate time m1occupy a middle ground betweenm0ando. Unlikem0, which must account for uncertainty about whether the intermediate state S1 will be positive or negative, m1is made after this uncertainty is resolved. However, unlike the final outcome o, m1still reflects the collective judgment of forecasters rather than a binary result. This positioning can make m1a superior estimate of Phiddenunder certain conditions, particularly when there is significant uncertainty in the transition from S0toS1(high estimation error for \u03c0) and when we have a moderate number of observations N. We provide detailed assumptions and simulation results demonstrating these trade-offs in Appendix A. Based on the hypothetical settings discussed above, let\u2019s now consider real scenarios of event forecasting tasks and address the question of whether to use outcome oor market prediction m0.", "mimetype": "text/plain", "start_char_idx": 33939, "end_char_idx": 37506, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b36ee1e1-e379-42a4-8288-aed0bcd8176e": {"__data__": {"id_": "b36ee1e1-e379-42a4-8288-aed0bcd8176e", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c93bffe-d77e-429f-ad1a-420fec555002", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "45651069b1befe7a2b4547a56f4506718f39cacb6dfced40e4d80fc7e52480b0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "279db839-6723-4de9-ab33-4981b1fd019a", "node_type": "1", "metadata": {}, "hash": "cc24e1a67163f2d40dac79024d5a9946522edebb4e3677bf43061b100f608eaa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Applying the hypothetical event Bayesian network framework, for data where there are few similar problems in the training data (small N), it would be good to use market prediction m0at question date time t0, and for cases where there are many similar problems (large N), it would be good to use outcome oat resolution date time t2. In practice, using both together could also be a way to get better estimates in some cases. According to the simulation in Appendix A, interestingly, there are also cases where using the market prediction value m1at timet1 betweent0andt2as a label for questions at time t0has advantages, and m1does not function merely as an approximation of o. The next subsubsection examines label assignment strategies that can be used based on this discussion. 4.1.3 Outcome as a reward signal The most direct method in event forecasting is using outcomes as rewards in RL. For example, we can use the negative Brier score between the probability predicted by the model and the actual outcome as a reward term (Turtel et al., 2025b), or give higher rewards to predictions closer to outcomes (Turtel et al., 2025a). 9Turtel et al. (2025b;a) achieved 5-10% Brier score improvement with training on outcomes; using outcomes in situations where an appropriately scaled dataset is secured can be a powerful baseline and practical approach. However, outcome-based training has the risk of models making extreme predictions approaching 0% or 100% after sufficient training epochs (Turtel et al., 2025b). More importantly, extreme predictions approaching 0% or 100% are likely signals that the LLM is not actually performing proper search and reasoning. The ultimate goal of event forecasting training is to learn good search and reasoning abilities and transfer them to test inference time, but extreme predictions hinder the development of these core abilities. Various regularization methods, such as early stopping, can be used to prevent this. 4.1.4 Market prediction as a reward signal Prediction markets serve as effective platforms for obtaining expert estimates of hidden probability Phidden in a scalable way. Each market prediction is a good estimate for that event, and from the hypothetical event Bayesian network perspective discussed earlier, it is an advantageous estimate to use when similar events occur infrequently. However, if we train only with market prediction, it becomes difficult to create event forecasting prediction models that surpass market prediction. Therefore, market prediction should be used as a reward signal in parallel with outcomes. In the research by Halawi et al. (2024), they used a specific interval between market prediction and outcome as the ground truth label. Specifically, they defined a 15% interval from the market prediction value in the direction of the actual outcome, and treated predictions within this range as correct answers. For example, if market prediction is 60% and outcome is 100%, they treated model predictions between 60% and 75% as correct. Additionally, various other methods for using market prediction and outcomes together in training can be considered. One method involves adding a KL-divergence term between model predictions and market predictions to the objective function, alongside the existing outcome-based reward signal. In another method, market predictions can be included directly as model inputs. The reliability of each market is also an important consideration. For example, markets with limited participation may exhibit higher noise levels (Bosse, 2023b). In (Halawi et al., 2024), they filtered out market data with few participants. Market reliability can be incorporated based on the specific approach used for market prediction. When using KL-divergence, the weight on the KL-divergence can be reduced for training instances corresponding to markets with few participants. When inputting market prediction values, related information about reliability can also be added together. Market predictions are available only when a prediction market exists for the specific event in question. When training on datasets containing both instances with available market predictions and instances without market data, reward signals derived from market predictions would be applied solely to those training instances where market prediction values are available.", "mimetype": "text/plain", "start_char_idx": 37507, "end_char_idx": 41866, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "279db839-6723-4de9-ab33-4981b1fd019a": {"__data__": {"id_": "279db839-6723-4de9-ab33-4981b1fd019a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b36ee1e1-e379-42a4-8288-aed0bcd8176e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "b6b4fbfa4c7d34bc6e597f2164d029244c68016fbe75c2e33153b6470cd0aa19", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2c15ca1a-6ff8-4c3b-aa9f-64612f7628fb", "node_type": "1", "metadata": {}, "hash": "b96c7dd332519cab4d18dd2670036f726a7c858da33519a3b0e4f1405998a026", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.1.5 Using prediction after the question time A considerable number of event forecasting questions in the world may not have outcomes determined yet at the current time point when we are training. Also, these forecasting questions may not have clearly defined resolution conditions, or there may be no pipeline to automatically extract outcomes for data construction because events are not registered in markets or databases. Can we train from such data where outcomes are not clearly obtained? If we can obtain market prediction m1at time point t1after question date t0, we can obtain reward signals from such data as well. There are two perspectives we can think about regarding the validity of using m1. The first is thinking of m1as a more accurate approximation of othanm0. Especially if the value of m1is close to 0.0 or 1.0, and if m1\u2019s estimation of ois close to unbiased (if the model\u2019s ECE is low), we can statistically say thatopredicts well at the probability that m1suggests. From that perspective, when we get m1that is sufficiently different from m0and close to 0.0 and 1.0, we can use m1for training. The statistical validity can be established through empirical data analysis. The second is understanding m1as an approximate estimate of Phiddenwhere uncertainty before t1has been resolved, as discussed in Section 4.1.2 earlier. In 10this interpretation, m1has meaning beyond being an estimate of o, and has the potential to provide better signals than oin certain scenarios. Next, we discuss whether the model\u2019s prediction q1at timet1can be used for model prediction where the question date is t0. When market prediction m1at timet1cannot be obtained because the prediction market does not handle that event, the use of model prediction q1becomes a consideration. Our hypothetical Bayesian network framework extends naturally from market predictions ( m0,m1) to model predictions (q0,q1). Critically, while q0offers no new information for training purposes, q1can leverage the temporal information gain between t0andt1, making it a viable training signal similar to m \u2081. The applicability of q1 can be evaluated using similar criteria as those for m1. Regarding the effectiveness of using q1, we need to additionally consider the performance of the predicting LLM itself. If the prediction model\u2019s predictions are not sufficiently accurate and have high noise, it may be difficult to use q1due to the high noise. Even when asking LLMs at time points after resolution date t2, if the LLM\u2019s search/RAG performance or fact checking performance is not 100%, the LLM may not achieve 100% accuracy. Notably, the model\u2019s prediction q1can be applied to forecasting questions where outcome resolution conditions are not rigorously defined. For instance, this value can be used for questions with ambiguous resolution conditions like \u201cDid ChatGPT released in 2023 have a positive impact on English education?\u201d or \u201cWill COVID vaccines effectively prevent COVID?\u201d This approach extends event forecasting from questions with clear resolution criteria to more general questions about the future by leveraging the information gap between past (S0) and present ( S1) states as training signals. 4.2 Training from data before knowledge cut-off In this part, we discuss the knowledge cut-off problem and introduce ideas to mitigate this problem, including (1) using events that LLMs do not remember well and (2) training counterfactual events together. 4.2.1 Knowledge cut-off problem When evaluating event forecasting problems using data from before the knowledge cut-off period, models can provide accurate responses by relying on their internal knowledge without employing search and reasoning capabilities. Since these memorization-based responses do not generalize to questions where the model has not observed the outcomes during training, data from before the knowledge cut-off loses its value for evaluation purposes. The same limitation applies to training. Models have reduced motivation to acquire additional information through search when they already possess the relevant knowledge internally, and similarly lack motivation to engage in reasoning processes for answers they have already memorized. Consequently, neither search capabilities nor reasoning abilities are enhanced through this training approach.", "mimetype": "text/plain", "start_char_idx": 41867, "end_char_idx": 46190, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2c15ca1a-6ff8-4c3b-aa9f-64612f7628fb": {"__data__": {"id_": "2c15ca1a-6ff8-4c3b-aa9f-64612f7628fb", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "279db839-6723-4de9-ab33-4981b1fd019a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "1af8969c1a3f803ae611b2fb84c82005459ccb7046a17ee12a902a0306c1b5c1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6ee032cc-ad33-4562-a00d-58f3706107c9", "node_type": "1", "metadata": {}, "hash": "83720a973a909f088fa42f4186d9eaae68041a393dd7ece019da4d78b1decac2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Consequently, neither search capabilities nor reasoning abilities are enhanced through this training approach. If we use past models with earlier knowledge cut-offs for event forecasting training, we can utilize more training data compared to the latest models. However, there are two major disadvantages to using past models. First, since the latest models outperform past models, we cannot leverage the capability improvements from LLM development (Karger et al., 2025). Second, the latest models possess the most recent knowledge. Models with more up-to-date knowledge will make better future predictions for questions that require recent trends as context, even without searching for that specific knowledge. Whether training can be conducted using data from before the knowledge cut-off is an important question. First, since substantially more data exists before the knowledge cut-off than after, the feasibility of utilizing pre-cutoff data determines the scale of available training data. Another issue is that if training data is constructed within a limited period after the knowledge cut-off, we end up training on data that exhibits biases specific to that particular period. For example, consider predicting numerous economic indicators during an economic boom period. Such a prediction model may not perform adequately during economic downturns. 4.2.2 Using events LLMs poorly recall One approach to addressing the knowledge cut-off problem is to use events that happened in the past but that LLMs cannot answer well through memorization as training data. We can explore what knowledge LLMs 11do not answer well through memorization by asking LLMs questions about various domains and use this approach to identify suitable training data. Types of information that LLMs do not memorize well are cases where LLMs know individual facts but do not memorize the relationships or comparison results between them. Wen et al. (2025) created an event forecasting task about which of two research ideas would show better performance on benchmarks. Existing LLM agents without special training showed only random baseline level (50%) performance in the above prediction task comparing the relative performance of two ideas, even though they had knowledge about individual papers. In that paper, they improved performance by training on 7,000 paper idea pairs based on open-source models. The trained model was able to achieve 77% accuracy forecasting performance on 1,500 pairs after the knowledge cut-off by retrieving related past papers and knowledge. If we apply this approach of predicting comparison results of two indicators from the same period to data from more domains, we should be able to create data that can be used for training to increase event forecasting performance, even though it is data from before the knowledge cut-off date. For example, we can consider (1) future relative market performance of products released at the same time, (2) comparison of specific future indicators of companies with similar backgrounds, and (3) comparison of future citation counts of papers presented at academic conferences. However, it remains an open empirical question whether training on such poorly-recalled historical events improves performance on general event forecasting tasks. Validating this transfer represents an important direction for future research. 4.2.3 Putting counterfactual events Another approach is to use counterfactual events to make LLMs utilize retrieved knowledge for reasoning and probability prediction even when training from data before the knowledge cut-off. In this idea, we use counterfactual events that have outcomes opposite to the actual events that happened in the past. The key insight of this approach is that since LLMs must reason based on retrieved information even in counterfactual scenarios, they develop actual reasoning abilities rather than simple memorization. Related research in the question answering field that used counterfactual event-based retrieved knowledge utilization can be referenced (Paranjape et al., 2022). For example, Neeman et al. (2023) showed that training on counterfactual knowledge can increase models\u2019 search grounding and reduce hallucination. In this research, counterfactual documents were constructed by modifying the correct answer entity in search documents. Specific ideas for creating counterfactual events are as follows. First, we need to create fictional search documents that support counterfactual events.", "mimetype": "text/plain", "start_char_idx": 46080, "end_char_idx": 50585, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6ee032cc-ad33-4562-a00d-58f3706107c9": {"__data__": {"id_": "6ee032cc-ad33-4562-a00d-58f3706107c9", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0f40196-a659-466c-a28a-b6b64a25be2a", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "593d2d196e60157e28c9d12aaad660e87f407ada94c7c9c0f88675c8b97f528b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c15ca1a-6ff8-4c3b-aa9f-64612f7628fb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv"}, "hash": "a26346e0207378b98b36cbf6798b1233424d0e1d438d9b9e681fd3f0192f9ac2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "First, we need to create fictional search documents that support counterfactual events. We can make LLMs generate fictional news articles reflecting counterfactualoutcomesandusethemasiftheyweresearchresults.Forexample,wecancreateacounterfactual event of \u201cSpaceX Starship 3rd launch failure in March 2024,\u201d which is the opposite outcome of \u201cSpaceX Starship 3rd launch success in March 2024,\u201d and create related fictional news articles. Here is an example of an implementable pipeline: Step 1: Base event selection and counterfactual divergence point setting For each base event, we set a specific time point (divergence date) where actual events and counterfactual events split. We use actual search documents until this poi", "mimetype": "text/plain", "start_char_idx": 50498, "end_char_idx": 51221, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3655e5af-c111-4716-97dd-083e09278ff0": {"__data__": {"id_": "3655e5af-c111-4716-97dd-083e09278ff0", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5787f5e6-7229-4a94-8af4-b8cce7de27a1", "node_type": "1", "metadata": {}, "hash": "756dcb15987eb92e60f254d1987bef254c53dcc232fefed2c36338e6cd8ae2eb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization\n\nAuthors: Anton Pembek, Artem Fatkulin, Anton Klenitskiy, Alexey Vasilev\n\nAbstract: Many sequential recommender systems suffer from the cold start problem, where\nitems with few or no interactions cannot be effectively used by the model due\nto the absence of a trained embedding. Content-based approaches, which leverage\nitem metadata, are commonly used in such scenarios. One possible way is to use\nembeddings derived from content features such as textual descriptions as\ninitialization for the model embeddings. However, directly using frozen content\nembeddings often results in suboptimal performance, as they may not fully adapt\nto the recommendation task. On the other hand, fine-tuning these embeddings can\ndegrade performance for cold-start items, as item representations may drift far\nfrom their original structure after training. We propose a novel approach to\naddress this limitation. Instead of entirely freezing the content embeddings or\nfine-tuning them extensively, we introduce a small trainable delta to frozen\nembeddings that enables the model to adapt item representa\n\nFull Text: Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization Anton Pembek apembek@bk.ru Sber AI Lab, Lomonosov Moscow State University (MSU) Moscow, Russian FederationArtem Fatkulin artem42fatkulin@gmail.com Sber AI Lab, HSE University Moscow, Russian Federation Anton Klenitskiy antklen@gmail.com Sber AI Lab Moscow, Russian FederationAlexey Vasilev alexxl.vasilev@yandex.ru Sber AI Lab, HSE University Moscow, Russian Federation Figure 1: Illustration of the proposed approach. Abstract Many sequential recommender systems suffer from the cold start problem, where items with few or no interactions cannot be effec- tively used by the model due to the absence of a trained embed- ding. Content-based approaches, which leverage item metadata, are commonly used in such scenarios. One possible way is to use embeddings derived from content features such as textual descrip- tions as initialization for the model embeddings. However, directly using frozen content embeddings often results in suboptimal per- formance, as they may not fully adapt to the recommendation task. On the other hand, fine-tuning these embeddings can degrade per- formance for cold-start items, as item representations may drift far from their original structure after training. We propose a novel approach to address this limitation. Instead of entirely freezing the content embeddings or fine-tuning them extensively, we introduce a small trainable delta to frozen embed- dings that enables the model to adapt item representations without letting them go too far from their original semantic structure. This approach demonstrates consistent improvements across multiple datasets and modalities, including e-commerce datasets with textual descriptions and a music dataset with audio-based representation. RecSys \u201925, Prague, Czech Republic \u00a92025 Copyright held by the owner/author(s). Publication rights licensed to ACM. This is the author\u2019s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in Proceedings of the Nineteenth ACM Conference on Recommender Systems (RecSys \u201925), September 22\u201326, 2025, Prague, Czech Republic , https://doi.org/10.1145/3705328.3748038.CCS Concepts \u2022Information systems \u2192Recommender systems . Keywords Recommender Systems, Sequential Recommendations, Cold-start ACM Reference Format: Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev. 2025. Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recom- mendations with Content-Based Initialization. In Proceedings of the Nine- teenth ACM Conference on Recommender Systems (RecSys \u201925), September 22\u201326, 2025, Prague, Czech Republic. ACM, New York, NY, USA, 6 pages.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3998, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5787f5e6-7229-4a94-8af4-b8cce7de27a1": {"__data__": {"id_": "5787f5e6-7229-4a94-8af4-b8cce7de27a1", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3655e5af-c111-4716-97dd-083e09278ff0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "fa5b60eaa00c82cdb1ee03839bd21a585e91c054feb7f761aed2ca470676fee7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0f4b023d-91fa-42ce-9d83-a43adb2beefb", "node_type": "1", "metadata": {}, "hash": "398a39e309cea0295ebe7b8f9674d7db0a49ec9561176b15b4b3080ff4aa3961", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "ACM, New York, NY, USA, 6 pages. https://doi.org/10.1145/3705328.3748038 1 Introduction The cold start problem remains a significant challenge for recom- mender systems in general and sequential recommender systems in particular. These systems aim to predict a user\u2019s next interac- tion based on their history, but struggle when encountering cold items with few or no interactions. This lack of interactions means the model cannot learn effective representations for these items, leading to poor recommendation quality. A common strategy to address this issue is to leverage content- based features, such as textual descriptions, to construct embed- dings for cold items. However, this approach introduces a distri- bution gap: the embeddings of warm items, learned during model training, may differ significantly from content-based embeddings used for cold items. To bridge this gap, various techniques have been explored, including learning transformations from cold embeddingsv1 [cs.IR] 25 Jul 2025RecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev to the warm item embedding space [ 21,23,27], employing con- trastive learning [ 26], adversarial training [ 3], and distillation [ 7] to encourage similarity between cold and warm item representations. Recent works [ 1,5] demonstrated that using text embeddings as initialization for transformer-based sequential recommendation models like SASRec [ 10] and BERT4Rec [ 18] improves overall rec- ommendation quality. In our work, we investigate how content- based initialization, not limited to text but also including audio- based features, affects the cold start problem in sequential rec- ommendation. A straightforward solution is to substitute content embeddings for cold items into a trained model. However, allowing full fine-tuning of these embeddings during training can hurt per- formance on cold items, as the embeddings may drift significantly from their initial content-based representation. On the other hand, fully freezing content embeddings limits the model\u2019s flexibility and hurts overall performance, as it cannot fully adapt to the interaction data. To address these limitations, we propose an approach where item embeddings consist of two components. The first component is frozen content embeddings with a fixed norm. The second com- ponent is a small trainable delta vector with a bounded norm. This setup allows the model to adapt item representations to the interac- tion data without letting them go far from their original semantic structure derived from content. As a result, it improves recommen- dation quality on new items without sacrificing performance on those seen during training. The main contributions of our work are as follows: \u2022We investigate the impact of content-based embedding ini- tialization on the cold start problem in transformer-based sequential recommendation. \u2022We propose a method that learns a small trainable delta with bounded norm on top of frozen content embeddings. \u2022We demonstrate that this approach consistently improves performance on cold items across different data modalities, including textual item descriptions and audio representations of songs. 2 Related Work Using content-based representations to derive model embeddings is a common strategy for addressing the item cold start problem. Different approaches have been proposed to align cold item em- beddings with the warm embedding space. The work [ 21] predicts latent factors directly from a song\u2019s audio content. DropoutNet [ 23] takes both latent preference factors and content features as input and applies input dropout to the latent factors during training, forcing the model to rely on content when preference information is missing. The paper [ 27] uses meta networks to generate item- specific scaling and shifting functions that transform cold item embeddings into the warm feature space. CLCRec [ 26] applies con- trastive learning to maximize the mutual information between item content representations and collaborative embeddings. GAR [ 3] em- ploys adversarial training between a generator and a recommender to ensure that generated cold item embeddings have a similar distri- bution to warm ones.", "mimetype": "text/plain", "start_char_idx": 3966, "end_char_idx": 8225, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0f4b023d-91fa-42ce-9d83-a43adb2beefb": {"__data__": {"id_": "0f4b023d-91fa-42ce-9d83-a43adb2beefb", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5787f5e6-7229-4a94-8af4-b8cce7de27a1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "56c3d35f496985c27fe5e61c9353214304ebcb1fe7035bbee3cb4358fbc3d2bd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4232ecb5-0f02-4c22-905d-17dfa3dab83c", "node_type": "1", "metadata": {}, "hash": "5e9b2d22c67e5beb93920180109746b8568d3a84dd30699f6d843ed1495dbfdd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "ALDI [ 7] introduces a distillation framework where warm items act as \"teachers\" and cold items as \"students,\" aligning the students\u2019 content-based predictions with the teachers\u2019behavior-based predictions. These works mainly focus on collabo- rative filtering models rather than sequential recommendations. For sequential recommendations, M2TRec [ 15] introduces an item-ID-free framework that learns item representations directly from metadata and uses multi-task learning. Recformer [ 13] models items and user preferences using language representations derived solely from item textual attributes. This approach, however, in- creases computational complexity compared to ID-based methods due to much longer input sequences. In contrast to these works, we focus on leveraging content embeddings within classic ID-based models like SASRec. SimRec [ 2] and the work [ 25] incorporate item similarities derived from textual embeddings into the training process of such models using customized loss functions. Unlike our approach, they consider tail items - those with very few in- teractions but not completely new - as cold. The works [ 1,5] use textual embeddings to initialize the transformer embedding layer and show that this approach improves recommendation metrics. However, they do not specifically address the cold start problem. The paper [ 20] explores the usage of frozen pretrained audio repre- sentations for music recommendations without any fine-tuning. 3 Approach 3.1 Task formulation LetUbe the set of users and Ibe the set of items. In the sequential recommendation setting, we are given an ordered history of user interactions with items. The objective is to predict the next item the user will interact with. State-of-the-art sequential recommender systems (e.g., SASRec and BERT4Rec) typically define a learnable embedding function \ud835\udc38:I\u2192R\ud835\udc5a, which maps each item \ud835\udc56\u2208Ito a vector representation e\ud835\udc56\u2208R\ud835\udc5a. A transformer-based architecture aggregates a sequence of user interactions into a user representation h\ud835\udc62\u2208R\ud835\udc5a. This representation is then used in a Maximum Inner Product Search (MIPS) to compute relevance scores for all items: \ud835\udc5f(\ud835\udc62,\ud835\udc56)=h\ud835\udc62\u00b7e\ud835\udc56(1) While demonstrating superior overall performance, such models fail to handle new items due to the absence of trained embeddings for them \u2014 a problem called item cold start. At the same time, enabling the model to make use of cold items can increase recom- mendation diversity, improve overall performance by leveraging interactions with newly introduced content, and extend the model\u2019s deployment lifetime by reducing the need for frequent retraining. Addressing this limitation is therefore crucial for building robust and efficient recommender systems. 3.2 Content-based initialization In many domains, items are accompanied by additional information, such as textual descriptions for goods or sound-based embeddings for music tracks. In the absence of trained embeddings for new items, it is reasonable to utilize this content information to gener- ate initial representations. For cold items, these representations can be used as-is during inference, while for warm items, they can be fine-tuned along with other parts of the model during training. Prior works have shown [ 1,5] that initializing the model with text-based embeddings can significantly improve recommendation quality.Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization RecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Nevertheless, the effectiveness of content-based initialization de- pends critically on both the quality of the source information and the capabilities of the encoder model. For example, as previously shown in [ 20], different audio encoding techniques demonstrate various performance when used to generate music track represen- tations. Furthermore, the direct use of content-based embeddings comes with a major drawback: freezing them during training leads to degraded model performance, while allowing them to be updated makes the approach less suitable for the item cold start scenario. That is, once training is complete, the content-based embeddings of cold items remain outside the learned representation space, re- sulting in poor generalization to unseen items.", "mimetype": "text/plain", "start_char_idx": 8226, "end_char_idx": 12516, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4232ecb5-0f02-4c22-905d-17dfa3dab83c": {"__data__": {"id_": "4232ecb5-0f02-4c22-905d-17dfa3dab83c", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0f4b023d-91fa-42ce-9d83-a43adb2beefb", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "30440cdf420b76aa485f92603ee0dbbb8168f72b5367d5944e211af59145674d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "132dad29-60f0-4e9f-a1a6-16810e9ac804", "node_type": "1", "metadata": {}, "hash": "4a0e43888fff2dd7533cc1fb17cf9c44950f42416050e008861c209c77346ac5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3.3 Representation adjustment To overcome this limitation, we propose freezing content-based item embeddings, fixing their norm, and training only a small delta layer. This allows the model to adjust item representations slightly while keeping them close to the original embeddings. di ei ci\u03b8 \u03b3 Figure 2: Geometric representation of the proposed approach. c\ud835\udc56is a frozen content-based item embedding, d\ud835\udc56is the corre- sponding trainable correction vector and e\ud835\udc56is the final item representation. Formally, given a content-based embedding c\ud835\udc56\u2208R\ud835\udc5aof an item \ud835\udc56\u2208Iwith unit norm\u2225c\ud835\udc56\u2225=1, and a trainable delta vector d\ud835\udc56\u2208R\ud835\udc5a with\u2225d\ud835\udc56\u2225=\ud835\udeff\ud835\udc56, where 0\u2264\ud835\udeff\ud835\udc56<1, we consider the cosine similarity between the original embedding and its adjusted form e\ud835\udc56=c\ud835\udc56+d\ud835\udc56: sim(c\ud835\udc56,e\ud835\udc56)=cos\ud835\udefe=\u221a\ufe03 1\u2212sin2\ud835\udefe (2) where\ud835\udefedenotes the angle between c\ud835\udc56ande\ud835\udc56. Although the minimum cosine similarity can be obtained by straightforward differentiation, here we present a more elegant and intuitive derivation using the law of sines: \u2225d\ud835\udc56\u2225 sin\ud835\udefe=\u2225c\ud835\udc56\u2225 sin\ud835\udf03=\u21d2 sin\ud835\udefe=\ud835\udeff\ud835\udc56sin\ud835\udf03 (3) where\ud835\udf03is the interior angle of the triangle opposite the side repre- sented by vector c\ud835\udc56(see Figure 2). Applying this substitution to Equation 2 gives an explicit rela- tionship between cosine similarity and the norm of the correction vector: sim(c\ud835\udc56,e\ud835\udc56)=\u221a\ufe03 1\u2212\ud835\udeff2 \ud835\udc56sin2\ud835\udf03 (4) The minimum cosine similarity occurs when \ud835\udf03=\ud835\udf0b/2and is equal: min \ud835\udf03sim(c\ud835\udc56,e\ud835\udc56)=\u221a\ufe03 1\u2212\ud835\udeff2 \ud835\udc56(5)Geometrically, if we visualize the endpoint of e\ud835\udc56tracing a sphere of radius\ud835\udeff\ud835\udc56around the endpoint of c\ud835\udc56, the case where the vector d\ud835\udc56 is orthogonal to e\ud835\udc56corresponds to this minimum (see Figure 2). Thus, by varying the norm \ud835\udeff\ud835\udc56, we can control how close the item representation is to the original content-based embedding. We apply the following strategy to constrain the correction vectors during training: we introduce a hyperparameter \ud835\udeffmaxand clip the norm of each vector if it exceeds this threshold. In the item cold start scenario, maintaining proximity to content- based embeddings enables direct use of these representations for cold items. Additionally, the proposed technique also serves as a form of regularization. Since sequential recommenders rely on MIPS, where the embedding norm directly influences item scores, it is important to manage the variation in norms across items, which we found to be substantial. 4 Experiments 4.1 Experimental settings Table 1: Statistics of the datasets after preprocessing, includ- ing average sequence length and the percentage of cold items in the ground truth (GT). Dataset # Users # Items # Interact.Avg. Cold items length in GT Amazon-M2 FR [9] 129,983 44,049 566,806 4.3 7% Beauty [14] 21,029 11,733 149,147 7.1 25% Zvuk [16] 9,076 131,085 3,236,653 356.6 13% 4.1.1 Datasets. We evaluate our approach on three datasets from different domains. Amazon-M2 [ 9] is a dataset from the KDD Cup 2023 competition1. It comprises customer shopping sessions from six locales and includes textual item descriptions.", "mimetype": "text/plain", "start_char_idx": 12517, "end_char_idx": 15449, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "132dad29-60f0-4e9f-a1a6-16810e9ac804": {"__data__": {"id_": "132dad29-60f0-4e9f-a1a6-16810e9ac804", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4232ecb5-0f02-4c22-905d-17dfa3dab83c", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "207a82cb8e210375b1a1c894619d017230eb2aec3665284ad44623a134a69edd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bb20f6c6-9134-47fa-bba7-c586c497b183", "node_type": "1", "metadata": {}, "hash": "f4d2066b623d1fe4f2e03162c5ad2d51982ed76e775665e24fabd7d0168eea7c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It comprises customer shopping sessions from six locales and includes textual item descriptions. Beauty, one of the most widely used datasets in sequential recommendation with inherent sequential patterns [ 12], contains customer reviews and is also rich in textual information. To verify that our method general- izes across modalities, we additionally examine Zvuk [ 16], a dataset with strong sequential structure [ 12] from the music streaming service containing audio-based item representations. For Amazon-M2, we use the original data provided by the au- thors, restricting our evaluation to the France locale (specifically, Task 2, Phase 1). Following [ 6,12], we remove consecutive dupli- cated items from the user sequence for all datasets. For the Zvuk dataset, we consider interactions longer than 60 seconds as positive and retain only those, while for Beauty, we filter out reviews with a rating lower than 4. Additionally, for Zvuk, we randomly sample 10,000 users to obtain a representative yet computationally efficient subset. Finally, we apply \ud835\udc5b-core filtering [ 19] with\ud835\udc5b=3to the train/validation data for Zvuk and Beauty. The final statistics of the datasets after preprocessing are summarized in Table 1. 4.1.2 Evaluation. For Amazon-M2, we use the original train-test split configuration with a 2-week training period followed by a 1-week test period. For Beauty and Zvuk, we use a global temporal split to prevent data leakage [ 8,17] with the temporal boundary set at 90% of the interactions. The validation set consists of sequences from 10% of randomly sampled users for all datasets. The last inter- action is used as the ground truth for validation and test sets, while 1https://kddcup23.github.ioRecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev Table 2: Performance on cold, warm, and all ground -truth items. Bold numbers mark the best model; the second best is underlined . Abbreviations: c.i. \u2013 content initialization, t.d. \u2013 trainable delta, GT \u2013 ground truth. Metric ModelAmazon-M2 Beauty Zvuk Cold GT Warm GT Total Cold GT Warm GT Total Cold GT Warm GT Total HR@10Content-based KNN 0.454 \u00b10.000 0.383\u00b10.000 0.388\u00b10.000 0.043\u00b10.000 0.044\u00b10.000 0.044\u00b10.000 0.009\u00b10.000 0.000\u00b10.000 0.001\u00b10.000 SASRec 0.000 \u00b10.000 0.610\u00b10.003 0.567\u00b10.002 0.000\u00b10.000 0.072\u00b10.001 0.054\u00b10.001 0.000\u00b10.000 0.094\u00b10.003 0.082\u00b10.003 SASRec with c.i. 0.435 \u00b10.015 0.620\u00b10.002 0.607\u00b10.001 0.032\u00b10.004 0.088\u00b10.002 0.074\u00b10.002 0.023\u00b10.003 0.088\u00b10.002 0.080\u00b10.002 SASRec with t.d.", "mimetype": "text/plain", "start_char_idx": 15353, "end_char_idx": 17913, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bb20f6c6-9134-47fa-bba7-c586c497b183": {"__data__": {"id_": "bb20f6c6-9134-47fa-bba7-c586c497b183", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "132dad29-60f0-4e9f-a1a6-16810e9ac804", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "9cfda5f3fd76f7d268ab953c8c49b969e092dbb279b0c26a20b6e12cb58547b0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6b162950-280a-48c2-b2e9-62de59c18016", "node_type": "1", "metadata": {}, "hash": "3fa5668d4f96900f984224428c76a11dd87076222bd2e204e1c8c2a9ce311560", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(ours) 0.509\u00b10.005 0.617\u00b10.002 0.609\u00b10.002 0.038\u00b10.008 0.092\u00b10.002 0.078\u00b10.003 0.034\u00b10.002 0.094\u00b10.002 0.087\u00b10.002 NDCG@10Content-based KNN 0.312 \u00b10.000 0.232\u00b10.000 0.238\u00b10.000 0.022\u00b10.000 0.024\u00b10.000 0.024\u00b10.000 0.006\u00b10.000 0.000\u00b10.000 0.001\u00b10.000 SASRec 0.000 \u00b10.000 0.438\u00b10.002 0.407\u00b10.002 0.000\u00b10.000 0.043\u00b10.001 0.033\u00b10.001 0.000\u00b10.000 0.063\u00b10.001 0.055\u00b10.001 SASRec with c.i. 0.297 \u00b10.010 0.448\u00b10.001 0.438\u00b10.000 0.018\u00b10.002 0.053\u00b10.001 0.044\u00b10.001 0.014\u00b10.002 0.058\u00b10.002 0.052\u00b10.001 SASRec with t.d. (ours) 0.359\u00b10.000 0.446\u00b10.002 0.440\u00b10.002 0.022\u00b10.004 0.054\u00b10.001 0.046\u00b10.002 0.021\u00b10.002 0.060\u00b10.002 0.055\u00b10.002 the previous part of the sequence is used as input to the model. This setup is appropriate for next-item prediction according to [4]. To evaluate the quality of the recommendation, we use Nor- malized Discounted Cumulative Gain (NDCG@10) and Hit Rate (HR@10) from the Replay library [ 22]. We distinguish between warm items, which are present in the training set, and cold items appearing only in the test set. To evaluate the impact on the cold- start problem, we measure the performance separately for users with warm ground-truth items and users with cold ground-truth items. Table 1 shows the proportion of such users. 4.1.3 Implementation Details. We perform the experiments with the SASRec model [ 10]. All models are trained using full cross- entropy loss following [ 11], with a batch size of 128. We employ the Adam optimizer with a learning rate of 1e-3. SASRec is configured with two transformer blocks, a single attention head, and a dropout rate of 0.3. The embedding dimension is set to 128 for Beauty and Zvuk, and to 64 for Amazon-M2. The maximum input sequence length is limited to 128 for Zvuk, and to 64 for Amazon-M2 and Beauty. For text-based content embeddings, we employ the E5 encoder [ 24], while the Zvuk dataset includes precomputed audio embeddings2. In practice, content-based embeddings often exhibit higher di- mensionality than the model\u2019s internal representations. To recon- cile this mismatch, we first apply component-wise standardization, followed by Principal Component Analysis (PCA) to reduce the embeddings to the target dimension. To increase the statistical significance of the results, we run each experiment five times with different random seeds and calculate ag- gregated metrics. All code necessary to reproduce our experiments is available at our GitHub repository3. 4.2 Results 4.2.1 Main results. Table 2 summarizes the results of the experi- ments on all datasets.", "mimetype": "text/plain", "start_char_idx": 17914, "end_char_idx": 20452, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6b162950-280a-48c2-b2e9-62de59c18016": {"__data__": {"id_": "6b162950-280a-48c2-b2e9-62de59c18016", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bb20f6c6-9134-47fa-bba7-c586c497b183", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "0180498e3be0023141f76df60c99daae0ec7e37c93002c775f84f97140ac1853", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a6bbdbaa-e091-4351-ac23-e38bbbc671fe", "node_type": "1", "metadata": {}, "hash": "129107df64879110251e74c84186607e4ed3e3c10692970e0224d3b2da6106de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Table 2 summarizes the results of the experi- ments on all datasets. The Content-based KNN method serves as a 2https://www.kaggle.com/datasets/alexxl/zvuk-dataset 3https://github.com/ArtemF42/let-it-gocontent-based baseline that recommends items most similar to the average content embedding of the user\u2019s sequence. SASRec refers to the standard version of the model, which cannot handle cold items. SASRec with content initialization is a baseline variant where item embeddings are initialized from content and then fully fine- tuned during training. SASRec with trainable delta is our proposed approach from Section 3 with a maximum norm constraint of the delta vector \ud835\udeffmax=0.5corresponding to minimum cosine similarity of0.87. SASRec with content initialization outperforms the content-based baseline on the Zvuk dataset and performs slightly worse on the other datasets in the cold-item settings. As expected, the content- based baseline performs significantly worse on warm items. Impor- tantly, incorporating cold items into SASRec does not degrade its performance on warm items. Content initialization even improves warm-item metrics compared to the original model on Amazon-M2 and Beauty datasets. Our proposed version with a trainable delta leads to substan- tial improvements in cold-item metrics across all three datasets, outperforming the content-based baseline. Warm-item and overall performance also show slight improvements, demonstrating the robustness of our method. 4.2.2 Norm of the delta vector. The norm of the trainable delta vector is the main hyperparameter in our approach. Figure 3 shows how NDCG@10 for cold and all items changes with different values of\ud835\udeffmaxon the Amazon-M2 dataset. When \ud835\udeffmaxis too small, the model does not have enough flexibility to adjust item representa- tions, and the total quality drops significantly. When the value is too large, the embeddings move too far from their original initializa- tion, which leads to worse performance on cold items. We find that values in the range of 0.3 to 0.6 provide a good trade-off, giving the model enough capacity to learn while still keeping the embeddings close to their initialization. 4.2.3 Cold items in input sequences. While the results in Table 2 are focused on cold items in the ground truth, Figure 4 shows how performance metrics change with the proportion of cold items inLet It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization RecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Figure 3: Mean total (top) and cold (bottom) NDCG@10 for SASRec with trainable delta evaluated against \ud835\udeffmaxon the Amazon-M2 dataset. SASRec with content initialization is provided for comparison. Low \ud835\udeffmax values yield high cold-item metrics but degrade the model\u2019s overall quality. user input sequences on the Amazon-M2 dataset. Using content- based initialization significantly improves recommendation quality when cold items are presented in the sequence. Implementing a trainable delta leads to a further, though smaller, improvement in this setting. Figure 4: Mean NDCG@10 for SASRec, SASRec with content initialization, and SASRec with trainable delta, evaluated across different proportions of warm items in test input se- quences on Amazon-M2 dataset. 4.2.4 Low-frequency items. We further analyze how recommen- dation quality metrics for ground-truth items vary with their fre- quency in the training set, as shown in Figure 5. Our trainable delta approach demonstrates improvements for rare items, with perfor- mance gradually converging to SASRec levels as item frequency increases.", "mimetype": "text/plain", "start_char_idx": 20384, "end_char_idx": 24021, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a6bbdbaa-e091-4351-ac23-e38bbbc671fe": {"__data__": {"id_": "a6bbdbaa-e091-4351-ac23-e38bbbc671fe", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6b162950-280a-48c2-b2e9-62de59c18016", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "3a05c75d6b047cd2cf2656a78a5770f57748516c1f34c0d41520243720038388", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ff5b4e40-acf6-4130-98f5-b0e1a580c413", "node_type": "1", "metadata": {}, "hash": "680fc475a271d987af6d0ceb7e9f4a70aeaa3d51a4acae566f3787350443b622", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "5 Conclusion In this work, we proposed a simple yet effective method for ad- dressing the cold start problem in sequential recommendations by adding a small trainable delta with a bounded norm to frozen Figure 5: Mean NDCG@10 (top) and NDCG@10 relative to SASRec (bottom) for SASRec, SASRec with content initial- ization, and SASRec with trainable delta, evaluated against the frequency of ground-truth items in the training set on Amazon-M2 dataset. content-based embeddings. We evaluated our approach on datasets with text-based and audio-based embeddings, confirming its appli- cability across different modalities of item content. Our key findings demonstrate that the performance on cold items in the ground truth shows significant improvement, while the metrics on warm items remain stable without degradation. Although the approach achieves superior quality metrics, it in- troduces additional training cost due to maintaining a second em- bedding vector for each item. This memory overhead may limit scalability for extremely large item sets. Future work could address this issue by reducing the embedding size or extending our study to additional modalities and recommendation scenarios. References [1]Artun Boz, Wouter Zorgdrager, Zoe Kotti, Jesse Harte, Panos Louridas, Vassilios Karakoidas, Dietmar Jannach, and Marios Fragkoulis. 2025. Improving sequential recommendations with llms. ACM Transactions on Recommender Systems (2025). doi:10.1145/3711667 [2]Shaked Brody and Shoval Lagziel. 2024. SimRec: Mitigating the cold- start problem in sequential recommendation by integrating item similarity. (2024). https://www.amazon.science/publications/simrec-mitigating-the-cold- start-problem-in-sequential-recommendation-by-integrating-item-similarity [3]Hao Chen, Zefan Wang, Feiran Huang, Xiao Huang, Yue Xu, Yishi Lin, Peng He, and Zhoujun Li. 2022. Generative adversarial framework for cold-start item recommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . 2565\u20132571. doi:10.1145/ 3477495.3531897 [4]Danil Gusak, Anna Volodkevich, Anton Klenitskiy, Alexey Vasilev, and Evgeny Frolov. 2025. Time to Split: Exploring Data Splitting Strategies for Offline Evalu- ation of Sequential Recommenders. In Proceedings of the 19th ACM Conference on Recommender Systems . doi:10.1145/3705328.3748164 [5]Jesse Harte, Wouter Zorgdrager, Panos Louridas, Asterios Katsifodimos, Diet- mar Jannach, and Marios Fragkoulis. 2023. Leveraging large language models for sequential recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems . 1096\u20131102. doi:10.1145/3604915.3610639 [6]Bal\u00e1zs Hidasi and \u00c1d\u00e1m Tibor Czapp. 2023. Widespread flaws in offline eval- uation of recommender systems. In Proceedings of the 17th acm conference on recommender systems . 848\u2013855. doi:10.1145/3604915.3608839 [7]Feiran Huang, Zefan Wang, Xiao Huang, Yufeng Qian, Zhetao Li, and Hao Chen. 2023. Aligning distillation for cold-start item recommendation. In ProceedingsRecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1147\u20131157.", "mimetype": "text/plain", "start_char_idx": 24022, "end_char_idx": 27302, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ff5b4e40-acf6-4130-98f5-b0e1a580c413": {"__data__": {"id_": "ff5b4e40-acf6-4130-98f5-b0e1a580c413", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a6bbdbaa-e091-4351-ac23-e38bbbc671fe", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "dd3dbf448c71dc4406c1a9673664c4788b2ec10eabe95024ef6c2159d32092c1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a3c125e6-af0b-4556-bac8-f4fcc93a3d65", "node_type": "1", "metadata": {}, "hash": "5c8724d6f3ec51f4131df9341e109cfc8bfcd859cc734b185b7e61808ec3fdc5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1147\u20131157. doi:10.1145/3539618.3591732 [8]Yitong Ji, Aixin Sun, Jie Zhang, and Chenliang Li. 2023. A critical study on data leakage in recommender system offline evaluation. ACM Transactions on Information Systems 41, 3 (2023), 1\u201327. doi:10.1145/3569930 [9]Wei Jin, Haitao Mao, Zheng Li, Haoming Jiang, Chen Luo, Hongzhi Wen, Haoyu Han, Hanqing Lu, Zhengyang Wang, Ruirui Li, et al .2023. Amazon-m2: A multilingual multi-locale shopping session dataset for recommendation and text generation. Advances in Neural Information Processing Systems 36 (2023), 8006\u2013 8026. https://dl.acm.org/doi/10.5555/3666122.3666473 [10] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom- mendation. In 2018 IEEE international conference on data mining (ICDM) . IEEE, 197\u2013206. doi:10.1109/ICDM.2018.00035 [11] Anton Klenitskiy and Alexey Vasilev. 2023. Turning dross into gold loss: is bert4rec really better than sasrec?. In Proceedings of the 17th ACM Conference on Recommender Systems . 1120\u20131125. doi:10.1145/3604915.3610644 [12] Anton Klenitskiy, Anna Volodkevich, Anton Pembek, and Alexey Vasilev. 2024. Does it look sequential? an analysis of datasets for evaluation of sequential recommendations. In Proceedings of the 18th ACM Conference on Recommender Systems . 1067\u20131072. doi:10.1145/3640457.3688195 [13] Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and Julian McAuley. 2023. Text is all you need: Learning language representations for se- quential recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 1258\u20131267. doi:10.1145/3580305.3599519 [14] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes. In Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval . 43\u201352. doi:10.1145/2766462.2767755 [15] Walid Shalaby, Sejoon Oh, Amir Afsharinejad, Srijan Kumar, and Xiquan Cui. 2022. M2TRec: Metadata-aware Multi-task Transformer for Large-scale and Cold-start free Session-based Recommendations. In Proceedings of the 16th ACM Conference on Recommender Systems . 573\u2013578. doi:10.1145/3523227.3551477 [16] Valeriy Shevchenko, Nikita Belousov, Alexey Vasilev, Vladimir Zholobov, Artyom Sosedka, Natalia Semenova, Anna Volodkevich, Andrey Savchenko, and Alexey Zaytsev. 2024. From Variability to Stability: Advancing RecSys Benchmarking Practices. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Dis- covery and Data Mining (Barcelona, Spain) (KDD \u201924) . Association for Computing Machinery, New York, NY, USA, 5701\u20135712. doi:10.1145/3637528.3671655 [17] Aixin Sun. 2023. Take a fresh look at recommender systems from an evaluation standpoint.", "mimetype": "text/plain", "start_char_idx": 27292, "end_char_idx": 30075, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a3c125e6-af0b-4556-bac8-f4fcc93a3d65": {"__data__": {"id_": "a3c125e6-af0b-4556-bac8-f4fcc93a3d65", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ff5b4e40-acf6-4130-98f5-b0e1a580c413", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "bd13ab658ecdb81ee75b5a91049eb577735378458b2f26799e3d7c5352d20f36", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8aa6d737-eb01-421e-896c-5969cfb6601b", "node_type": "1", "metadata": {}, "hash": "e23811d8a2794fac2c73d8738b749c20f66efa875f99976294052feb12ff9360", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Take a fresh look at recommender systems from an evaluation standpoint. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 2629\u20132638. doi:10.1145/ 3539618.3591931 [18] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional en- coder representations from transformer. In Proceedings of the 28th ACM in- ternational conference on information and knowledge management . 1441\u20131450. doi:10.1145/3357384.3357895 [19] Zhu Sun, Di Yu, Hui Fang, Jie Yang, Xinghua Qu, Jie Zhang, and Cong Geng. 2020. Are we evaluating rigorously? benchmarking recommendation for reproducible evaluation and fair comparison. In Proceedings of the 14th ACM Conference on Recommender Systems . 23\u201332. doi:10.1145/3383313.3412489 [20] Yan-Martin Tamm and Anna Aljanaki. 2024. Comparative Analysis of Pretrained Audio Representations in Music Recommender Systems. In Proceedings of the 18th ACM Conference on Recommender Systems . 934\u2013938. doi:10.1145/3640457.3688172 [21] Aaron Van den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep content-based music recommendation. Advances in neural information processing systems 26 (2013). https://dl.acm.org/doi/10.5555/2999792.2999907 [22] Alexey Vasilev, Anna Volodkevich, Denis Kulandin, Tatiana Bysheva, and Anton Klenitskiy. 2024. RePlay: a Recommendation Framework for Experimentation and Production Use. In Proceedings of the 18th ACM Conference on Recommender Systems . 1191\u20131194. doi:10.1145/3640457.3691701 [23] Maksims Volkovs, Guangwei Yu, and Tomi Poutanen. 2017. Dropoutnet: Ad- dressing cold start in recommender systems. Advances in neural information processing systems 30 (2017). https://dl.acm.org/doi/10.5555/3295222.3295249 [24] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. 2022. Text Embeddings by Weakly-Supervised Contrastive Pre-training. arXiv preprint  (2022). doi:10.48550/ arXiv.2212.03533 [25] Shiyu Wang, Hao Ding, Yupeng Gu, Sergul Aydore, Kousha Kalantari, and Branislav Kveton. 2024. Language-Model Prior Overcomes Cold-Start Items. arXiv preprint  (2024). doi:10.48550/arXiv.2411.09065 [26] Yinwei Wei, Xiang Wang, Qi Li, Liqiang Nie, Yan Li, Xuanping Li, and Tat-Seng Chua. 2021. Contrastive learning for cold-start recommendation. In Proceedings of the 29th ACM international conference on multimedia . 5382\u20135390. doi:10.1145/ 3474085.3475665 [27] Yongchun Zhu, Ruobing Xie, Fuzhen Zhuang, Kaikai Ge, Ying Sun, Xu Zhang, Leyu Lin, and Juan Cao. 2021. Learning to warm up cold item embeddings for cold- start recommendation with meta scaling and shifting networks. In Proceedingsof the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1167\u20131176.", "mimetype": "text/plain", "start_char_idx": 29998, "end_char_idx": 32866, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8aa6d737-eb01-421e-896c-5969cfb6601b": {"__data__": {"id_": "8aa6d737-eb01-421e-896c-5969cfb6601b", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce000b18-e86a-4418-8240-8b7779fb0411", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "f80346c3c2a7030b8d1e0d713dda67446cf8c7bcfc2e525597ddad5427bb49eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a3c125e6-af0b-4556-bac8-f4fcc93a3d65", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv"}, "hash": "8df112faa9ae99afce5d1bc5da5763b56aa3e9e9c4b0b800c570732414ec794f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1167\u20131176. doi:10.1145/3404835.", "mimetype": "text/plain", "start_char_idx": 32856, "end_char_idx": 32887, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a01fa895-5f83-46af-9fc3-bbd26f899a45": {"__data__": {"id_": "a01fa895-5f83-46af-9fc3-bbd26f899a45", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba7060b2-c1c4-48c8-967f-acb5a5e228f5", "node_type": "1", "metadata": {}, "hash": "b7349f87f3d700f66aa1e7065e96673c221e7856d06c4abd2725230bf1d673df", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "f67a7758-7358-4539-828e-a06cc05e491d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "88a6d31aada36c458cc53d30aabaeabf08eb6485425eb1fbcc5ee51703e120b2", "class_name": "RelatedNodeInfo"}, {"node_id": "d7d3a8d2-696e-44de-9b80-a9a04b798420", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2d451399d92c33fab9b1ba921255e5f0887a6a166de20fe6b2c5ab58118bf83d", "class_name": "RelatedNodeInfo"}, {"node_id": "72ca9d2d-0c71-4ccb-bfe0-7db20c790544", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b00509312f845fd034ad685ece1960194f0b455bf2b33492166e187007d05ed1", "class_name": "RelatedNodeInfo"}, {"node_id": "57b31622-1557-422e-bbd7-e9e6ea16b735", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "82682353a42c9b1cd18053fcd67eccf7355117921394fda5571fe241deb30e4e", "class_name": "RelatedNodeInfo"}, {"node_id": "1254c435-fbf0-4649-a7d6-f158fc8b1213", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9004dfa0055c47bd2ecdd199f71ddc30729ea61d2b65b3f24e73182f56fa69dd", "class_name": "RelatedNodeInfo"}, {"node_id": "e75d4856-4cdb-4b2f-b492-784e59799624", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "71e94518331b10bd16335e1d1de7cc6795f72e7cc7069a9ca321ba7505dc0dee", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "TITLE: Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts\n\nAUTHORS: Sang-Woo Lee, Sohee Yang, Donghyun Kwak, Noah Y. Siegel\n\nABSTRACT: Many recent papers have studied the development of superforecaster-level\nevent forecasting LLMs. While methodological problems with early studies cast\ndoubt on the use of LLMs for event forecasting, recent studies with improved\nevaluation methods have shown that state-of-the-art LLMs are gradually reaching\nsuperforecaster-level performance, and reinforcement learning has also been\nreported to improve future forecasting. Additionally, the unprecedented success\nof recent reasoning models and Deep Research-style models suggests that\ntechnology capable of greatly improving forecasting performance has been\ndeveloped. Therefore, based on these positive recent trends, we argue that the\ntime is ripe for research on large-scale training of superforecaster-level\nevent forecasting LLMs. We discuss two key research directions: training\nmethods and data acquisition. For training, we first introduce three\ndifficulties of LLM-based event forecasting training: noisiness-sparsity,\nknowledge cut-off, an\n\nKEY DEFINITIONS: LLMs: gradually reaching superforecaster-level performance, and reinforcement learning has also been reported to improve future forecasting | time: ripe for research on large-scale training of superforecaster-level event forecasting LLMs | forecasting: a task of predicting whether specific events will happen in the future, or what the probability of occurrence is, based on information up to a certain point in time (Jin et al | Today: December 31st,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1679, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ba7060b2-c1c4-48c8-967f-acb5a5e228f5": {"__data__": {"id_": "ba7060b2-c1c4-48c8-967f-acb5a5e228f5", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a01fa895-5f83-46af-9fc3-bbd26f899a45", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4b2b0be90cea560fc5366830d8c8f3e59bff0bd1c2513d85886ec90f86beae8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "node_type": "1", "metadata": {}, "hash": "19031f3a3ddc27a799f4981f58e383dec4f6c7156fe1d96cb8f221e44a1e4891", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "1560e316-0278-4e30-b751-ec24ef3deac7", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d7f7c4005ffd0f6aaa374187544e35ab808151f0706f0ab1bf3b47dfec64559c", "class_name": "RelatedNodeInfo"}, {"node_id": "05c7e783-1c8e-46fa-89b0-e577ecc3ba69", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3a87e5004e79c88ec51809b128c2da13810f66d0fc9b52487984f418c2771661", "class_name": "RelatedNodeInfo"}, {"node_id": "7e983058-8495-42d0-b7ea-72bbc288957b", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "88585bcc47a0946cacd4a9d49feb38cb43c2fb0db2bdb517919771afe2421f21", "class_name": "RelatedNodeInfo"}, {"node_id": "b5edf441-b4e6-4d88-b1ab-b6be5e840ff2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a9b5e6a1ce93832eb353d6dcc0ea7dd38730eb5b33272682e4fcdbdaa35429e9", "class_name": "RelatedNodeInfo"}, {"node_id": "5d8327e8-0269-48cc-82ba-d0a56cba74d6", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3e955686c68769fd03436f3fe35c51a0023f21acadd380b75bbda229de35f70e", "class_name": "RelatedNodeInfo"}, {"node_id": "b1972c46-76a6-4b05-ac48-9fa83e86489e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "46008471cc6d2c6645013c17323fe2a0e854843227ba898b8cdc0764ad8b78f6", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "or what the probability of occurrence is, based on information up to a certain point in time (Jin et al | Today: December 31st, 2023 | approach: Retrieve-Augmented Generation (RAG) (Lewis et al | information: first retrieved, followed by reasoning processes that derive the final answer (Halawi et al | field: to make LLMs perform as well as top-level human forecasting experts or collective intelligence of general experts, that is, to make models reach superforecaster-level (Tetlock and Gardner, 2016; Karger et al | forecasting: steadily improving with generational advances, and they are getting closer to superforecaster-level | conditions: now favorable for research on large-scale training of event forecasting LLMs to approach superforecaster-level performance | First: the noisiness and sparsity problem, which is the difficulty in learning due to inherent uncertainty in event forecasting outcomes and the sparsity of similar events\n\nFULL TEXT: Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts Sang-Woo Lee\u2217sangwoolee.cs@gmail.com Independent Sohee Yang\u2020soheeyang@google.com Google Deepmind Donghyun Kwak donghyun.kwak@navercorp.com NAVER Cloud Noah Y. Siegel\u2020siegeln@google.com Google Deepmind Abstract Many recent papers have studied the development of superforecaster-level event forecasting LLMs.", "mimetype": "text/plain", "start_char_idx": 1552, "end_char_idx": 2936, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3ac06a99-d62a-4b14-8057-5ad071c9a8b2": {"__data__": {"id_": "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba7060b2-c1c4-48c8-967f-acb5a5e228f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "38ea6b49c1bc4cc5b37ecf5ddd1443f346af8396c9af8cf5c48163af04390af3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b203616-3a2a-4b73-b264-44ae27413c5a", "node_type": "1", "metadata": {}, "hash": "98603cb9856c773787a31271693ffc41c67b4d1066bc476fa5282f01015c2987", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "6d937604-5db8-47cc-a662-2b0aa94f3a68", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a97c7ca115db38061667e879b012dcbff60dea9de266cede1194addc0809a0e9", "class_name": "RelatedNodeInfo"}, {"node_id": "fef62cd4-9e15-440e-b235-9327c4f3726d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0106252a0accd07629ddba696a6b0c7ce0a549dc3f34317150fe2d700833fadd", "class_name": "RelatedNodeInfo"}, {"node_id": "cbf9cf49-855f-454b-822f-a0c688c91f33", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a2899245e4a5e6120a17f8b565c7db0f9cfc24d0e60429bfa618271ca59897e4", "class_name": "RelatedNodeInfo"}, {"node_id": "ef0843ca-0e39-44c4-8f16-d294697f54e7", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dbe7a19709bc97ca3444b745a741f985f204914edf14ba82f154ee2c0a1d97f5", "class_name": "RelatedNodeInfo"}, {"node_id": "b2aa2894-fbb5-490f-9cc2-b42016adc155", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7cdcef9676e81ce22c12bbc06142e537cd49654f23e5e861fdcb8ac99420bcb4", "class_name": "RelatedNodeInfo"}, {"node_id": "d8af5298-de5f-499a-9e8b-9df15181ae20", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "050f3996c98d29413660fc6096cc5a8b1831ccc8cfa433375d0dfe9d560ac2b6", "class_name": "RelatedNodeInfo"}, {"node_id": "ff9fe6e1-300e-4238-b879-c00fae44e746", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "cf0c8b2aba191692ef12c0f793598c74969633e8bbbcfd7a6f7ed904cdca0093", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "kwak@navercorp.com NAVER Cloud Noah Y. Siegel\u2020siegeln@google.com Google Deepmind Abstract Many recent papers have studied the development of superforecaster-level event forecasting LLMs. While methodological problems with early studies cast doubt on the use of LLMs for event forecasting, recent studies with improved evaluation methods have shown that state-of- the-art LLMs are gradually reaching superforecaster-level performance, and reinforcement learning has also been reported to improve future forecasting. Additionally, the unprecedented success of recent reasoning models and Deep Research-style models suggests that technology capable of greatly improving forecasting performance has been developed. Therefore, based on these positive recent trends, we argue that the time is ripe for research on large-scale training of superforecaster-level event forecasting LLMs. We discuss two key research directions: training methods and data acquisition. For training, we first introduce three difficulties of LLM-based event forecasting training: noisiness-sparsity, knowledge cut-off, and simple reward structure problems. Then, we present related ideas to mitigate these problems: hypothetical event Bayesian networks, utilizing poorly-recalled and counterfactual events, and auxiliary reward signals. For data, we propose aggressive use of market, public, and crawling datasets to enable large-scale training and evaluation. Finally, we explain how these technical advances could enable AI to provide predictive intelligence to society in broader areas. This position paper presents promising specific paths and considerations for getting closer to superforecaster-level AI technology, aiming to call for researchers\u2019 interest in these directions.", "mimetype": "text/plain", "start_char_idx": 2750, "end_char_idx": 4503, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0b203616-3a2a-4b73-b264-44ae27413c5a": {"__data__": {"id_": "0b203616-3a2a-4b73-b264-44ae27413c5a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5b494e927064a8d15ad971603a6ab9cec2ca361819f5d5af8da5fa7b499fdabe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "518bbff6-f700-466e-ae5e-151ca9c45c9a", "node_type": "1", "metadata": {}, "hash": "d61dffb11f32304cef24a6df00ab8392f89f11b2e340f161aa82c1070af149ad", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "e8a717d8-1720-4376-956f-aed5bc62ae9c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2461cfaaba0ba1e584775d3134efa93f9578b3d568090c17479f62e4dba1d450", "class_name": "RelatedNodeInfo"}, {"node_id": "887ef03b-8d4d-463f-a102-2c7f116ace6a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "24d168562093b0c7e632e5e969db0321afc9b48d61666e39fef836a235bba04a", "class_name": "RelatedNodeInfo"}, {"node_id": "cc5a5b22-3ae4-45ad-9cc9-f870fd194fe8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f24a1665d6e163188791f06a80f446f5cb9c381118a7640713b7e8f97d99b1e9", "class_name": "RelatedNodeInfo"}, {"node_id": "5b2a83f0-a1cc-48ed-8191-6eb8d509bd8d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "72da7a9cb63c4562902c3e6f6d4c258942e33ff592f97800a16e41125e2a691f", "class_name": "RelatedNodeInfo"}, {"node_id": "ef6402f4-f7a3-4388-956f-5735811f42b8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "1c86bbc3ed616cb02404ebf762e5f0306d70fb2423c17ccdbdd97017ecb45444", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This position paper presents promising specific paths and considerations for getting closer to superforecaster-level AI technology, aiming to call for researchers\u2019 interest in these directions. 1 Introduction Future event forecasting is a task of predicting whether specific events will happen in the future, or what the probability of occurrence is, based on information up to a certain point in time (Jin et al., 2021; Zou et al., 2022; Halawi et al., 2024). For example, consider the question: \u201cToday is December 31st, 2023. Will SpaceX successfully complete an orbital flight\u2014reaching space and circling the Earth\u2014before June 2024?\u201d When solving this task with Large Language Models (LLMs), the widely used approach is Retrieve-Augmented Generation (RAG) (Lewis et al., 2020), whereby relevant news articles and related information are first retrieved, followed by reasoning processes that derive the final answer (Halawi et al., 2024). An important goal \u2217corresponding author \u2020Participated only in an advisory capacity. 1v1 [cs.LG] 25 Jul 2025in the future event forecasting field is to make LLMs perform as well as top-level human forecasting experts or collective intelligence of general experts, that is, to make models reach superforecaster-level (Tetlock and Gardner, 2016; Karger et al., 2025; Liptay, 2024a).", "mimetype": "text/plain", "start_char_idx": 4310, "end_char_idx": 5630, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "518bbff6-f700-466e-ae5e-151ca9c45c9a": {"__data__": {"id_": "518bbff6-f700-466e-ae5e-151ca9c45c9a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b203616-3a2a-4b73-b264-44ae27413c5a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "41787e373179d7800531033b26bff64a7a89bded72b3506316d99c3b7d9d38b9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f8949761-d7ef-452b-b6d0-0d1f4c571764", "node_type": "1", "metadata": {}, "hash": "23d0facbbda59a1dd2bccd9771f5688d1d54d6dc1f8d26bc1d9d5ecb430e736f", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "fef29f8b-d5d5-4f02-9fe9-9e0ac18bddaf", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "65f6da5ccee4903767835c56af0259becea69cd792ce7e3d03328686a4cb8718", "class_name": "RelatedNodeInfo"}, {"node_id": "e896a32e-f3b1-4a3d-9e7e-b44a246a9069", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "848696887db688d5d1aba866355c3220832ece5bb83373203840fe0543866a85", "class_name": "RelatedNodeInfo"}, {"node_id": "6838372f-1425-4c57-aa9f-c3950828e2c8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c3c6203dc10d5cf3a08c2133e5a7ad2d936b06ec9f90a47265cf16caa3487bde", "class_name": "RelatedNodeInfo"}, {"node_id": "e2477c6f-c898-452f-966a-287b2097bd04", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "285c0daf9e10bf8afa0212fa4bd3b7c177b9ef4134fa1dbf44f739426fdfec1c", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since ChatGPT was released (OpenAI, 2022), numerous studies have evaluated LLMs\u2019 event forecasting capabilities and compared them with human performance (Schoenegger et al., 2024; Hsieh et al., 2024). Initially, optimistic reports were shared that LLMs showed performance approaching superforecaster-level (Phan et al., 2024). However, subsequent analyses identified methodological issues including insufficient statistical significance, information leakage from data preceding the knowledge cut-off date, and contamination from post-resolution documents in search results, leading to criticism that LLMs\u2019 abilities were overestimated (Lopez-Lira et al., 2025; Bosse et al., 2024). These criticisms resulted in skepticism within the event forecasting community (Paleka et al., 2025a; Matthews, 2025). However, we argue that recent studies provide positive signals for event forecasting. A recent study using more rigorous evaluation methods (Karger et al., 2025) reports that LLM performance in event forecasting is steadily improving with generational advances, and they are getting closer to superforecaster-level. Additionally, recent reasoning models like OpenAI o1 and o3 (OpenAI, 2024; 2025a) have shown improved performance compared to previous models (Hickman, 2025), and performance improvements through reinforcement learning (RL) have also been reported (Turtel et al., 2025a;b).", "mimetype": "text/plain", "start_char_idx": 5631, "end_char_idx": 7021, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f8949761-d7ef-452b-b6d0-0d1f4c571764": {"__data__": {"id_": "f8949761-d7ef-452b-b6d0-0d1f4c571764", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "518bbff6-f700-466e-ae5e-151ca9c45c9a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e5e58102d8e28b7e262191de99596748c0a564576d0d354712a97ae43d479c5d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5815e249-b092-433f-be95-f8cbe0b3daab", "node_type": "1", "metadata": {}, "hash": "e55c0e3e82db6e2957780f7f36474f6b33bc7acdf8a14d9113e7d47149c6e947", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "f7afb3af-75f4-40bf-9bf6-97c2be306db0", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e7a3f699d53e2a0812e4e50f0bac321aa5e95e53e72f3dc697b72bc934fd37d9", "class_name": "RelatedNodeInfo"}, {"node_id": "81a9dff0-d2c8-4e19-b34a-ea54ec89aff4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5c8f562cb112c7a7c2ac6ff0cdc9fdaa37d1d8424bb1c983928a32c45ef25691", "class_name": "RelatedNodeInfo"}, {"node_id": "1342e88d-46cb-41fb-a360-5c984b7e4b07", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f760d83cc0de3944ac0291bf999949f50fac43ad8f7707b8c95bcd44d02cccdf", "class_name": "RelatedNodeInfo"}, {"node_id": "98c4dc26-0fbe-4670-b1b5-d9353b1b19f6", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6a831be6164f74e37d36c2bf049daf35a0bd9d8b5698e94720acdeebc6a5fff3", "class_name": "RelatedNodeInfo"}, {"node_id": "58e79da7-7039-4fe9-93c8-9a4d2119cd19", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0fe7affb86c9539f968f62c89d0e4570e5c7f8f1ec20afac8b9403cfa1199a5d", "class_name": "RelatedNodeInfo"}, {"node_id": "d67f47ce-3ca9-4035-95fd-50d76bc5d27a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7bddf6a66d6a0ca8d9c810a13d39940d234c7187e2d661a0438752533d1916d3", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Furthermore, the unprecedented success of reasoning model with tool-use like OpenAI\u2019s and Gemini\u2019s Deep Research (Citron, 2024; OpenAI, 2025b; Anthropic, 2025) suggests that technology capable of greatly improving forecasting performance has been developed. Based on these recent positive trends, we argue that conditions are now favorable for research on large-scale training of event forecasting LLMs to approach superforecaster-level performance. This paper presents two key research directions for this purpose: training methodology (Section 4) and large-scale data acquisition (Section 5). For training methodology, we first introduce three unique difficulties in LLM-based event forecasting training. First is the noisiness and sparsity problem, which is the difficulty in learning due to inherent uncertainty in event forecasting outcomes and the sparsity of similar events. Second is the knowledge cut-off problem, where it is difficult to train or evaluate event forecasting questions about knowledge that LLMs already know internally, greatly limiting usable training data. Third is the simple reward structure problem, where models can obtain rewards more easily than in other RL tasks without developing proper reasoning capabilities, hindering actual prediction ability improvement. To mitigate these problems, we present several solutions. We provide theoretical grounds for various training label assignment strategies through hypothetical event Bayesian network modeling, introduce methods of utilizing poorly-recalled data and generating counterfactual events to tackle the knowledge cut-off problem, and discuss ways to solve the simple reward structure problem through auxiliary reward signals and subquestions.", "mimetype": "text/plain", "start_char_idx": 7022, "end_char_idx": 8752, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5815e249-b092-433f-be95-f8cbe0b3daab": {"__data__": {"id_": "5815e249-b092-433f-be95-f8cbe0b3daab", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f8949761-d7ef-452b-b6d0-0d1f4c571764", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "98d994daf535408e3d99104325e3503b320f71b2a86dd2d06592422be072bc09", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b1166cfc-d3a5-4815-acd0-2407106e63f1", "node_type": "1", "metadata": {}, "hash": "763beb62ff64746d0a652d76e6106d4f68fb9ceea8d0fedaaabe8bc1a42702ad", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "5aefaae7-5438-4d76-aa50-cea746c00f8c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7602e701bfea976f51cd3a4685779bbddfa9a609bd4344fc351b268f67154ac0", "class_name": "RelatedNodeInfo"}, {"node_id": "bb510eef-d5a7-4b09-9fc6-e91155bceef7", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "4d1249f988f2a6feabfa6fcdf3a4c340324e06455b06f00c4eecd31e2f9c6703", "class_name": "RelatedNodeInfo"}, {"node_id": "e939d74a-1846-4c73-8f6b-9fb5a08e23d5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "95e9b65360397e4f04539e3798d0a94aa16b66131bb61a1b44028de67ded15a1", "class_name": "RelatedNodeInfo"}, {"node_id": "a898fed2-472f-49f3-99ac-8fe6cc78117c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c0d0f445b51d2b244d5983ceaa4442a146705099a136cf298d330c0bd9deda81", "class_name": "RelatedNodeInfo"}, {"node_id": "1793f7cf-183e-4a98-8174-074bc48152bf", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "4302eb7b4f46afa655e984fcc19c14de51640b454acd854a6fe0755e905e083d", "class_name": "RelatedNodeInfo"}, {"node_id": "f9b28e53-7b26-4e01-8e4a-45beb13cc969", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5b1ae4190c5b104e241afb1eef21366fc5464940b2a25c611bfeacff6dde737d", "class_name": "RelatedNodeInfo"}, {"node_id": "fe584ebf-1e0d-4439-980f-d6d31f5bfb96", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "20bec196db9200fdae1edfaedcfd8b83e5cd91ee5a86fcfc409ab99e3d27702b", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For large-scale data acquisition, we point out that previous research mainly relied on prediction markets and propose aggressive use of three data categories: (1) market dataset - data available from prediction markets like Polymarket and Metaculus, (2) public dataset - structured data available from public databases like GDP and economic indicators, and (3) crawling dataset - unstructured data collected and processed from the web like news. Using these diverse data sources will enable large-scale training and fast evaluation cycles, promoting model performance improvement and development of generalized event forecasting capabilities. Finally, we discuss the broad impacts these technical advances could have on society (Section 6). We examine promising applications, including expanding the scope of AI forecasting, AI-assisted trading systems, future simulation capabilities, and integrating probabilistic reasoning capabilities into general AI agents and AI scientists. We also analyze key challenges, including assessing prediction confidence, user interface design, self-fulfilling prediction effects, and vulnerability to malicious attacks. This position paper provides a comprehensive review of event forecasting with LLMs, arguing that recent advances in LLM capabilities have created favorable conditions for large-scale training toward superforecaster- level AI systems. We identify and formalize the unique training challenges specific to event forecasting, propose methodological solutions to address these challenges, and develop strategies for performance enhancement 2Term Example Definition Question Today is Dec 12, 2023. Will SpaceX successfully launch and return a space- craft from Earth orbit by 2024 June?The question which asks about whether a specific event will happen by a certain time. Question date Dec 12, 2023 The date that the question is asked. LLM must utilize the knowledge before this date to answer the question.", "mimetype": "text/plain", "start_char_idx": 8753, "end_char_idx": 10709, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b1166cfc-d3a5-4815-acd0-2407106e63f1": {"__data__": {"id_": "b1166cfc-d3a5-4815-acd0-2407106e63f1", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5815e249-b092-433f-be95-f8cbe0b3daab", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8b696f514b7a1d29ad8bf9f0d828a9584a96002f79c90366c28812018dea00d9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5077d32d-8eb7-4a7e-b626-3736f5ea976e", "node_type": "1", "metadata": {}, "hash": "eeb5a8eab66e01ca54bb4dfca5c3ad29c83f0681a87459db88dafc109e7eace5", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "cff87716-9c31-4efa-977a-57da71ea9caf", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "320b7f11931c142e12229f2b17ede321f04e4372edc0b82bdc3a4d82f564a8ad", "class_name": "RelatedNodeInfo"}, {"node_id": "82aece2a-57f3-40a3-b965-c1a79180d271", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "61aa04ab490d2a2a75c93ba9c1e888b7779605621de177f27c1f7825b4883eb4", "class_name": "RelatedNodeInfo"}, {"node_id": "c0daad12-ed76-45a9-b2ce-079e4927cd52", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8d9c5f52f71a3349b98c33fb285627526ff277dc3bf820d455b227d122d92a61", "class_name": "RelatedNodeInfo"}, {"node_id": "d88747cc-f81d-4571-94b7-4d32f89e6187", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d18b1d06eca8d17779d5f94af75450a50c29fcfbaed01dd148313c6a8198a42c", "class_name": "RelatedNodeInfo"}, {"node_id": "d1b99fcd-e0b6-4bc4-b874-e503548a1b2a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b59826016d8059c456e86e1b4e9306c04fdabd279429f7b900ddec5c7a14f548", "class_name": "RelatedNodeInfo"}, {"node_id": "134ca2a5-6721-444f-8735-3fcbd4279912", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "fc09ae50c94383a73719bf17a81164ef24e4ce58561f5eee6e715b46bd2b8901", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Question date Dec 12, 2023 The date that the question is asked. LLM must utilize the knowledge before this date to answer the question. Therefore, this must be the \u201cevent knowledge cut-off date\u201d for the LLM. Resolution date Mar 14, 2024 The date that the outcome of the event is determined. In other words, the date that the outcome is resolved. Outcome Yes The outcome of the event known and finalized from the resolution date. It remains unknown before the resolution date, leaving the outcome unresolved. LLM knowledge cut-off dateNov 30, 2023 The latest date of the knowledge an LLM is trained on. Table 1: Examples and explanations of major terms. The event example is referenced from (Polymarket, 2023). through large-scale dataset expansion. In addition, we conduct a systematic analysis of the societal implications of event forecasting LLMs, examining both their potential for widespread adoption and associated risks. 2 Background This section provides background on event forecasting using established terminology in the field (Table 1). 2.1 Prediction market A prediction market is a platform where users bet on whether specific events will occur. Each market within prediction market platforms corresponds to a specific event and provides market predictions for outcomes at different time periods for that event (Pratt et al., 2024). Market predictions represent the aggregated probability estimates from participants regarding whether a specific event will occur before resolution. Representative prediction markets include Polymarket, Metaculus, and Manifold Markets. Polymarket uses real money, whereas Metaculus and Manifold Markets use virtual currency.", "mimetype": "text/plain", "start_char_idx": 10574, "end_char_idx": 12245, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5077d32d-8eb7-4a7e-b626-3736f5ea976e": {"__data__": {"id_": "5077d32d-8eb7-4a7e-b626-3736f5ea976e", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1166cfc-d3a5-4815-acd0-2407106e63f1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "beb2cbd0557b911ff26c6db080858ea162abc3ee5f5d5b6f53f8c1b70c0d0807", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8", "node_type": "1", "metadata": {}, "hash": "d674ec98aef93cc2bc7d7bcdbb2e602e76b35a283f28c8e9c1e6260f338f54ee", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "c067d04b-7966-4862-9d67-714264a9ba14", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3759bd2df07a1b30ed455b9847c38206d74ff135223a83cfab38be653631b356", "class_name": "RelatedNodeInfo"}, {"node_id": "c6fc1767-9a71-474d-a95d-eec42bfdd67d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "fd5d0ecc3e2be40cb0c21727b32671cd102ced85b34141c30e20d3d0ab00de2c", "class_name": "RelatedNodeInfo"}, {"node_id": "a74a2647-c490-4d09-abaa-43f16952b578", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e2514ceff89c7565236632926d2f41a8b82469f86407d94f7f59f9918347e468", "class_name": "RelatedNodeInfo"}, {"node_id": "61f3dbfa-f6f5-4bfb-bcd4-767a0322452a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dc396d3e9914987108b13dee75e566e3871d24f10cadf4e2a1ec4025e9741be5", "class_name": "RelatedNodeInfo"}, {"node_id": "659aa38f-8022-4a40-9cb2-48e544b37d93", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f8918d8a65cf861c781f393cca2f8e6853384ee1579d05ffe2d5395f9d756226", "class_name": "RelatedNodeInfo"}, {"node_id": "17410a37-262c-4bb4-ac80-3131cf1cefbe", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7912e3a51174466ad34fca7bc7d971b7e26fc71f9176392c202577529b4d4a9b", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Representative prediction markets include Polymarket, Metaculus, and Manifold Markets. Polymarket uses real money, whereas Metaculus and Manifold Markets use virtual currency. These platforms democratize future knowledge by providing reliable probability estimates for significant global events through various mechanisms (Williams, 2025a; Chen, 2022). For example, Polymarket achieved recognition for delivering more accurate predictions for the 2024 U.S. presidential election compared to expert analysts and political forecasting platforms (Jones, 2024). Prediction markets play a significant role in the field of event forecasting AI. They are widely used as sources of both training and evaluation data for developing such systems. Moreover, matching the forecasting performance of prediction markets and scaling it to a wider range of prediction problems is one of the key motivations for event forecasting AI research. 2.2 Superforecaster Superforecaster (Tetlock and Gardner, 2016) is a term referring to top forecasters who have exceptional talent in prediction compared to the general public. The criteria for superforecaster-level vary slightly across different literature and experimental settings, but recent studies define it as the prediction level of collective intelligence of forecasting experts (Karger et al., 2025; Liptay, 2024a). Forecasting experts refer to professionals hired as forecasters, while collective intelligence represents the aggregated predictions from multiple experts. 3Karger et al. (2025) asked the general public and forecasting experts a total of 200 questions, with randomly selected 20 questions each, and used their combined answers for comparison with models.", "mimetype": "text/plain", "start_char_idx": 12070, "end_char_idx": 13776, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8": {"__data__": {"id_": "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5077d32d-8eb7-4a7e-b626-3736f5ea976e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c96d5fdb583a0a6829c8b79ec59fc5f3244b3a3b6999ca7e1d7793a93c48e6d4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a3c375a8-9dc5-4a67-b9af-514b1f764e59", "node_type": "1", "metadata": {}, "hash": "b0705f7cdb8d8c446eb1c043ab24bae6941a17b07b9f399117a9048b3a07cbb6", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "6fca940a-7f41-4c2d-a5d3-f69b3d1ed098", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "4ef0f02cf03d44f88ee9604063141eb2887cb67464d86266c02b1b54f4268a1b", "class_name": "RelatedNodeInfo"}, {"node_id": "6fec6105-9b7d-470c-a6ce-36ceea0d2491", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6d9ae127194a230d8d54049069940d4b4cb88fc83c156fb1b0b6542904c3a02a", "class_name": "RelatedNodeInfo"}, {"node_id": "91c5d9fe-99e9-4d58-99df-b4bb9029619e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e743f7d7f77f874c4b30600bdbf5f5d9751b98dc53e0aa6b9965529e139ec683", "class_name": "RelatedNodeInfo"}, {"node_id": "4c8596f3-16b6-4ab3-b9da-f34b710cd6e9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a06f2d05afc3b9c1558d2fca7ea553d86c32f8155e1dcbd7ade1616f5c22eff7", "class_name": "RelatedNodeInfo"}, {"node_id": "10d56503-07e6-427f-ab7c-06fe148afc35", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ef09b5927e9f81b3b0228a322af71b61429f675e3047dd81292c8da94946a1e1", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3Karger et al. (2025) asked the general public and forecasting experts a total of 200 questions, with randomly selected 20 questions each, and used their combined answers for comparison with models. Metaculus AI Benchmarking (Liptay, 2024a; Hickman, 2025) hosted by Metaculus is also an active challenge in this field. In this challenge, the performance of AI systems is compared using approximately 300 questions. Furthermore, the top-performing AI systems from previous competitions are combined into an ensemble, which is then evaluated against groups of approximately 10 expert forecasters using around 100 questions to assess the performance gap. This definition clarifies that, contrary to the common first impression of the term \u201csuperforecaster,\u201d superforecaster-level AI does not mean a prophet who predicts everything perfectly. Superforecaster-level simply means the top level of human expert forecasters or the collective intelligence level of expert forecasters. 2.3 Benchmark Static benchmark ForecastQA (Jin et al., 2021), AutoCastQA (Zou et al., 2022), and AutoCast++ (Yan et al., 2024) are early major event forecasting benchmark studies. These benchmarks can be classified as static benchmarks because they consist of data from specific periods in the past that have already been resolved (Ye et al., 2024). The main challenge of static benchmarks is that data contamination can easily occur due to the nature of future prediction. If an LLM is developed in 2024 but the evaluation data contains questions about events that occurred in 2023, it cannot be used for evaluation because it may already be contaminated through training.", "mimetype": "text/plain", "start_char_idx": 13578, "end_char_idx": 15227, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a3c375a8-9dc5-4a67-b9af-514b1f764e59": {"__data__": {"id_": "a3c375a8-9dc5-4a67-b9af-514b1f764e59", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07a199dede03ee51c8f457ac0b0d1d0701896839c2e0bf5d17ecbb3db8e37f9f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2c71a4ba-fb61-4962-bc10-e322980ec04a", "node_type": "1", "metadata": {}, "hash": "b3a8aa9d8fabf79f9f52366622602c3441d669c27437dfc5d12f996ab0d43136", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "89bb33ac-a79e-44c8-8f66-e0df0fa73c3c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "706aa0113a569b4fa7495c07ad9beebc423d13d34dbf3907aa3a75dda02a7292", "class_name": "RelatedNodeInfo"}, {"node_id": "90b2626b-b05b-4bc3-b0ab-93d0759e23be", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a2f0ee1970db20ef327385b81af98a9b93e41394aad7b1d568e64baf9dd6eb05", "class_name": "RelatedNodeInfo"}, {"node_id": "07ed3ee9-c6a3-4b5c-98ca-b3d9014df619", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "bd3c07df5ba12fad1895a14d0d449b4d5e95c01256d809cd8862196118f6df17", "class_name": "RelatedNodeInfo"}, {"node_id": "07b5a9e0-bf5e-4da4-9dcf-ba10e87175fb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "74aa8f80fcea66755391b63a3636ea8389703548cc67d220520d718a7f8d43d4", "class_name": "RelatedNodeInfo"}, {"node_id": "8fe56c3d-194d-4903-a3ac-371944c5bf77", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "da5f903facc4399a3f66f641d6b15a8e64a5ce137505fc94e055be882409a2d2", "class_name": "RelatedNodeInfo"}, {"node_id": "0b09c21d-c881-40b8-b873-b0e20d7730d9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "1d93c15f4c4f1302e718b9b1d6553b156a8907a99ad3587a6f8883881cdb1c9d", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "If an LLM is developed in 2024 but the evaluation data contains questions about events that occurred in 2023, it cannot be used for evaluation because it may already be contaminated through training. Therefore, static benchmarks soon become outdated and cannot be used to evaluate the latest LLMs. Dynamic benchmark In contrast to static benchmarks, dynamic benchmarks continuously update their question sets and resolution information from the latest databases. Here, models answer unresolved questions posted in the database at specific times, and when these questions are resolved after a certain period, the model receives a score based on the resolution outcome. Since previous static benchmarks created reliability issues related to contamination, dynamic benchmarks are considered a major advancement. Recently, dynamic benchmarks and related challenges continue to be shared (Karger et al., 2025; Paleka et al., 2025b; Liptay, 2024a). Recent dynamic benchmark studies use market data from prediction markets as a key source for performance evaluation. Metric Benchmarks compare the error between the model\u2019s probability predictions and the actual resolved results using various metrics. The Brier score is a commonly used metric. The Brier score is defined as (f\u2212o)2, wheref\u2208[0,1]is the probabilistic forecast and o\u2208{0,1}is the outcome after the event is resolved. Lower Brier scores indicate better performance, and a uniform prediction of 50% creates a Brier score of 0.25 (random baseline). Another metric is the logarithm score, defined as ologf+(1\u2212o)log(1\u2212f). The logarithm score is more sensitive to extreme errors in probability estimates.", "mimetype": "text/plain", "start_char_idx": 15028, "end_char_idx": 16682, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2c71a4ba-fb61-4962-bc10-e322980ec04a": {"__data__": {"id_": "2c71a4ba-fb61-4962-bc10-e322980ec04a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a3c375a8-9dc5-4a67-b9af-514b1f764e59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b416a75a95d5ab7a878a5a8c7be8fe94e99e47be3540518faa1a760f956ba5c0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "node_type": "1", "metadata": {}, "hash": "5136f9a7991fd8d86fc8457fd4e78e94fd73d6e588f320de3fe99a50a6f8466b", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "9d8d8f57-95d1-49c8-87e8-fe37cca7127e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "cfee8399ad9da97766d31f6b1ab225a1b1d4548077dd73e371437f5ef0bb6e1c", "class_name": "RelatedNodeInfo"}, {"node_id": "df241559-7c56-43f4-b0c2-7b44caf4371b", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0c782dab096661294adb7c3347c09230746a95d653ac40d99262317150c0c078", "class_name": "RelatedNodeInfo"}, {"node_id": "2179b319-ddfd-43e5-a6b6-67880b53a055", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7a6b602ba7a82f570a613564625894241257a81a4e05e5d033df2d59bcd9d8f1", "class_name": "RelatedNodeInfo"}, {"node_id": "0886f1ee-01f2-4054-a49d-a30f2462ed9f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9566d7dddd39049c64f056d8d3bbd5d35e8c7b4555dfa093722f593ae7a1e758", "class_name": "RelatedNodeInfo"}, {"node_id": "2c8822af-79f7-435b-bac6-e77a454e835e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d489bb7b068dce10457d62a3ce1e9e31eb195fe8f4b7510b465bab3e1bf98c21", "class_name": "RelatedNodeInfo"}, {"node_id": "9b243eda-64b3-4ebe-890e-e2cf7da7d4fb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "329067631e3a100553e8f64a525be75c8b54a99bde89421e71a60fe04f277927", "class_name": "RelatedNodeInfo"}, {"node_id": "807a94fc-2c07-4fa5-9b7c-f6a16d40b8e1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "465919f2cf792df49a306348b9f2c378e2f8207e934e1d7fb5b2172160210304", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Another metric is the logarithm score, defined as ologf+(1\u2212o)log(1\u2212f). The logarithm score is more sensitive to extreme errors in probability estimates. Expected Calibration Error (ECE) is a metric that measures whether the actual outcome resolution probability of questions the model predicted with probability pis close top. Generally, specific interval bins (e.g., 5%) are set, and the absolute difference between the actual outcome resolution probabilities for prediction data within that range is used as the average metric. The concurrent position paper by Paleka et al. (2025a) addresses the difficulties in event forecasting evaluation and provides detailed explanations of these metrics along with comprehensive comparisons of their limitations. 2.4 Inference Information retrieval Information retrieval plays an important role in event forecasting systems (Hsieh et al., 2024). The study by Halawi et al. (2024) provides foundational research for current event forecasting and information retrieval pipeline design. In this study, they used an appropriate LLM-RAG-based pipeline to significantly improve prediction performance compared to cases without search. First, the LLM generates search queries related to the question, which are then used to conduct news searches with the search period restricted to information available before the question date. Then, the retrieved documents are reranked. Finally, answers are generated based on the organized documents. Additionally, Metaculus (Hickman, 2025) 4now provides an integrated information retrieval system with commercial LLM APIs to support forecasting research and practice.1 In practice, ensuring temporal integrity in document retrieval remains a significant challenge in event forecasting systems, particularly when the question date differs from the current time point.", "mimetype": "text/plain", "start_char_idx": 16530, "end_char_idx": 18371, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8005f7a8-6a58-4018-b2d2-c43d4956a5a4": {"__data__": {"id_": "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c71a4ba-fb61-4962-bc10-e322980ec04a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2ad1b86c194950b028bc32b84461bc144370c0ca62e260bd70c3c237e9f2d2bc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0718afa5-46ea-4eda-8c4d-a57fd276fa0f", "node_type": "1", "metadata": {}, "hash": "af04fe9d21f357743321e483b874a5d66661abdfa1cdb9bd53bd5bfd1b406190", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "bf2a084c-54e7-4747-8e04-f4827636db70", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f670bd161eb1018554eee9fe3d10f1a060133502ff6377ac69d8d3a1a7e5705d", "class_name": "RelatedNodeInfo"}, {"node_id": "fe5f80a4-4584-4cb4-a0f6-c5539025c6bd", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a06572821769489e26ac1a72360b364aed2ba6f1a943fcde6cbce7df1ca63852", "class_name": "RelatedNodeInfo"}, {"node_id": "b94fe5c1-8fa1-43b7-9893-b830fcfab3de", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f57d6f5d50d81df4a7f2b87d539a8130d77cc636c353b8bf633997674a52e073", "class_name": "RelatedNodeInfo"}, {"node_id": "4ac0b80f-b80e-489c-b8de-d9856894aa8c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "fb29a30fdad0798c871a02d52313455e0f1f7dae7e0efde87616cb03ed5329b7", "class_name": "RelatedNodeInfo"}, {"node_id": "f1c38983-8d4e-43fd-ae0c-bf32163cd896", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2b3f66446ee92edb599001f0695059fd0c5953597a8e3d4658d1fd6c92844501", "class_name": "RelatedNodeInfo"}, {"node_id": "adf5011f-2293-4bd2-8a97-4b361b4bb6c3", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "47dc8ee82c54ef3b0a8247a0a069edcc4ca1ca4ec79206de788ddf13816e2dd4", "class_name": "RelatedNodeInfo"}, {"node_id": "7999f46f-e821-46e3-b203-d074345239e1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "76e19c4da37fdaa03d76d5df1da0e82671b070d8cd96db9e0fad0630d054470e", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It is difficult to guarantee that retrieved documents do not contain information published after the question date, which can lead to data leakage and overestimated performance. Therefore, additional research and system development on future information leakage are required. For example, Wildman et al. (2025) introduced a static benchmark with retrieved documents before the question date for each question using RetroSearch technique (Bosse et al., 2025). 20,000 documents are provided for each question on average. On the other hand, Turtel et al. (2025b) reported that they used a specific search API, Exa.ai API, which prevents information leakage. Ensemble Many forecasting studies employ LLM ensemble methods to enhance final performance (Halawi et al., 2024; Karger et al., 2025). This approach can involve generating multiple predictions from the same model using different prompts or ensembling predictions from multiple distinct models. Schoenegger et al. (2024) investigated ensemble effects using 12 models and compared their performance against human forecasters. Label type This paper explains event forecasting focusing on binary problems. Many event forecasting studies handle problems in binary classification form, or solve other types of problems by converting them to binary form. However, event forecasting can handle diverse problem types beyond binary classification. Multi-option, continuous (usually dates or numbers), entity-type open-ended (similar to multi-option but options are not given as choices), and sentence-type open-ended are problem types that can be handled in event forecasting (Wang et al., 2025). Most problem types can be relatively easily converted to binary problems.", "mimetype": "text/plain", "start_char_idx": 18372, "end_char_idx": 20087, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0718afa5-46ea-4eda-8c4d-a57fd276fa0f": {"__data__": {"id_": "0718afa5-46ea-4eda-8c4d-a57fd276fa0f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "37d20bb39b106ec0e6388a83b451491fa699d92274dcad9f660eecdba602b2cb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5dfdb998-f423-445d-8bfc-a68a110eb2db", "node_type": "1", "metadata": {}, "hash": "39d48a79a7dfb08e573a7e9f338b1f5cda1a56b99d8cd9d0be36aad38c252989", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "e7e6f438-3001-43e9-85ce-4c954cc42ad9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a3ad1e2db78ab68ba53a2e46a763b91e2486972998070786976ac9e47bcd884d", "class_name": "RelatedNodeInfo"}, {"node_id": "cafb6e9c-8ab2-4de0-97e0-52c4f5f873c3", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a69884160b8a4e1e3f902ef1f6a7b1a99747bf6fd01b6e855a07d141ad98a706", "class_name": "RelatedNodeInfo"}, {"node_id": "1566bd9d-d0bc-4db5-b348-ff0f2b1504cd", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f76b0e06d50649c830cbb28549f4420b467bcae5bd4fed82cdeba838b393d7f5", "class_name": "RelatedNodeInfo"}, {"node_id": "c3ace333-fec2-436f-b687-5f84638c3bf9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c9ec0ec041787624bfe2bc319d3ba0511da26f26520efa50ab55742236de2b5e", "class_name": "RelatedNodeInfo"}, {"node_id": "01506521-f1d3-4197-a64f-34c6dbe53b75", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b7ac296a9c99141c18cdafe221b393d966843c63e113fed586a42c6132aafd49", "class_name": "RelatedNodeInfo"}, {"node_id": "8db70806-7aec-4ea4-9ebe-a055a49be4cc", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3aaee5433d242a9bd1c0b1b2efaa8346b480cae9d2065e769b6100378b69dfbd", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Most problem types can be relatively easily converted to binary problems. Multi-option or entity-type open-ended problems can be converted to binary problems for each individual option, and continuous problems can be converted to binary problems by dividing the range into appropriate intervals. LLMs can generally perform well across all of these problem types. For example, when asked to infer probabilities of specific dates or numbers (continuous), LLMs can approximate the probability distribution over continuous values by providing probability estimates at regular intervals (e.g., 5% intervals from the 5th to 95th percentile). While recent work on training (Halawi et al., 2024; Turtel et al., 2025a;b) for event forecasting have focused on binary outcomes, future work could investigate whether direct training on multi-option or continuous predictions outperforms binarization approaches. Consistency Many reports have mentioned that LLMs exhibit poor consistency in probabilistic reasoning. The prediction that a candidate will lose by April and the prediction that they will lose after April should sum to 100%, but LLMs often do not (Liptay, 2024b). Lyu et al. (2025) discussed that LLMs have poor probabilistic consistency ability, and suggested the possibility that probability estimation performance could improve if this is handled well. The winner of Metaculus AI Benchmarking 4Q tackled the consistency problem well to achieve results that surpassed other AI systems (Hickman, 2025). The winner improved model predictions by having the model consider additional related options beyond the two choices presented in binary problems, thereby improving performance in the challenge.", "mimetype": "text/plain", "start_char_idx": 20014, "end_char_idx": 21712, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5dfdb998-f423-445d-8bfc-a68a110eb2db": {"__data__": {"id_": "5dfdb998-f423-445d-8bfc-a68a110eb2db", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0718afa5-46ea-4eda-8c4d-a57fd276fa0f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "784d4395096f346efa94556ffb1cdac53ce54093ee212796ba6335d64356c0bc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b915ffc9-8d12-45df-9dcd-6789cf6d0126", "node_type": "1", "metadata": {}, "hash": "9a4c593593635763c55b7c78035d4dd544f4735c1bac81c94a59fd5932328f90", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "5c73fba3-4b69-4c3c-bffd-da0e146648d1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "bc3049180ebc452bb670850919bdff34d201b1dfec7f7cd5f67ea94245ebc314", "class_name": "RelatedNodeInfo"}, {"node_id": "51fe30d5-c30f-4e90-8ccd-170665aa548b", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "01cee481fc8856183ea1c63014aba0df9d43a8e485a79869b9704f737d432e4f", "class_name": "RelatedNodeInfo"}, {"node_id": "d88b291d-e7e2-472e-a1cd-d8528e7b87c4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "4869f06fb7545de902a8bf4fac4853abf8346d8e4a58b5bdb7ede26352cf007d", "class_name": "RelatedNodeInfo"}, {"node_id": "1de52656-dd9a-45c2-80ea-b3a7aad79d8f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b08f434d2ccb4826f5aa61b6d877450cc87ef615fcd6a6096c33560678c8a783", "class_name": "RelatedNodeInfo"}, {"node_id": "70e3e75a-5eef-4a6c-b798-fa0f3ce85172", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8edf4ec791fb8dae340f048fa04e56b196d0cee0a49c5a8878294eed66af95e3", "class_name": "RelatedNodeInfo"}, {"node_id": "dc04308a-3eea-4418-ae92-d30d753a0d0d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "072fd4c412171dccd92a7080e40aa0a431295dda90ce82fe7b8aacd74df713df", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The winner improved model predictions by having the model consider additional related options beyond the two choices presented in binary problems, thereby improving performance in the challenge. For example, if asked whether there would be the first negative GDP growth in the fall, they also asked about growth in winter and summer at the same time. Paleka et al. (2025b), which deeply discussed consistency, not only pointed out existing problems in the event forecasting field but also proposed related datasets. In the proposed dataset, they evaluate whether LLMs follow probabilistic conditions that should be mathematically satisfied for 10 different consistency rules, including negation, paraphrasing, and consequence. 3 Past and current state of event forecasting Evaluation problems in previous studies Following the emergence of ChatGPT and similar models, numerous reports emerged claiming that LLM-based systems achieved near-superforecaster performance, 1https://github.com/Metaculus/metac-bot-template/ 5particularly throughout 2024 (Phan et al., 2024). However, subsequent analyses identified methodological flaws in these early optimistic analyses (Bosse et al., 2024; Paleka et al., 2025a). First, some studies drew excessive conclusions based on small samples that lacked sufficient statistical power to support their claims. Second, some studies erroneously used events that were resolved prior to the LLM\u2019s knowledge cut-off as evaluation instances, creating situations where models could simply recall memorized information (Lopez-Lira et al., 2025). Third, data contamination cases were also reported where documents from after the prediction resolution time were mixed into search results during web searches (Hendrycks and Mazeika, 2024).", "mimetype": "text/plain", "start_char_idx": 21518, "end_char_idx": 23281, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b915ffc9-8d12-45df-9dcd-6789cf6d0126": {"__data__": {"id_": "b915ffc9-8d12-45df-9dcd-6789cf6d0126", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5dfdb998-f423-445d-8bfc-a68a110eb2db", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07307918ff0274f9f1ad39885c8ed1c467898d130c1371c2971d84e051badeaf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e96a93da-42b0-486f-921a-eaefd380df59", "node_type": "1", "metadata": {}, "hash": "296fd00988449b01b7c52323c9fa19de45184419c6bee9817378bffdf4e6a477", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "1fe3ce0b-d366-4501-987a-4bfdf3acf64c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "cf59bb514be68cdc8403bca111824778a85ca425add3e50a1e96d9e54bdbb616", "class_name": "RelatedNodeInfo"}, {"node_id": "c11f5be5-32c5-44b8-b3aa-869d75bd0a34", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "1732504c75d2e89c6a63fd7eecfcde6f9f65438f2121aacbb1b8e4a71c795137", "class_name": "RelatedNodeInfo"}, {"node_id": "7d49b8f5-ab44-472e-90f5-ac68db726b50", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ae53cc340f5b04779de9097aeceec9db0d8df756111b72c605212fd656e862ef", "class_name": "RelatedNodeInfo"}, {"node_id": "a50b5997-c789-484c-892b-ca34806fd4b4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "344952e3bdda8381faa241b8abe78372e679e6ed0ab0202ab6a8790a7a00b623", "class_name": "RelatedNodeInfo"}, {"node_id": "6c2e8972-8180-4956-8458-2f5e2a3ae9fe", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "398f1bdfc35fc7e946eda88200bb53a2f7df42461ebaf9f55495624d756abc38", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Third, data contamination cases were also reported where documents from after the prediction resolution time were mixed into search results during web searches (Hendrycks and Mazeika, 2024). These methodological issues led to criticism that studies systematically overestimated LLM capabilities (Bosse, 2023a). However, Matthews (2025) present a balanced assessment of both promising developments and ongoing challenges in event forecasting, explaining that while there have been limitations in recent academic progress, there are still reasons to pay attention to AI prediction technology development. Recent AI performance advances Indeed, positive trends are being observed in recent developments in the event forecasting field, according to recent studies using rigorous evaluation with dynamic benchmarks. The ForecastBench paper (Karger et al., 2025) created a dynamic benchmark and evaluated various LLM systems in summer 2024. They showed that while LLMs are still far from reaching superforecaster-level, LLM performance in event forecasting develops along with LLM performance improvements. Specifically, the authors highlighted strong correlations between event forecasting Brier scores and both (a) Chatbot Arena (Chiang et al., 2024) scores and (b) estimates of pretraining compute, implying that increases in general LLM performance directly affect improvements in event forecasting performance.", "mimetype": "text/plain", "start_char_idx": 23091, "end_char_idx": 24500, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e96a93da-42b0-486f-921a-eaefd380df59": {"__data__": {"id_": "e96a93da-42b0-486f-921a-eaefd380df59", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b915ffc9-8d12-45df-9dcd-6789cf6d0126", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "177a810379cfdaafcf26c2600f684a6a8c6792225add313bd88e4224cb1f12dd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "22b58cc1-4f09-4bcd-ae98-ca507709fa3a", "node_type": "1", "metadata": {}, "hash": "f871cd33692992a53a5704f926b67650d20e8b35b6720032b0647c51859ef543", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "7ca6856e-1e79-4780-9597-b70d983ccc81", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "08a133eeeafc3298ca67703a4e68cadb8994d4a0021a4cd8cffb5f9da377c859", "class_name": "RelatedNodeInfo"}, {"node_id": "c8470257-32dc-40c2-84af-1ce80a7b2311", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b6cd1a5cc9134b140b424ab8864d2666a1f022b9eab1d69b16b4bc4a39dabf65", "class_name": "RelatedNodeInfo"}, {"node_id": "3bf34f78-400a-4357-817e-ccbd99fabf43", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b43f5a6555202ecd439ecc4769ffcb52e498f70de5f52cf04454f50c6f74e882", "class_name": "RelatedNodeInfo"}, {"node_id": "f456e7c2-6ee0-4349-a699-3d591248fe77", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "fe7dce4c82c92db2b4c899aa5dc4e52bf4cfbf38610cf2bb812522dc63bf32be", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Compared to early open-source models like GPT-3.5-Turbo and Llama-2-70B which had Brier scores exceeding 0.2, recent high-performance models like GPT-4o (Brier score 0.133 in the paper) and Claude-3.5-Sonnet (Brier score 0.122) have significantly narrowed the gap to Superforecaster AI (Brier score 0.096). This analysis also evaluated the collective intelligence of the general public, finding that when aggregating forecasts from general public participants, the median prediction achieved a Brier score of 0.121, similar to the best AI level. Generally, collective median predictions offset individual participants\u2019 biases and errors, performing much better than individual predictions; at least in the paper\u2019s benchmark, AI performance has likely already significantly surpassed average individual performance. Furthermore, recent insightful reports on the Metaculus AI Benchmarking Series examine performance differences between evaluation experts and AI systems, sharing the trends that the latest models like OpenAI o1 and o3 (OpenAI, 2024; 2025a) consistently and significantly outperform previous models in these challenges (Liptay, 2024a; Hickman, 2025; Wilson and Bash, 2025; Williams, 2025b). Performance improvement through RL Recent achievements by Turtel et al. (2025a;b) regarding training are also noteworthy. These studies showed that reinforcement learning with verifiable rewards (RLVR) (Lambert et al., 2024; Guo et al., 2025) on outcomes can increase model performance.", "mimetype": "text/plain", "start_char_idx": 24501, "end_char_idx": 25992, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "22b58cc1-4f09-4bcd-ae98-ca507709fa3a": {"__data__": {"id_": "22b58cc1-4f09-4bcd-ae98-ca507709fa3a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e96a93da-42b0-486f-921a-eaefd380df59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5fb382dd16c9102c4ea40976da91321fd5fa47f3d09cc3cf36e01ccd12662480", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9ab2e3f1-f9ff-4080-915a-0444f695af0d", "node_type": "1", "metadata": {}, "hash": "026ea29ad9957d4802e348c665525a32fcc07cc22827e757b0eca511566fd8d4", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "69f22d16-cb3b-4044-833d-88b59cc6c693", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6dd5ac04886f4ec7178998d732f6f40ce44c7f49fdaff487073119fd4554a503", "class_name": "RelatedNodeInfo"}, {"node_id": "1b42ec54-8165-4702-bbca-52099bdf3c4f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c567f5520868e5e52181f941ab35f31fd76755ec3e50ca9cb4aa56086e786028", "class_name": "RelatedNodeInfo"}, {"node_id": "ef7c8c26-2e41-4bb4-a26e-50570b057687", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b3a2b49599ebc1dd67a880215a2cde94f188fcb6bf59cd07b363b42e5313b350", "class_name": "RelatedNodeInfo"}, {"node_id": "0e246a18-28de-48c0-a966-d09a06822fd5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "df4947e4c0e869ec0c823250dff48d922b2f1ef6e760732fc78861eb6482f3cc", "class_name": "RelatedNodeInfo"}, {"node_id": "fc174872-b179-44c1-8143-c7e59c96be01", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "30ccf887da0c1f3b5de1a2a2625aaf1ddf8def345f829217fa1ae599de667220", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These studies showed that reinforcement learning with verifiable rewards (RLVR) (Lambert et al., 2024; Guo et al., 2025) on outcomes can increase model performance. They conducted training and evaluation of the R1-14B model based on Polymarket datasets, showing that the R1-14B model with an original Brier score of 0.214 could reach OpenAI o1\u2019s 0.197 level through learning. Furthermore, they showed that additional data augmentation could further slightly improve performance, reduce algorithmic variance, and lower the model\u2019s overall ECE. Additionally, they showed in backtest experiments on Polymarket \u2014 experiments evaluating making money by betting on Polymarket\u2019s market in a virtual environment \u2014 that OpenAI o1 model and their trained algorithms could generate profits. They simulated trading by conducting trades when there were differences between the model\u2019s predicted values and market predicted values. While the long-term viability of LLM-based algorithmic trading in prediction markets requires further validation through real-world implementation, this result supports the argument that trained LLM models are getting closer to superforecaster-level AI. Deep Research Recent reasoning models with tool use like Deep Research (Citron, 2024; OpenAI, 2025b; Anthropic, 2025), o3, etc., also have the potential to be a major breakthrough for the event forecasting field. There are grounds to think their model structures could be suitable for event forecasting, especially when they are further trained with event forecasting-specific objective functions.", "mimetype": "text/plain", "start_char_idx": 25828, "end_char_idx": 27397, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9ab2e3f1-f9ff-4080-915a-0444f695af0d": {"__data__": {"id_": "9ab2e3f1-f9ff-4080-915a-0444f695af0d", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "22b58cc1-4f09-4bcd-ae98-ca507709fa3a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ff49a9bb196c5d1311d2ed81a04c0ce6b4c6d000d6d33ba70e1b951d7ce81333", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5", "node_type": "1", "metadata": {}, "hash": "5ee6ee2027dacced6ea313e2754273bbd4d6d1f393f3d0971c4384202ded72af", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "f184f6e9-9f46-4a2d-a412-9b8e398f2b00", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "311fc0d79647e772a29bc1bb99dc3fd82c97a94ecf8de28c470eed25ac1c08dc", "class_name": "RelatedNodeInfo"}, {"node_id": "dacb713e-5773-4425-bb40-0accaaa094be", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a36e946f168ef478535fee08a4f25f25699c51fa79f3377c347712d589532d6b", "class_name": "RelatedNodeInfo"}, {"node_id": "1cb9fe24-627d-40fa-8b2c-4d5734d2eee0", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c5cc40ef9618ea1a0a46f66aa6932e9eee95bb58bfd5899ebad65a092a60b1b1", "class_name": "RelatedNodeInfo"}, {"node_id": "4980577f-97d2-41ef-a27a-761f41225875", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "4279e290d737cfe4b18946158d502b778d6ba1e2c4f260fd5433011934cd2be7", "class_name": "RelatedNodeInfo"}, {"node_id": "89ca1f59-64b8-4a3f-a0bd-1dc4c18b9c51", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "41fc679506946fc87a1e8f4835a0341424cd798369d593b2d91fd9089fe54ead", "class_name": "RelatedNodeInfo"}, {"node_id": "7412b6d1-756e-41ee-91d3-0f62943e3d09", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "385ddb3c55b75019dffe3e463103b6af41044b7788544f47110a9e14a1f81224", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "There are grounds to think their model structures could be suitable for event forecasting, especially when they are further trained with event forecasting-specific objective functions. They try various search and reasoning strategies on their own and attempt to solve problems by themselves, departing from the standardized prompt engineering-based or template-based reasoning used previously (Futuresearch, 2025). Furthermore, regression 6tests that infer current data values based on previous data are an important technique in event forecasting, and Deep research models have the capability to perform programming-based regression tests well (Liu et al., 2025). Therefore, using these models as a foundation model while incorporating event forecasting-specific training and inference strategies could yield substantial performance improvements. Proposal for large-scale training Based on these positive trends, we propose large-scale training for event forecasting LLM development. The current situation where model performance continues to improve and various training-related technologies are being developed suggests that opportunities have emerged to close the gap to superforecaster-level performance through comprehensive large-scale training. We address two key research directions for large-scale training in the next two sections: training (Section 4) and dataset (Section 5). Section 4 covers reward signal strategies and synthetic data generation methods to enhance efficiency within existing datasets, and Section 5 focuses on large-scale data collection. While these approaches can function independently, several algorithms from Section 4 create synergies with Section 5. In particular, solutions for the knowledge cut-off problem discussed in Section 4.2 enable models to effectively learn from historical patterns from the training instances before the knowledge cut-off, as discussed in Section 5.", "mimetype": "text/plain", "start_char_idx": 27213, "end_char_idx": 29130, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5": {"__data__": {"id_": "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9ab2e3f1-f9ff-4080-915a-0444f695af0d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "560835adb11b2aff7cb97e3c4232f18b97fb48c7f3b196d7f4b7ffebf9fedb4f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c66f7c50-d609-4182-af3b-864ded6b5b70", "node_type": "1", "metadata": {}, "hash": "0331643841184f332373fad340aabd2605abdf16ef384e4646bd0768be6dde03", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "ac94e726-9fc9-4598-866c-be5eeb8a19e8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e9308492cbfe6f212d940e41b60ce80b8e17d40ddfdf284d56ad506772d48634", "class_name": "RelatedNodeInfo"}, {"node_id": "533b5dd0-38da-4d13-9304-7938b016c0da", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dbb0d6d89ee4e729975225680f12809757e437e80e978adfc5f89f2646221436", "class_name": "RelatedNodeInfo"}, {"node_id": "e29b52c9-9060-40ab-adb4-31d7d30491a9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7f4aadeb285c678ac97e21deb9d6fd104e5a085328a2740dc5ea0653a1c05779", "class_name": "RelatedNodeInfo"}, {"node_id": "10cb0e8f-2c50-402c-b7b4-0a46cd655ba2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "16431fb49f390031dd91addf2db7afd1084e732d6aa4fa14031af99fe96924b7", "class_name": "RelatedNodeInfo"}, {"node_id": "5e7c3a27-ab1d-4162-8c57-410c678dc6de", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "154829653b3426410bb8bfab963dca38de848d981c105626032028109f0c9ee0", "class_name": "RelatedNodeInfo"}, {"node_id": "f5128987-775b-480e-a9b5-7f162afd1132", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "09b5c60d61affa0c604389f5e0d9a197e57184299befa4e29888a2d910a911b8", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In particular, solutions for the knowledge cut-off problem discussed in Section 4.2 enable models to effectively learn from historical patterns from the training instances before the knowledge cut-off, as discussed in Section 5. 4 Training algorithm improvements for future event forecasting In this section, we introduce three difficulties of event forecasting tasks that other AI tasks do not have when it comes to model training. Then, for the purpose of understanding these difficulties and enabling people to think about additional research directions based on this, we introduce several training ideas to mitigate these difficulties. The first training difficulty is the noisiness and sparsity problem of event forecasting outcomes (Kendall and Gal, 2017). For example, consider the problem of predicting the outcome of a US presidential election based on the initial situation. Since we can only make probabilistic inferences, not logical ones, based on information about the initial situation, the prediction label is noisy. Also, since presidential elections only occur once every four years, similar cases that can be used for training are sparse, making it difficult for models to learn sufficient patterns. We introduce the concept of hypothetical event Bayesian networks that can model this series of problems, and based on this, we discuss what kind of reward signals can be used for training. The second training difficulty is the knowledge cut-off problem, which is the difficulty of training or evaluating event forecasting questions about knowledge that LLMs already know internally. This greatly reduces the amount of data that LLMs can train on. As one approach to this problem, we introduce utilizing events that LLMs do not recall well, such as comparative outcomes between two items.", "mimetype": "text/plain", "start_char_idx": 28902, "end_char_idx": 30708, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c66f7c50-d609-4182-af3b-864ded6b5b70": {"__data__": {"id_": "c66f7c50-d609-4182-af3b-864ded6b5b70", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "18f3a1f8e8c7ce753494ef62bc38cad38af6f71b21656ff71750140eb0e8572d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eb5d3a53-a45e-4097-845b-a18ce54f9cec", "node_type": "1", "metadata": {}, "hash": "8bbcc3bf6ee1b6b053dfaff153f414473998fbc75ae2215315a99f059d28b2d9", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "7bbd5992-de2a-4648-8c84-c9ee77eeee49", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ae5637882cb531a5c2a192da145a031a669d761e1af0fa9e18c20e7f8332882c", "class_name": "RelatedNodeInfo"}, {"node_id": "dc34b97a-ab03-4082-8cff-a6445520e426", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9b5cfb0f7b59af376295b224f650d4115be2be719f881df020dec3a4d3d237a0", "class_name": "RelatedNodeInfo"}, {"node_id": "e27f06d3-38b6-4362-bd97-8436a55a2414", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "eb2b8d1e2cccaf9b499f3fb21e56188b42a10c68ef66c140b50f29f618873f10", "class_name": "RelatedNodeInfo"}, {"node_id": "5ae7250c-3613-4177-bd2e-498eb743de05", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0ee30fd79e320b7ce524e074c6fb9871210decdb0fd5cefb7351fa4b90c7a196", "class_name": "RelatedNodeInfo"}, {"node_id": "b52683be-a1cd-40d4-861e-fd619d8b79f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "635ff87d65c677a1e870eb353cb15e64b42f93fb36eddcfc3a40e4d0b6f4c03c", "class_name": "RelatedNodeInfo"}, {"node_id": "f79e69c1-9bac-4083-92a2-1c0e6bf0ee3f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "084563a05de4dfce818f8b347700227f3555b6a8d4b41a04d3892a9bbd852ba3", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This greatly reduces the amount of data that LLMs can train on. As one approach to this problem, we introduce utilizing events that LLMs do not recall well, such as comparative outcomes between two items. As another approach, we present the idea of training counterfactual events together so that models can focus more on search and reasoning. The third training difficulty is the simple reward structure problem, where models can obtain rewards more easily than in other RL tasks without proper reasoning, hindering actual prediction ability improvement. To mitigate this problem, we propose auxiliary label training that can provide additional reward signals. One example of auxiliary labels is evaluating the consistency of reasoning, and another is having the model answer additional questions related to the main question. 4.1 Modeling hidden probability of future event forecasting Let\u2019s say we want to train on whether \u201cToday is Dec 12, 2023. Will SpaceX successfully launch and return a spacecraft from Earth orbit by 2024 June?\u201d What should we use as the label for training and what training method should we use? Timeline: t0(Dec)\u2192t1(Feb)\u2192t2(Mar) Information: S0(initial situation) \u2192S1(intermediate update) \u2192S2(final result) Available: m0(market)\u2192m1(market)\u2192o(outcome) 7S0S1m0m1o Figure 1: A hypothetical event Bayesian network. The state S0at timet0changes to S1at timet1, and the probability of outcome ochanges. At time t0, we get market prediction value m0, and at time t1, we getm1.", "mimetype": "text/plain", "start_char_idx": 30504, "end_char_idx": 32001, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "eb5d3a53-a45e-4097-845b-a18ce54f9cec": {"__data__": {"id_": "eb5d3a53-a45e-4097-845b-a18ce54f9cec", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c66f7c50-d609-4182-af3b-864ded6b5b70", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "853232996bd2020c22e2cfb1adf9568f6c90d0794dd3846a0e84db0b2b88bc47", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c3852fdd-7c7c-4592-bf72-0a655646bec5", "node_type": "1", "metadata": {}, "hash": "203a5863c06c247d3eaf79682aa389a6fad277b07b9bf8c869fa9e70b6e64ee6", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "4442f3a1-3dfb-449c-a15d-852e24414c41", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "fd795100e47c9e1fdf6ed6461f1184614a6cb91f250c1cff807d9850d6f44344", "class_name": "RelatedNodeInfo"}, {"node_id": "02668298-18e8-44bb-93d7-19da4b9b3790", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2cf47d1570f311c6c9cf957e0503b077929d432287d72d307d0527a589a91b58", "class_name": "RelatedNodeInfo"}, {"node_id": "55b09120-0922-4df4-ad14-50ae22a2f0e2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "41a54f74576861dca5e950f0d44e49afb58e2b45f8cc0e6ca567ce406066b17d", "class_name": "RelatedNodeInfo"}, {"node_id": "26e4455f-0d4e-488e-a544-9f5625380731", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "12f63ac88ecfa22b79216a25de91833873e5285847839e845400bf3fb13c61e3", "class_name": "RelatedNodeInfo"}, {"node_id": "509b1e58-b476-4a27-9ded-777abf739514", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8d92fe0cb17363a4ff2981d50a95516c31f64eff934d149b64d0cd910f824c18", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "At time t0, we get market prediction value m0, and at time t1, we getm1. When training models, the natural and intuitive label in event forecasting is the outcome that can be known after the event is resolved. For example, since SpaceX successfully completed orbital flight on March 14, 2024, the actual outcome is 1.0 (success). However, if the prediction probability of a training instance becomes 1.0 during the actual training process, it suggests that the LLM may not be conducting good search and reasoning. Since the purpose of training is to generalize search and reasoning abilities, such extreme predictions hinder the development of core abilities in event forecasting. From the perspective of assigning appropriate probabilities to training instances, market prediction obtained from prediction markets would be a good estimate for that event through collective intelligence. However, if we train only on market predictions, it becomes difficult to create event forecasting prediction models that surpass market predictions. In this subsection, we first discuss the level of noisiness and sparsity of this problem to explain how this dilemma makes event forecasting problems difficult from a machine learning perspective. Then we introduce hypothetical event Bayesian networks that can theoretically understand this problem. Based on this conceptual analysis, we discuss how each approach to assigning labels in event forecasting can be explained and what label construction strategies and their variations can be used. 4.1.1 Noisiness and sparsity Event forecasting labels have two difficulties related to uncertainty built into them: the first is noisiness, and the second is sparsity.", "mimetype": "text/plain", "start_char_idx": 31929, "end_char_idx": 33628, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c3852fdd-7c7c-4592-bf72-0a655646bec5": {"__data__": {"id_": "c3852fdd-7c7c-4592-bf72-0a655646bec5", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb5d3a53-a45e-4097-845b-a18ce54f9cec", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f294da9f278345a925ffb9e9116e04ba0344df9c84d710780b6af4c7c5d502ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "540c70b6-2abc-4c67-9556-0c10b87b742a", "node_type": "1", "metadata": {}, "hash": "c721a0f0aec40d2899b5700041d5bc9c9ebffbdc182c8ab91380b5389300ff70", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "33348eb5-0677-4387-b789-c9ff60480007", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "278c73d86977d7ff45c039e2682d77b3a7c0f3bd4cacfe8ecf79db2e909f4998", "class_name": "RelatedNodeInfo"}, {"node_id": "ff062373-d901-443d-b8e2-7171d9d6fab4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "72311bf02e0b273738a72d109659b0e7e20a33a54409094bedc77585dab94cfa", "class_name": "RelatedNodeInfo"}, {"node_id": "3771e800-f5e0-468b-bf9e-66c996acd849", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2b06d5ad9765906d5e2fe1f2cbb0151ff063f9934cd2639c75fda14c0285b108", "class_name": "RelatedNodeInfo"}, {"node_id": "337584ff-0a73-48fb-98ef-48c0246e2518", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "70ca8fc7e21f6b522bd78ef04e8cce3dd6dd8d8478100c5cd79d704b00d721dc", "class_name": "RelatedNodeInfo"}, {"node_id": "2f780ae3-b5b8-4fab-ba53-5bc0e811f981", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6d4d468312286f383cb9bb2b760650e992369909eb6883f91b1242946dd4dd83", "class_name": "RelatedNodeInfo"}, {"node_id": "f77e394c-7c29-4b63-81dc-af15bd0e66f3", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "54741d5fab46ef98582e4e1f6df3f00e171a62ad9636aae65f5dd088398033ee", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.1.1 Noisiness and sparsity Event forecasting labels have two difficulties related to uncertainty built into them: the first is noisiness, and the second is sparsity. Regarding noisiness, consider the problem of predicting which candidate will win the 2024 US presidential election based on information available during the early stages of a competitive electoral campaign. No matter how much a smart expert analyzes available information from the early stages of the election, they cannot know for certain who will become president or what the probability is in percent. This means that the outcomes or market predictions we can use are inherently uncertain and noisy in explaining events. Regarding sparsity, US presidential elections are events that happen once every four years, making them very sparse events. Presidential elections exist for each country and each cycle, so we might be able to achieve generalization through this, but the context of presidential elections differs for each event, and it is difficult to generalize from one case to other cases. Although event frequency varies by domain, this illustrates the inherent sparsity of comparable training instances in event forecasting problems. From a traditional ML perspective, the former (noisiness) corresponds to aleatoric uncertainty, and the latter (sparsity) is related to epistemic uncertainty: events for which we have less data will have higher associated epistemic uncertainty (Kendall and Gal, 2017). The combination of these factors means that event forecasting faces higher uncertainty than many other ML problems. 4.1.2 Hypothetical event Bayesian networks We posed the question of what should be used as labels for event forecasting problems at the beginning of this subsection.", "mimetype": "text/plain", "start_char_idx": 33461, "end_char_idx": 35225, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "540c70b6-2abc-4c67-9556-0c10b87b742a": {"__data__": {"id_": "540c70b6-2abc-4c67-9556-0c10b87b742a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c3852fdd-7c7c-4592-bf72-0a655646bec5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7f477dae4ea6aca24b23eb488c928606ce2b7d75e653ec7af0bb06644a95a123", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a166db30-c2e0-4ee6-961d-c55174141f73", "node_type": "1", "metadata": {}, "hash": "dad274afe4d635be118ece4a95ce25a8c7060f5056047acaab53e2e36e366500", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "c4b2c7ef-1930-4255-acf6-bc1f652dafdc", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d868291feae115b660ae91e50e8d9f3662040802b29ec25093cdd30863d5466a", "class_name": "RelatedNodeInfo"}, {"node_id": "13883121-5801-4bbc-84bf-5d235841e0fa", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e4739bf349c8f15b2f29a5e4c40aed2af93ec9a8935f6ff7c60e5cade53b77fe", "class_name": "RelatedNodeInfo"}, {"node_id": "6fc6cc15-ff76-46c1-bbd1-3e9458afb757", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "be0757c24a787f7af8e6fa7ed26a310474ae8b6f222ee8949359db99e49b9c64", "class_name": "RelatedNodeInfo"}, {"node_id": "ac8c847f-de9b-4eab-a8f0-66c4cd60c4e3", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "bd489127f9867208baf78bb89e80db70285657a8830a301d8a4dd9ef99c37da4", "class_name": "RelatedNodeInfo"}, {"node_id": "7877ca51-85bd-40d2-96f7-2e6f9f2383b1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "37fd3b18d520de90733f08e586e4924fed601efbfa041c1ce241151df3e72dbc", "class_name": "RelatedNodeInfo"}, {"node_id": "46ab98fc-8d19-47df-9741-ecb36253fde1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2ba6ec8876c4724e8b5f5c974076e8de745bfff30b6eb9d9878b422cf46db1dc", "class_name": "RelatedNodeInfo"}, {"node_id": "6bda768b-04d6-42e0-a0e0-61b6c2846b7a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9cbbd3ba49863f944fde707727a5cb2da34a1237e640690cec1b2f138845f44f", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.1.2 Hypothetical event Bayesian networks We posed the question of what should be used as labels for event forecasting problems at the beginning of this subsection. As a conceptual framework for understanding this problem, let\u2019s construct a simple hypothetical event Bayesian network. Using the SpaceX example mentioned earlier, we model a situation where there is intermediate information in February ( t1)\u2014the success or failure of initial tests and reports\u2014between the question date t0in December and the resolution date t2in March. In our model, we define three core probabilities: \u03b1: final success probability when initial test fails (negative), \u03b2: final success probability when initial test succeeds (positive), \u03c0: probability that initial test succeeds (positive). Figure 1 is a diagram of our 8hypothetical event Bayesian network. Equations are as follows: \u03b1=P(o= 1|S1=negative ) \u03b2=P(o= 1|S1=positive ) \u03c0=P(S1=positive|S0=initial ) We seek to estimate an accurate probability for this question. Since the question date is t0, we need to estimate the probability that the outcome will occur at the S0point. We refer to this probability we are interested in as \u201chidden probability.\u201d The hidden probability Phiddenat the question date is as follows: Phidden =P(o= 1|S0=initial ) = (1\u2212\u03c0)\u03b1+\u03c0\u03b2 To estimate Phidden, we cannot observe these underlying probabilities \u03b1,\u03b2, and\u03c0directly, and instead need to infer these probabilities. One good estimate for Phiddenis a market prediction obtained through the collective intelligence of human forecasters.", "mimetype": "text/plain", "start_char_idx": 35060, "end_char_idx": 36612, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a166db30-c2e0-4ee6-961d-c55174141f73": {"__data__": {"id_": "a166db30-c2e0-4ee6-961d-c55174141f73", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "540c70b6-2abc-4c67-9556-0c10b87b742a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7c29efe98bd8eed0c838f7055c5f6bf5efc8cbecbaf8715307e110c2ecccf296", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2ba5b336-cde8-49ef-a2f5-c655bbf4b151", "node_type": "1", "metadata": {}, "hash": "d5b7095066d33faafdeeb25467c884620d39e457b641eda4bd336cd86bab2c61", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "ae37413a-987a-45f1-ac83-85e86906dc24", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3fd662ba08799ba002cc937138a36657456107f041f7ec028c2bdd6e256fac8d", "class_name": "RelatedNodeInfo"}, {"node_id": "3cec132b-2354-471e-b143-28f66c24ffda", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "75c225e75a24259d749e6142176fda0d4394eef730d81784dbe99f79a954a744", "class_name": "RelatedNodeInfo"}, {"node_id": "784e4f95-3d47-4c94-8bcb-b3ffc2b20b99", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ff91c39e2b45460d8fbf66b1824f64d0b3ebe50648a59657c219853e076d9bf6", "class_name": "RelatedNodeInfo"}, {"node_id": "78b4572e-8d75-486c-b0cc-d001f906f947", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "90b8e2718a19633c4f0adab865be53a48d5539846e74e359cf9ff6678798664e", "class_name": "RelatedNodeInfo"}, {"node_id": "9a3e3c8f-fbba-4417-8877-018258745278", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3460cea35a97d7ff70265040e90fcb1967a68ff239e96209e47d334bb74ce79d", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "One good estimate for Phiddenis a market prediction obtained through the collective intelligence of human forecasters. Market predictions m0andm1are estimates of P(o= 1|S0)and P(o= 1|S1), respectively, and we can assume they estimate values based on noisy observation of the actual parameters \u03b1,\u03b2, and\u03c0. In this hypothetical modeling, we can analyze how the accuracy of Phiddenestimation differs according to noise level and Nby sampling m0,m1,o Ntimes each (i.e., we simulate Nsimilar events, yielding {m0,n,m1,n,on}n=1,\u00b7\u00b7\u00b7,N).Nrepresents the number of hypothetical simulation trials. For example, in each trial,S1is sampled as positive with probability \u03c0. We can then compute separate estimates of Phidden by averaging the m0values,m1values, and ovalues, respectively (i.e.,1 N/summationtextN n=1m0,n,1 N/summationtextN n=1m1,n, and 1 N/summationtextN n=1on). How does the relative accuracy of each estimate differ at different Nvalues? First, let\u2019s think about the case whereN= 1. Sinceohas values of 0.0 or 1.0, there will be a considerable gap from Phidden. In this case, m0 is likely to be a much stronger estimate than o. However, let\u2019s think about the case where Nis sufficiently large. The estimation of m0contains prediction uncertainty noise, and this noise will slow convergence to Phidden.", "mimetype": "text/plain", "start_char_idx": 36494, "end_char_idx": 37796, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2ba5b336-cde8-49ef-a2f5-c655bbf4b151": {"__data__": {"id_": "2ba5b336-cde8-49ef-a2f5-c655bbf4b151", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a166db30-c2e0-4ee6-961d-c55174141f73", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "58e7285059a3b17d10ee60b3daf3a0d0275f2038155bd4536679677e87be4872", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad3be8a6-aac9-451d-8483-8b16fc4671ff", "node_type": "1", "metadata": {}, "hash": "5b919a53e12f410722f25e03cb758d8b9034882691de75664c1414148c4af86c", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "ab98e195-eb5e-4ed6-9a70-d344757e63bf", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c23544a7bbfd3f4fa66f306068fc41bc824daa7eb1da477b1e1b997c5851418b", "class_name": "RelatedNodeInfo"}, {"node_id": "d85a4458-1a16-4407-ade7-3c2b5aa33bdb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f3b3748cd6f5a4a95d3a4b059d6f923dcdf5a8a306f20ba7144ae6069121e9a8", "class_name": "RelatedNodeInfo"}, {"node_id": "7952f00d-bbc1-4a84-9017-c477ea9100bc", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2c8f82408db27fff3b89d70d8e92a6886bbcc9ddd0797acbdf9c58b2ed0b3cb3", "class_name": "RelatedNodeInfo"}, {"node_id": "e4ed83f7-38fa-4f45-9736-8eca5668e997", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "12b0c5c47ca7930497d7bc81501d92cd9cd5ecb011b7a588a56c29eb20c7ff05", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The estimation of m0contains prediction uncertainty noise, and this noise will slow convergence to Phidden. In this case, owill be a better estimate compared to m0. Can we use m1to estimate Phidden? Market predictions at the intermediate time m1occupy a middle ground betweenm0ando. Unlikem0, which must account for uncertainty about whether the intermediate state S1 will be positive or negative, m1is made after this uncertainty is resolved. However, unlike the final outcome o, m1still reflects the collective judgment of forecasters rather than a binary result. This positioning can make m1a superior estimate of Phiddenunder certain conditions, particularly when there is significant uncertainty in the transition from S0toS1(high estimation error for \u03c0) and when we have a moderate number of observations N. We provide detailed assumptions and simulation results demonstrating these trade-offs in Appendix A. Based on the hypothetical settings discussed above, let\u2019s now consider real scenarios of event forecasting tasks and address the question of whether to use outcome oor market prediction m0. Applying the hypothetical event Bayesian network framework, for data where there are few similar problems in the training data (small N), it would be good to use market prediction m0at question date time t0, and for cases where there are many similar problems (large N), it would be good to use outcome oat resolution date time t2. In practice, using both together could also be a way to get better estimates in some cases.", "mimetype": "text/plain", "start_char_idx": 37689, "end_char_idx": 39217, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ad3be8a6-aac9-451d-8483-8b16fc4671ff": {"__data__": {"id_": "ad3be8a6-aac9-451d-8483-8b16fc4671ff", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2ba5b336-cde8-49ef-a2f5-c655bbf4b151", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a2a5d57ba34b250693698c7b9e2fff62e3262c0ca3b1ea267a58929db94062cf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "11edbd09-dceb-4d7a-936d-c5b63e1320cb", "node_type": "1", "metadata": {}, "hash": "d9b1c4a077cb6e497ab5a5980faf9ae1d93c75caa838b9fb726eb04a591a2f5c", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "b1d619cb-53e3-46f0-b0ad-a4372afa43d0", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e87db552aa3c00d18da8e651f62d6ecc9b6c2113689d9837b0313983a118a315", "class_name": "RelatedNodeInfo"}, {"node_id": "8916e982-5a90-4d15-969c-65e7f0e0a16c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9af8f12a132b8cfab1fbfa27f71f3928d2244b41d87b45684dbd95c71e42646a", "class_name": "RelatedNodeInfo"}, {"node_id": "0ae4b470-79c3-4f69-bdac-bd5915ee5223", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "adf0741da91f017e0db8f3bfc1ac31a374aea49905d522ee809872c898d75f60", "class_name": "RelatedNodeInfo"}, {"node_id": "d638a830-8ac5-4174-82a7-be5eaf341ee4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "40f611349cc5a2b2dcfbb799ae220e5d096a6003c51187b943093d3e726082b5", "class_name": "RelatedNodeInfo"}, {"node_id": "8605bedc-51ff-4e99-b9f0-86888e23332d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d7561bf25f60f3e0215954c87ae3d697fae5d916a600c02371cd7e8973028465", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In practice, using both together could also be a way to get better estimates in some cases. According to the simulation in Appendix A, interestingly, there are also cases where using the market prediction value m1at timet1 betweent0andt2as a label for questions at time t0has advantages, and m1does not function merely as an approximation of o. The next subsubsection examines label assignment strategies that can be used based on this discussion. 4.1.3 Outcome as a reward signal The most direct method in event forecasting is using outcomes as rewards in RL. For example, we can use the negative Brier score between the probability predicted by the model and the actual outcome as a reward term (Turtel et al., 2025b), or give higher rewards to predictions closer to outcomes (Turtel et al., 2025a). 9Turtel et al. (2025b;a) achieved 5-10% Brier score improvement with training on outcomes; using outcomes in situations where an appropriately scaled dataset is secured can be a powerful baseline and practical approach. However, outcome-based training has the risk of models making extreme predictions approaching 0% or 100% after sufficient training epochs (Turtel et al., 2025b). More importantly, extreme predictions approaching 0% or 100% are likely signals that the LLM is not actually performing proper search and reasoning. The ultimate goal of event forecasting training is to learn good search and reasoning abilities and transfer them to test inference time, but extreme predictions hinder the development of these core abilities. Various regularization methods, such as early stopping, can be used to prevent this.", "mimetype": "text/plain", "start_char_idx": 39126, "end_char_idx": 40753, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "11edbd09-dceb-4d7a-936d-c5b63e1320cb": {"__data__": {"id_": "11edbd09-dceb-4d7a-936d-c5b63e1320cb", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ad3be8a6-aac9-451d-8483-8b16fc4671ff", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c573696465a96adcc30831ce133319655835a555c85b0bdefdefe3be3dc5f5a9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f", "node_type": "1", "metadata": {}, "hash": "eb8e94fb808f553a52423bea285c9e385569902ff2bab6c9cd63a02e8581f63a", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "f05a8110-c1e8-44c1-8148-cf387813423c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "606ef049b3024885bdcda6f6082378f230135987c44828b0f0b540fd4357f515", "class_name": "RelatedNodeInfo"}, {"node_id": "e426f93a-2cdd-4643-a68e-aed3ac84197f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d60fe540dcef365dd4b6b3faad5a63d4d6b862730ba5bc0d65990d05077fbcd3", "class_name": "RelatedNodeInfo"}, {"node_id": "39f03018-d143-4b90-96e0-1c72f0a252fd", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "255ebe8040fbbd1ea13fa67861762cb6ef6f4139fb754f22ae71c7508e4e72d0", "class_name": "RelatedNodeInfo"}, {"node_id": "d31452c3-fad9-4265-a515-982d866fe71f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c4f77977b8c6c4009b5f1c62b156a676cf2b7f057e3b24449cbba71282121926", "class_name": "RelatedNodeInfo"}, {"node_id": "c8a98fbf-eb5b-49cf-ae46-79e8fa49ad83", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ca33fd32899d53edce10bdb11568ce3291c8df7f1872774447af9f7af454033f", "class_name": "RelatedNodeInfo"}, {"node_id": "8275affe-d885-49c8-8008-fa2f9a85e949", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ee60257c612318fcee7104009d34a95edf2d7aa376203d22c77e2437fd7bbd5d", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Various regularization methods, such as early stopping, can be used to prevent this. 4.1.4 Market prediction as a reward signal Prediction markets serve as effective platforms for obtaining expert estimates of hidden probability Phidden in a scalable way. Each market prediction is a good estimate for that event, and from the hypothetical event Bayesian network perspective discussed earlier, it is an advantageous estimate to use when similar events occur infrequently. However, if we train only with market prediction, it becomes difficult to create event forecasting prediction models that surpass market prediction. Therefore, market prediction should be used as a reward signal in parallel with outcomes. In the research by Halawi et al. (2024), they used a specific interval between market prediction and outcome as the ground truth label. Specifically, they defined a 15% interval from the market prediction value in the direction of the actual outcome, and treated predictions within this range as correct answers. For example, if market prediction is 60% and outcome is 100%, they treated model predictions between 60% and 75% as correct. Additionally, various other methods for using market prediction and outcomes together in training can be considered. One method involves adding a KL-divergence term between model predictions and market predictions to the objective function, alongside the existing outcome-based reward signal. In another method, market predictions can be included directly as model inputs. The reliability of each market is also an important consideration. For example, markets with limited participation may exhibit higher noise levels (Bosse, 2023b). In (Halawi et al., 2024), they filtered out market data with few participants.", "mimetype": "text/plain", "start_char_idx": 40669, "end_char_idx": 42432, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f": {"__data__": {"id_": "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "11edbd09-dceb-4d7a-936d-c5b63e1320cb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c4f2bf40801c732be905b4413f2e306b24e33e769f8b2c770ea70218e37119a6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "55f139d1-e089-4158-875f-be649f023996", "node_type": "1", "metadata": {}, "hash": "43ae352c2210d67281477e228f622071e914de87f67ed67d7216b5d2a3faae76", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "99e02a18-40e1-41b6-96cf-c723ea00d9eb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "71bc5177e5cad3dc74ef8a86ad9b32a249693d7d2057c43709ce853726414800", "class_name": "RelatedNodeInfo"}, {"node_id": "f5130f5e-b5f9-4e70-b3f0-9f2013d4e2af", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0889a45af90d76a21102c69d5a4409791e338249df03ca1f3cd536cb069cd0d1", "class_name": "RelatedNodeInfo"}, {"node_id": "2f705498-ca27-4f7c-9fd5-5f770ca72e64", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f9ddb9fb32792131665d0f5c3b164a39cf75e14c8579f98c9fafe0be67a8c595", "class_name": "RelatedNodeInfo"}, {"node_id": "e66b0dee-d1fd-4330-9d19-def6628417b8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2666ed26db78e7139b21064276888fd85b02ec991fc25d96eee71ca500957190", "class_name": "RelatedNodeInfo"}, {"node_id": "73c3b4ce-76eb-412d-a7a7-a138434ac2eb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "1c510ba1a73583a9cb9d601871e9917e920aa47b0d584e90af94bcf911c7d4b6", "class_name": "RelatedNodeInfo"}, {"node_id": "46c2615c-9ce0-4efa-96fa-3678f0edf050", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a63c55afeb17076dfc5687a30f55d5e2231ed1e71b8a886e458c405f8a5f4775", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, markets with limited participation may exhibit higher noise levels (Bosse, 2023b). In (Halawi et al., 2024), they filtered out market data with few participants. Market reliability can be incorporated based on the specific approach used for market prediction. When using KL-divergence, the weight on the KL-divergence can be reduced for training instances corresponding to markets with few participants. When inputting market prediction values, related information about reliability can also be added together. Market predictions are available only when a prediction market exists for the specific event in question. When training on datasets containing both instances with available market predictions and instances without market data, reward signals derived from market predictions would be applied solely to those training instances where market prediction values are available. 4.1.5 Using prediction after the question time A considerable number of event forecasting questions in the world may not have outcomes determined yet at the current time point when we are training. Also, these forecasting questions may not have clearly defined resolution conditions, or there may be no pipeline to automatically extract outcomes for data construction because events are not registered in markets or databases. Can we train from such data where outcomes are not clearly obtained? If we can obtain market prediction m1at time point t1after question date t0, we can obtain reward signals from such data as well. There are two perspectives we can think about regarding the validity of using m1. The first is thinking of m1as a more accurate approximation of othanm0.", "mimetype": "text/plain", "start_char_idx": 42258, "end_char_idx": 43933, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "55f139d1-e089-4158-875f-be649f023996": {"__data__": {"id_": "55f139d1-e089-4158-875f-be649f023996", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dc2f2b9c372f1d9b1dd4428e764f0e75e04ea2fce032313058b2889fae33d700", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "edf14a7e-432c-4aab-a664-7a0b40a5e13e", "node_type": "1", "metadata": {}, "hash": "627cc043fe65c45e1dd2df3dd243d154efd7d2623283aa4ecfbc568be483c737", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "728835ac-2a2d-4994-87c0-9468e82f4dba", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0d63882e6890027fe35b42fa94ec1cf354b8e598a56ef7074c311bedfdbdbe63", "class_name": "RelatedNodeInfo"}, {"node_id": "139e6c95-59e4-4b78-9e3e-9549c1d0722b", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "bbbfa80fc3bfc78a1ac1f655aea3b924c3660fb99077dd0049b601cbaf2a2232", "class_name": "RelatedNodeInfo"}, {"node_id": "fbe01bbb-ff31-4480-84cf-3dae7be082dd", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f24b5f8ec11af2db0fbf3dffa21ccc8644d9b299f81fe0be05f9cdb893595db0", "class_name": "RelatedNodeInfo"}, {"node_id": "c30e5b3e-2ae3-4737-8921-3f3ea68877f1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3c4d144a0beaf48b5b1dc95e878285a97302fd436e6b8a07eba748b2ec4e150b", "class_name": "RelatedNodeInfo"}, {"node_id": "97678d71-ea37-4e77-bb46-cdcf6b3bef75", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8e1401f0af55539f76f76835af9027151a76ce0d8b209b2b9292cc0609441a9c", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "There are two perspectives we can think about regarding the validity of using m1. The first is thinking of m1as a more accurate approximation of othanm0. Especially if the value of m1is close to 0.0 or 1.0, and if m1\u2019s estimation of ois close to unbiased (if the model\u2019s ECE is low), we can statistically say thatopredicts well at the probability that m1suggests. From that perspective, when we get m1that is sufficiently different from m0and close to 0.0 and 1.0, we can use m1for training. The statistical validity can be established through empirical data analysis. The second is understanding m1as an approximate estimate of Phiddenwhere uncertainty before t1has been resolved, as discussed in Section 4.1.2 earlier. In 10this interpretation, m1has meaning beyond being an estimate of o, and has the potential to provide better signals than oin certain scenarios. Next, we discuss whether the model\u2019s prediction q1at timet1can be used for model prediction where the question date is t0. When market prediction m1at timet1cannot be obtained because the prediction market does not handle that event, the use of model prediction q1becomes a consideration. Our hypothetical Bayesian network framework extends naturally from market predictions ( m0,m1) to model predictions (q0,q1).", "mimetype": "text/plain", "start_char_idx": 43780, "end_char_idx": 45061, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "edf14a7e-432c-4aab-a664-7a0b40a5e13e": {"__data__": {"id_": "edf14a7e-432c-4aab-a664-7a0b40a5e13e", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "55f139d1-e089-4158-875f-be649f023996", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a63d187fbccb82a5b77faf9ae1991f5d018bd291b44490bbd745b5eb9c7b04ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "56dc8265-cdb6-46d9-9ee5-d6c9dc798056", "node_type": "1", "metadata": {}, "hash": "e900e76fc7036b2a04f16d92431a8efc2137da37a48a52286ad13db9b85e56d8", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "4901693c-df30-4c8c-ab43-417154ba1e05", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "883b62d834138acbd1c5237aed518acba0682c1a2873d3791ea172db38ebff84", "class_name": "RelatedNodeInfo"}, {"node_id": "a8b484a1-2343-493a-9b2c-50c2ebb5ec4b", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3c489162ab7d8cc131ba10076d7b3aaf5008a1a242c981d9c422fbc380ba14b9", "class_name": "RelatedNodeInfo"}, {"node_id": "0f5b974e-f657-4360-8ea7-6bd11d43c8e6", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "953061b39c9bd05ddddc4a623718e527241178725fbdedb3e4874c2a64bb9053", "class_name": "RelatedNodeInfo"}, {"node_id": "38717897-3269-43f2-973e-540622079d25", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "920cc5158d3c70370ce74be9d64e929c031399a852380197bab462576bc6fc98", "class_name": "RelatedNodeInfo"}, {"node_id": "e6e7ca7d-bacf-44d9-9ca9-5923dffdfe93", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ab6b15776ef20824f954c3875fdd31c877006c0b97dfb75f74695503d2130626", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Our hypothetical Bayesian network framework extends naturally from market predictions ( m0,m1) to model predictions (q0,q1). Critically, while q0offers no new information for training purposes, q1can leverage the temporal information gain between t0andt1, making it a viable training signal similar to m \u2081. The applicability of q1 can be evaluated using similar criteria as those for m1. Regarding the effectiveness of using q1, we need to additionally consider the performance of the predicting LLM itself. If the prediction model\u2019s predictions are not sufficiently accurate and have high noise, it may be difficult to use q1due to the high noise. Even when asking LLMs at time points after resolution date t2, if the LLM\u2019s search/RAG performance or fact checking performance is not 100%, the LLM may not achieve 100% accuracy. Notably, the model\u2019s prediction q1can be applied to forecasting questions where outcome resolution conditions are not rigorously defined. For instance, this value can be used for questions with ambiguous resolution conditions like \u201cDid ChatGPT released in 2023 have a positive impact on English education?\u201d or \u201cWill COVID vaccines effectively prevent COVID?\u201d This approach extends event forecasting from questions with clear resolution criteria to more general questions about the future by leveraging the information gap between past (S0) and present ( S1) states as training signals. 4.2 Training from data before knowledge cut-off In this part, we discuss the knowledge cut-off problem and introduce ideas to mitigate this problem, including (1) using events that LLMs do not remember well and (2) training counterfactual events together.", "mimetype": "text/plain", "start_char_idx": 44937, "end_char_idx": 46607, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "56dc8265-cdb6-46d9-9ee5-d6c9dc798056": {"__data__": {"id_": "56dc8265-cdb6-46d9-9ee5-d6c9dc798056", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "edf14a7e-432c-4aab-a664-7a0b40a5e13e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "80f477774ce4cecbea43218ca827ec15c3d2a96846b036fa5088306fde7ee2cb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "72e13c48-1857-4244-900f-9e7a1f7e6763", "node_type": "1", "metadata": {}, "hash": "382508a7e17bb6cdef5a48f3802630c1edf48272a743f27c1db729863ce87acf", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "0d6eb3be-a4ef-43dc-ba46-72e04779a732", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6f5a9a6884351f52d4a356d0296e521bb2db8f39564095bbf5760e401810832f", "class_name": "RelatedNodeInfo"}, {"node_id": "22abeffe-1304-407e-beb1-44c3a9fd4fa7", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "aef1d0c5cf4ce4bf016fe98b9725b4acbb5418b75b7fc231c10dbc8ad586501e", "class_name": "RelatedNodeInfo"}, {"node_id": "20c5ad66-47b2-4351-a2d0-b2c4042f2ff5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d103bb3cc2dfbd7c5718291fe92f1ee51001da0ca61747aff99ae0a145fb95b8", "class_name": "RelatedNodeInfo"}, {"node_id": "78bc3360-41e9-4d3e-a816-7e5d7914eabf", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a9b15ff3df39d5a4ebc3ed88dc3c515d579fdc37bbf5b37d2ccc75d199a44ad0", "class_name": "RelatedNodeInfo"}, {"node_id": "0d804174-3b08-4fd1-ac1d-eac32cc650f9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "98922793a002173a7000d485e71b80ec5320574fc725d3c7685fcf05e871b2b6", "class_name": "RelatedNodeInfo"}, {"node_id": "2a85ef71-2638-4918-9650-1ab5cdff23c8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "03ad55206420417683976e307b34f1f80ef632549e3d73b55f118e61591d6a29", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.2.1 Knowledge cut-off problem When evaluating event forecasting problems using data from before the knowledge cut-off period, models can provide accurate responses by relying on their internal knowledge without employing search and reasoning capabilities. Since these memorization-based responses do not generalize to questions where the model has not observed the outcomes during training, data from before the knowledge cut-off loses its value for evaluation purposes. The same limitation applies to training. Models have reduced motivation to acquire additional information through search when they already possess the relevant knowledge internally, and similarly lack motivation to engage in reasoning processes for answers they have already memorized. Consequently, neither search capabilities nor reasoning abilities are enhanced through this training approach. If we use past models with earlier knowledge cut-offs for event forecasting training, we can utilize more training data compared to the latest models. However, there are two major disadvantages to using past models. First, since the latest models outperform past models, we cannot leverage the capability improvements from LLM development (Karger et al., 2025). Second, the latest models possess the most recent knowledge. Models with more up-to-date knowledge will make better future predictions for questions that require recent trends as context, even without searching for that specific knowledge. Whether training can be conducted using data from before the knowledge cut-off is an important question. First, since substantially more data exists before the knowledge cut-off than after, the feasibility of utilizing pre-cutoff data determines the scale of available training data. Another issue is that if training data is constructed within a limited period after the knowledge cut-off, we end up training on data that exhibits biases specific to that particular period.", "mimetype": "text/plain", "start_char_idx": 46608, "end_char_idx": 48554, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "72e13c48-1857-4244-900f-9e7a1f7e6763": {"__data__": {"id_": "72e13c48-1857-4244-900f-9e7a1f7e6763", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "56dc8265-cdb6-46d9-9ee5-d6c9dc798056", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4231435026602d89e8547d74edaac91fbc146c6dfe2957ac8de672c8265489c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "204c3fb6-154c-4508-9774-68fd1f274e01", "node_type": "1", "metadata": {}, "hash": "8b078a7a4b3944f455a6833a9d3c7967466136d2e5bf918f509c9b15ea132c74", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "8b85f05c-56eb-43f6-8072-33bc9783a316", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c8c421f2da5b1b9e50cebf1574ffcafbd330ac915934f4c325bfd59c480dfff7", "class_name": "RelatedNodeInfo"}, {"node_id": "558be939-068f-4390-945a-28cef910cbff", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e74b038e422c63a9ab993d4f75a5bea5282fc76773bc3bde38684c1a8e9c96fb", "class_name": "RelatedNodeInfo"}, {"node_id": "ffda4781-e364-49ad-9903-36dec832e44e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "faad75540705e85373749048a0acacd6d9d22dcb2f6a47da5ad5eae78cda1e52", "class_name": "RelatedNodeInfo"}, {"node_id": "b9741048-0bcf-49fa-b8ee-ce7f6cea6a81", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "255a301d62445904dfd082fdcd76b396526f2661f93fa065de709bbf4d9d4ec8", "class_name": "RelatedNodeInfo"}, {"node_id": "810c43b0-cfca-4998-8584-bb70ee120696", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d3659466edd7781d3b4e658a62c1527b27d6e0a11c3bf7e1d0ae3adece83a632", "class_name": "RelatedNodeInfo"}, {"node_id": "ff63f380-3595-4180-b636-5a380e924651", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "99765d891c9ec938d43eee577131f684c93a35aa881a01d9a04eaeefe2172fcf", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Another issue is that if training data is constructed within a limited period after the knowledge cut-off, we end up training on data that exhibits biases specific to that particular period. For example, consider predicting numerous economic indicators during an economic boom period. Such a prediction model may not perform adequately during economic downturns. 4.2.2 Using events LLMs poorly recall One approach to addressing the knowledge cut-off problem is to use events that happened in the past but that LLMs cannot answer well through memorization as training data. We can explore what knowledge LLMs 11do not answer well through memorization by asking LLMs questions about various domains and use this approach to identify suitable training data. Types of information that LLMs do not memorize well are cases where LLMs know individual facts but do not memorize the relationships or comparison results between them. Wen et al. (2025) created an event forecasting task about which of two research ideas would show better performance on benchmarks. Existing LLM agents without special training showed only random baseline level (50%) performance in the above prediction task comparing the relative performance of two ideas, even though they had knowledge about individual papers. In that paper, they improved performance by training on 7,000 paper idea pairs based on open-source models. The trained model was able to achieve 77% accuracy forecasting performance on 1,500 pairs after the knowledge cut-off by retrieving related past papers and knowledge.", "mimetype": "text/plain", "start_char_idx": 48364, "end_char_idx": 49924, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "204c3fb6-154c-4508-9774-68fd1f274e01": {"__data__": {"id_": "204c3fb6-154c-4508-9774-68fd1f274e01", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "72e13c48-1857-4244-900f-9e7a1f7e6763", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "217757993c6cd45d521fff52ce4bc2e2e0e27d8c4cd56ac1ef3a1868733b5d18", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "65f85521-e243-4b44-842b-bfebfce7cc2a", "node_type": "1", "metadata": {}, "hash": "ca2fbc8d42846b013ddb2a407c4416a1b8e7c0c1c065c83cb0180ef4d1f6cbcc", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "47e1d198-bb83-44b4-b265-a42a3583f23f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9b33ee7cb6b18841a204a3227900278142f40a661bef11d8663d4866b760ff56", "class_name": "RelatedNodeInfo"}, {"node_id": "13814057-a813-48ef-88a5-4ac5616376c8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6016a73760c520a1830b2045d4fbf5ff1ef296c103a3e28f552ca7ac9f72c2ee", "class_name": "RelatedNodeInfo"}, {"node_id": "18abf32b-3d18-4271-9924-c50acf8154a6", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "67d7ec6dfb1686bd8106b0cd4846f6a2f2f11dc7ed80e3e3c1f404a5a020f564", "class_name": "RelatedNodeInfo"}, {"node_id": "7d8532ed-9156-4344-8487-a8afb326ea52", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "13e59297068490eec5b7d6a0cf807723e0ee850a7ef5ee6865de40b7897fae20", "class_name": "RelatedNodeInfo"}, {"node_id": "ebafaaf0-1b03-42af-b797-ac464052d90d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ec2e1038879d4716b726fb9429920678520c00031d930f44c3234e4aec51242b", "class_name": "RelatedNodeInfo"}, {"node_id": "e237093e-779e-4c5b-9b17-93a82b6575dd", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7df280f4507916d09a4a2cd1071443dc56147033be8e04d9938a015348965e19", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The trained model was able to achieve 77% accuracy forecasting performance on 1,500 pairs after the knowledge cut-off by retrieving related past papers and knowledge. If we apply this approach of predicting comparison results of two indicators from the same period to data from more domains, we should be able to create data that can be used for training to increase event forecasting performance, even though it is data from before the knowledge cut-off date. For example, we can consider (1) future relative market performance of products released at the same time, (2) comparison of specific future indicators of companies with similar backgrounds, and (3) comparison of future citation counts of papers presented at academic conferences. However, it remains an open empirical question whether training on such poorly-recalled historical events improves performance on general event forecasting tasks. Validating this transfer represents an important direction for future research. 4.2.3 Putting counterfactual events Another approach is to use counterfactual events to make LLMs utilize retrieved knowledge for reasoning and probability prediction even when training from data before the knowledge cut-off. In this idea, we use counterfactual events that have outcomes opposite to the actual events that happened in the past. The key insight of this approach is that since LLMs must reason based on retrieved information even in counterfactual scenarios, they develop actual reasoning abilities rather than simple memorization. Related research in the question answering field that used counterfactual event-based retrieved knowledge utilization can be referenced (Paranjape et al., 2022). For example, Neeman et al. (2023) showed that training on counterfactual knowledge can increase models\u2019 search grounding and reduce hallucination.", "mimetype": "text/plain", "start_char_idx": 49758, "end_char_idx": 51598, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "65f85521-e243-4b44-842b-bfebfce7cc2a": {"__data__": {"id_": "65f85521-e243-4b44-842b-bfebfce7cc2a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "204c3fb6-154c-4508-9774-68fd1f274e01", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "845332175e4a9ebb9ba3e5cd25ec8260f70ace153c6d84caa8bac70fd79c5708", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "9cddb9dd-5b78-4d09-9172-3fa43c4dcd17", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "042cd932a9b9197528f48cd95eb6683b3fb4fc7c584ddfec2c06ba61993f2b7a", "class_name": "RelatedNodeInfo"}, {"node_id": "d3182eb9-b7ca-4419-aed0-c1ed4b717f6d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e416c81da06629b0c4a8899ab84646281762460de08f17d443abd90b30e6caf2", "class_name": "RelatedNodeInfo"}, {"node_id": "b655faac-56fc-4430-99cc-da0a5388efc8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7499ba23a7a024fa97ad4e7b4dff7cfda8b3186098323601abd8df77e013d922", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, Neeman et al. (2023) showed that training on counterfactual knowledge can increase models\u2019 search grounding and reduce hallucination. In this research, counterfactual documents were constructed by modifying the correct answer entity in search documents. Specific ideas for creating counterfactual events are as follows. First, we need to create fictional search documents that support counterfactual events. We can make LLMs generate fictional news articles reflecting counterfactualoutcomesandusethemasiftheyweresearchresults.Forexample,wecancreateacounterfactual event of \u201cSpaceX Starship 3rd launch failure in March 2024,\u201d which is the opposite outcome of \u201cSpaceX Starship 3rd launch success in March 2024,\u201d and create related fictional news articles. Here is an example of an implementable pipeline: Step 1: Base event selection and counterfactual divergence point setting For each base event, we set a specific time point (divergence date) where actual events and counterfactual events split. We use actual search documents until this poi", "mimetype": "text/plain", "start_char_idx": 51452, "end_char_idx": 52508, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f67a7758-7358-4539-828e-a06cc05e491d": {"__data__": {"id_": "f67a7758-7358-4539-828e-a06cc05e491d", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a01fa895-5f83-46af-9fc3-bbd26f899a45", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4b2b0be90cea560fc5366830d8c8f3e59bff0bd1c2513d85886ec90f86beae8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "TITLE: Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts\n\nAUTHORS: Sang-Woo Lee, Sohee Yang, Donghyun Kwak, Noah Y. Siegel\n\nABSTRACT: Many recent papers have studied the development of superforecaster-level\nevent forecasting LLMs.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 304, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d7d3a8d2-696e-44de-9b80-a9a04b798420": {"__data__": {"id_": "d7d3a8d2-696e-44de-9b80-a9a04b798420", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f67a7758-7358-4539-828e-a06cc05e491d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "88a6d31aada36c458cc53d30aabaeabf08eb6485425eb1fbcc5ee51703e120b2", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a01fa895-5f83-46af-9fc3-bbd26f899a45", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4b2b0be90cea560fc5366830d8c8f3e59bff0bd1c2513d85886ec90f86beae8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "While methodological problems with early studies cast\ndoubt on the use of LLMs for event forecasting, recent studies with improved\nevaluation methods have shown that state-of-the-art LLMs are gradually reaching\nsuperforecaster-level performance, and reinforcement learning has also been\nreported to improve future forecasting. Additionally, the unprecedented success\nof recent reasoning models and Deep Research-style models suggests that\ntechnology capable of greatly improving forecasting performance has been\ndeveloped.", "mimetype": "text/plain", "start_char_idx": 305, "end_char_idx": 827, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "72ca9d2d-0c71-4ccb-bfe0-7db20c790544": {"__data__": {"id_": "72ca9d2d-0c71-4ccb-bfe0-7db20c790544", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d7d3a8d2-696e-44de-9b80-a9a04b798420", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2d451399d92c33fab9b1ba921255e5f0887a6a166de20fe6b2c5ab58118bf83d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a01fa895-5f83-46af-9fc3-bbd26f899a45", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4b2b0be90cea560fc5366830d8c8f3e59bff0bd1c2513d85886ec90f86beae8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Additionally, the unprecedented success\nof recent reasoning models and Deep Research-style models suggests that\ntechnology capable of greatly improving forecasting performance has been\ndeveloped. Therefore, based on these positive recent trends, we argue that the\ntime is ripe for research on large-scale training of superforecaster-level\nevent forecasting LLMs. We discuss two key research directions: training\nmethods and data acquisition. For training,", "mimetype": "text/plain", "start_char_idx": 632, "end_char_idx": 1087, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "57b31622-1557-422e-bbd7-e9e6ea16b735": {"__data__": {"id_": "57b31622-1557-422e-bbd7-e9e6ea16b735", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "72ca9d2d-0c71-4ccb-bfe0-7db20c790544", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b00509312f845fd034ad685ece1960194f0b455bf2b33492166e187007d05ed1", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a01fa895-5f83-46af-9fc3-bbd26f899a45", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4b2b0be90cea560fc5366830d8c8f3e59bff0bd1c2513d85886ec90f86beae8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We discuss two key research directions: training\nmethods and data acquisition. For training, we first introduce three\ndifficulties of LLM-based event forecasting training: noisiness-sparsity,\nknowledge cut-off, an\n\nKEY DEFINITIONS: LLMs: gradually reaching superforecaster-level performance,", "mimetype": "text/plain", "start_char_idx": 995, "end_char_idx": 1286, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1254c435-fbf0-4649-a7d6-f158fc8b1213": {"__data__": {"id_": "1254c435-fbf0-4649-a7d6-f158fc8b1213", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "57b31622-1557-422e-bbd7-e9e6ea16b735", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "82682353a42c9b1cd18053fcd67eccf7355117921394fda5571fe241deb30e4e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a01fa895-5f83-46af-9fc3-bbd26f899a45", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4b2b0be90cea560fc5366830d8c8f3e59bff0bd1c2513d85886ec90f86beae8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For training, we first introduce three\ndifficulties of LLM-based event forecasting training: noisiness-sparsity,\nknowledge cut-off, an\n\nKEY DEFINITIONS: LLMs: gradually reaching superforecaster-level performance, and reinforcement learning has also been reported to improve future forecasting | time: ripe for research on large-scale training of superforecaster-level event forecasting LLMs | forecasting: a task of predicting whether specific events will happen in the future,", "mimetype": "text/plain", "start_char_idx": 1074, "end_char_idx": 1551, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e75d4856-4cdb-4b2f-b492-784e59799624": {"__data__": {"id_": "e75d4856-4cdb-4b2f-b492-784e59799624", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1254c435-fbf0-4649-a7d6-f158fc8b1213", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9004dfa0055c47bd2ecdd199f71ddc30729ea61d2b65b3f24e73182f56fa69dd", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a01fa895-5f83-46af-9fc3-bbd26f899a45", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4b2b0be90cea560fc5366830d8c8f3e59bff0bd1c2513d85886ec90f86beae8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "and reinforcement learning has also been reported to improve future forecasting | time: ripe for research on large-scale training of superforecaster-level event forecasting LLMs | forecasting: a task of predicting whether specific events will happen in the future, or what the probability of occurrence is, based on information up to a certain point in time (Jin et al | Today: December 31st,", "mimetype": "text/plain", "start_char_idx": 1287, "end_char_idx": 1679, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1560e316-0278-4e30-b751-ec24ef3deac7": {"__data__": {"id_": "1560e316-0278-4e30-b751-ec24ef3deac7", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ba7060b2-c1c4-48c8-967f-acb5a5e228f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "38ea6b49c1bc4cc5b37ecf5ddd1443f346af8396c9af8cf5c48163af04390af3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "or what the probability of occurrence is, based on information up to a certain point in time (Jin et al | Today: December 31st, 2023 | approach: Retrieve-Augmented Generation (RAG) (Lewis et al | information: first retrieved, followed by reasoning processes that derive the final answer (Halawi et al | field: to make LLMs perform as well as top-level human forecasting experts or collective intelligence of general experts, that is,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 433, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "05c7e783-1c8e-46fa-89b0-e577ecc3ba69": {"__data__": {"id_": "05c7e783-1c8e-46fa-89b0-e577ecc3ba69", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1560e316-0278-4e30-b751-ec24ef3deac7", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d7f7c4005ffd0f6aaa374187544e35ab808151f0706f0ab1bf3b47dfec64559c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ba7060b2-c1c4-48c8-967f-acb5a5e228f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "38ea6b49c1bc4cc5b37ecf5ddd1443f346af8396c9af8cf5c48163af04390af3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "followed by reasoning processes that derive the final answer (Halawi et al | field: to make LLMs perform as well as top-level human forecasting experts or collective intelligence of general experts, that is, to make models reach superforecaster-level (Tetlock and Gardner, 2016; Karger et al | forecasting: steadily improving with generational advances,", "mimetype": "text/plain", "start_char_idx": 226, "end_char_idx": 579, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7e983058-8495-42d0-b7ea-72bbc288957b": {"__data__": {"id_": "7e983058-8495-42d0-b7ea-72bbc288957b", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "05c7e783-1c8e-46fa-89b0-e577ecc3ba69", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3a87e5004e79c88ec51809b128c2da13810f66d0fc9b52487984f418c2771661", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ba7060b2-c1c4-48c8-967f-acb5a5e228f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "38ea6b49c1bc4cc5b37ecf5ddd1443f346af8396c9af8cf5c48163af04390af3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "that is, to make models reach superforecaster-level (Tetlock and Gardner, 2016; Karger et al | forecasting: steadily improving with generational advances, and they are getting closer to superforecaster-level | conditions: now favorable for research on large-scale training of event forecasting LLMs to approach superforecaster-level performance | First: the noisiness and sparsity problem,", "mimetype": "text/plain", "start_char_idx": 425, "end_char_idx": 814, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b5edf441-b4e6-4d88-b1ab-b6be5e840ff2": {"__data__": {"id_": "b5edf441-b4e6-4d88-b1ab-b6be5e840ff2", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7e983058-8495-42d0-b7ea-72bbc288957b", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "88585bcc47a0946cacd4a9d49feb38cb43c2fb0db2bdb517919771afe2421f21", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ba7060b2-c1c4-48c8-967f-acb5a5e228f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "38ea6b49c1bc4cc5b37ecf5ddd1443f346af8396c9af8cf5c48163af04390af3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "and they are getting closer to superforecaster-level | conditions: now favorable for research on large-scale training of event forecasting LLMs to approach superforecaster-level performance | First: the noisiness and sparsity problem, which is the difficulty in learning due to inherent uncertainty in event forecasting outcomes and the sparsity of similar events\n\nFULL TEXT: Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions,", "mimetype": "text/plain", "start_char_idx": 580, "end_char_idx": 1057, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5d8327e8-0269-48cc-82ba-d0a56cba74d6": {"__data__": {"id_": "5d8327e8-0269-48cc-82ba-d0a56cba74d6", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5edf441-b4e6-4d88-b1ab-b6be5e840ff2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a9b5e6a1ce93832eb353d6dcc0ea7dd38730eb5b33272682e4fcdbdaa35429e9", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ba7060b2-c1c4-48c8-967f-acb5a5e228f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "38ea6b49c1bc4cc5b37ecf5ddd1443f346af8396c9af8cf5c48163af04390af3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "which is the difficulty in learning due to inherent uncertainty in event forecasting outcomes and the sparsity of similar events\n\nFULL TEXT: Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts Sang-Woo Lee\u2217sangwoolee.cs@gmail.com Independent Sohee Yang\u2020soheeyang@google.com Google Deepmind Donghyun Kwak donghyun.kwak@navercorp.", "mimetype": "text/plain", "start_char_idx": 815, "end_char_idx": 1213, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b1972c46-76a6-4b05-ac48-9fa83e86489e": {"__data__": {"id_": "b1972c46-76a6-4b05-ac48-9fa83e86489e", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5d8327e8-0269-48cc-82ba-d0a56cba74d6", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3e955686c68769fd03436f3fe35c51a0023f21acadd380b75bbda229de35f70e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ba7060b2-c1c4-48c8-967f-acb5a5e228f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "38ea6b49c1bc4cc5b37ecf5ddd1443f346af8396c9af8cf5c48163af04390af3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "cs@gmail.com Independent Sohee Yang\u2020soheeyang@google.com Google Deepmind Donghyun Kwak donghyun.kwak@navercorp.com NAVER Cloud Noah Y. Siegel\u2020siegeln@google.com Google Deepmind Abstract Many recent papers have studied the development of superforecaster-level event forecasting LLMs.", "mimetype": "text/plain", "start_char_idx": 1102, "end_char_idx": 1384, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6d937604-5db8-47cc-a662-2b0aa94f3a68": {"__data__": {"id_": "6d937604-5db8-47cc-a662-2b0aa94f3a68", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5b494e927064a8d15ad971603a6ab9cec2ca361819f5d5af8da5fa7b499fdabe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "kwak@navercorp.com NAVER Cloud Noah Y. Siegel\u2020siegeln@google.com Google Deepmind Abstract Many recent papers have studied the development of superforecaster-level event forecasting LLMs.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 186, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fef62cd4-9e15-440e-b235-9327c4f3726d": {"__data__": {"id_": "fef62cd4-9e15-440e-b235-9327c4f3726d", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6d937604-5db8-47cc-a662-2b0aa94f3a68", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a97c7ca115db38061667e879b012dcbff60dea9de266cede1194addc0809a0e9", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5b494e927064a8d15ad971603a6ab9cec2ca361819f5d5af8da5fa7b499fdabe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "kwak@navercorp.com NAVER Cloud Noah Y. Siegel\u2020siegeln@google.com Google Deepmind Abstract Many recent papers have studied the development of superforecaster-level event forecasting LLMs. While methodological problems with early studies cast doubt on the use of LLMs for event forecasting, recent studies with improved evaluation methods have shown that state-of- the-art LLMs are gradually reaching superforecaster-level performance, and reinforcement learning has also been reported to improve future forecasting.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 514, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cbf9cf49-855f-454b-822f-a0c688c91f33": {"__data__": {"id_": "cbf9cf49-855f-454b-822f-a0c688c91f33", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fef62cd4-9e15-440e-b235-9327c4f3726d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0106252a0accd07629ddba696a6b0c7ce0a549dc3f34317150fe2d700833fadd", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5b494e927064a8d15ad971603a6ab9cec2ca361819f5d5af8da5fa7b499fdabe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Additionally, the unprecedented success of recent reasoning models and Deep Research-style models suggests that technology capable of greatly improving forecasting performance has been developed. Therefore, based on these positive recent trends, we argue that the time is ripe for research on large-scale training of superforecaster-level event forecasting LLMs. We discuss two key research directions: training methods and data acquisition.", "mimetype": "text/plain", "start_char_idx": 515, "end_char_idx": 956, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef0843ca-0e39-44c4-8f16-d294697f54e7": {"__data__": {"id_": "ef0843ca-0e39-44c4-8f16-d294697f54e7", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cbf9cf49-855f-454b-822f-a0c688c91f33", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a2899245e4a5e6120a17f8b565c7db0f9cfc24d0e60429bfa618271ca59897e4", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5b494e927064a8d15ad971603a6ab9cec2ca361819f5d5af8da5fa7b499fdabe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Therefore, based on these positive recent trends, we argue that the time is ripe for research on large-scale training of superforecaster-level event forecasting LLMs. We discuss two key research directions: training methods and data acquisition. For training, we first introduce three difficulties of LLM-based event forecasting training: noisiness-sparsity, knowledge cut-off, and simple reward structure problems.", "mimetype": "text/plain", "start_char_idx": 711, "end_char_idx": 1126, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b2aa2894-fbb5-490f-9cc2-b42016adc155": {"__data__": {"id_": "b2aa2894-fbb5-490f-9cc2-b42016adc155", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef0843ca-0e39-44c4-8f16-d294697f54e7", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dbe7a19709bc97ca3444b745a741f985f204914edf14ba82f154ee2c0a1d97f5", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5b494e927064a8d15ad971603a6ab9cec2ca361819f5d5af8da5fa7b499fdabe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We discuss two key research directions: training methods and data acquisition. For training, we first introduce three difficulties of LLM-based event forecasting training: noisiness-sparsity, knowledge cut-off, and simple reward structure problems. Then, we present related ideas to mitigate these problems: hypothetical event Bayesian networks, utilizing poorly-recalled and counterfactual events, and auxiliary reward signals.", "mimetype": "text/plain", "start_char_idx": 878, "end_char_idx": 1306, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d8af5298-de5f-499a-9e8b-9df15181ae20": {"__data__": {"id_": "d8af5298-de5f-499a-9e8b-9df15181ae20", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b2aa2894-fbb5-490f-9cc2-b42016adc155", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7cdcef9676e81ce22c12bbc06142e537cd49654f23e5e861fdcb8ac99420bcb4", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5b494e927064a8d15ad971603a6ab9cec2ca361819f5d5af8da5fa7b499fdabe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Then, we present related ideas to mitigate these problems: hypothetical event Bayesian networks, utilizing poorly-recalled and counterfactual events, and auxiliary reward signals. For data, we propose aggressive use of market, public, and crawling datasets to enable large-scale training and evaluation. Finally, we explain how these technical advances could enable AI to provide predictive intelligence to society in broader areas.", "mimetype": "text/plain", "start_char_idx": 1127, "end_char_idx": 1559, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ff9fe6e1-300e-4238-b879-c00fae44e746": {"__data__": {"id_": "ff9fe6e1-300e-4238-b879-c00fae44e746", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d8af5298-de5f-499a-9e8b-9df15181ae20", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "050f3996c98d29413660fc6096cc5a8b1831ccc8cfa433375d0dfe9d560ac2b6", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "3ac06a99-d62a-4b14-8057-5ad071c9a8b2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5b494e927064a8d15ad971603a6ab9cec2ca361819f5d5af8da5fa7b499fdabe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For data, we propose aggressive use of market, public, and crawling datasets to enable large-scale training and evaluation. Finally, we explain how these technical advances could enable AI to provide predictive intelligence to society in broader areas. This position paper presents promising specific paths and considerations for getting closer to superforecaster-level AI technology, aiming to call for researchers\u2019 interest in these directions.", "mimetype": "text/plain", "start_char_idx": 1307, "end_char_idx": 1753, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e8a717d8-1720-4376-956f-aed5bc62ae9c": {"__data__": {"id_": "e8a717d8-1720-4376-956f-aed5bc62ae9c", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0b203616-3a2a-4b73-b264-44ae27413c5a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "41787e373179d7800531033b26bff64a7a89bded72b3506316d99c3b7d9d38b9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This position paper presents promising specific paths and considerations for getting closer to superforecaster-level AI technology, aiming to call for researchers\u2019 interest in these directions. 1 Introduction Future event forecasting is a task of predicting whether specific events will happen in the future, or what the probability of occurrence is, based on information up to a certain point in time (Jin et al., 2021; Zou et al., 2022; Halawi et al., 2024).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 460, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "887ef03b-8d4d-463f-a102-2c7f116ace6a": {"__data__": {"id_": "887ef03b-8d4d-463f-a102-2c7f116ace6a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e8a717d8-1720-4376-956f-aed5bc62ae9c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2461cfaaba0ba1e584775d3134efa93f9578b3d568090c17479f62e4dba1d450", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0b203616-3a2a-4b73-b264-44ae27413c5a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "41787e373179d7800531033b26bff64a7a89bded72b3506316d99c3b7d9d38b9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, consider the question: \u201cToday is December 31st, 2023.", "mimetype": "text/plain", "start_char_idx": 461, "end_char_idx": 527, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cc5a5b22-3ae4-45ad-9cc9-f870fd194fe8": {"__data__": {"id_": "cc5a5b22-3ae4-45ad-9cc9-f870fd194fe8", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "887ef03b-8d4d-463f-a102-2c7f116ace6a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "24d168562093b0c7e632e5e969db0321afc9b48d61666e39fef836a235bba04a", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0b203616-3a2a-4b73-b264-44ae27413c5a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "41787e373179d7800531033b26bff64a7a89bded72b3506316d99c3b7d9d38b9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, consider the question: \u201cToday is December 31st, 2023. Will SpaceX successfully complete an orbital flight\u2014reaching space and circling the Earth\u2014before June 2024?\u201d When solving this task with Large Language Models (LLMs), the widely used approach is Retrieve-Augmented Generation (RAG) (Lewis et al., 2020), whereby relevant news articles and related information are first retrieved, followed by reasoning processes that derive the final answer (Halawi et al., 2024).", "mimetype": "text/plain", "start_char_idx": 461, "end_char_idx": 940, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5b2a83f0-a1cc-48ed-8191-6eb8d509bd8d": {"__data__": {"id_": "5b2a83f0-a1cc-48ed-8191-6eb8d509bd8d", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc5a5b22-3ae4-45ad-9cc9-f870fd194fe8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f24a1665d6e163188791f06a80f446f5cb9c381118a7640713b7e8f97d99b1e9", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0b203616-3a2a-4b73-b264-44ae27413c5a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "41787e373179d7800531033b26bff64a7a89bded72b3506316d99c3b7d9d38b9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "An important goal \u2217corresponding author \u2020Participated only in an advisory capacity.", "mimetype": "text/plain", "start_char_idx": 941, "end_char_idx": 1024, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef6402f4-f7a3-4388-956f-5735811f42b8": {"__data__": {"id_": "ef6402f4-f7a3-4388-956f-5735811f42b8", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5b2a83f0-a1cc-48ed-8191-6eb8d509bd8d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "72da7a9cb63c4562902c3e6f6d4c258942e33ff592f97800a16e41125e2a691f", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0b203616-3a2a-4b73-b264-44ae27413c5a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "41787e373179d7800531033b26bff64a7a89bded72b3506316d99c3b7d9d38b9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "An important goal \u2217corresponding author \u2020Participated only in an advisory capacity. 1v1 [cs.LG] 25 Jul 2025in the future event forecasting field is to make LLMs perform as well as top-level human forecasting experts or collective intelligence of general experts, that is, to make models reach superforecaster-level (Tetlock and Gardner, 2016; Karger et al., 2025; Liptay, 2024a).", "mimetype": "text/plain", "start_char_idx": 941, "end_char_idx": 1320, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fef29f8b-d5d5-4f02-9fe9-9e0ac18bddaf": {"__data__": {"id_": "fef29f8b-d5d5-4f02-9fe9-9e0ac18bddaf", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "518bbff6-f700-466e-ae5e-151ca9c45c9a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e5e58102d8e28b7e262191de99596748c0a564576d0d354712a97ae43d479c5d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since ChatGPT was released (OpenAI, 2022), numerous studies have evaluated LLMs\u2019 event forecasting capabilities and compared them with human performance (Schoenegger et al., 2024; Hsieh et al., 2024). Initially, optimistic reports were shared that LLMs showed performance approaching superforecaster-level (Phan et al., 2024).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 326, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e896a32e-f3b1-4a3d-9e7e-b44a246a9069": {"__data__": {"id_": "e896a32e-f3b1-4a3d-9e7e-b44a246a9069", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fef29f8b-d5d5-4f02-9fe9-9e0ac18bddaf", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "65f6da5ccee4903767835c56af0259becea69cd792ce7e3d03328686a4cb8718", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "518bbff6-f700-466e-ae5e-151ca9c45c9a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e5e58102d8e28b7e262191de99596748c0a564576d0d354712a97ae43d479c5d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Initially, optimistic reports were shared that LLMs showed performance approaching superforecaster-level (Phan et al., 2024). However, subsequent analyses identified methodological issues including insufficient statistical significance, information leakage from data preceding the knowledge cut-off date, and contamination from post-resolution documents in search results, leading to criticism that LLMs\u2019 abilities were overestimated (Lopez-Lira et al., 2025; Bosse et al., 2024).", "mimetype": "text/plain", "start_char_idx": 201, "end_char_idx": 681, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6838372f-1425-4c57-aa9f-c3950828e2c8": {"__data__": {"id_": "6838372f-1425-4c57-aa9f-c3950828e2c8", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e896a32e-f3b1-4a3d-9e7e-b44a246a9069", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "848696887db688d5d1aba866355c3220832ece5bb83373203840fe0543866a85", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "518bbff6-f700-466e-ae5e-151ca9c45c9a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e5e58102d8e28b7e262191de99596748c0a564576d0d354712a97ae43d479c5d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These criticisms resulted in skepticism within the event forecasting community (Paleka et al., 2025a; Matthews, 2025). However, we argue that recent studies provide positive signals for event forecasting. A recent study using more rigorous evaluation methods (Karger et al., 2025) reports that LLM performance in event forecasting is steadily improving with generational advances, and they are getting closer to superforecaster-level.", "mimetype": "text/plain", "start_char_idx": 682, "end_char_idx": 1116, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e2477c6f-c898-452f-966a-287b2097bd04": {"__data__": {"id_": "e2477c6f-c898-452f-966a-287b2097bd04", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6838372f-1425-4c57-aa9f-c3950828e2c8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c3c6203dc10d5cf3a08c2133e5a7ad2d936b06ec9f90a47265cf16caa3487bde", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "518bbff6-f700-466e-ae5e-151ca9c45c9a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e5e58102d8e28b7e262191de99596748c0a564576d0d354712a97ae43d479c5d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A recent study using more rigorous evaluation methods (Karger et al., 2025) reports that LLM performance in event forecasting is steadily improving with generational advances, and they are getting closer to superforecaster-level. Additionally, recent reasoning models like OpenAI o1 and o3 (OpenAI, 2024; 2025a) have shown improved performance compared to previous models (Hickman, 2025), and performance improvements through reinforcement learning (RL) have also been reported (Turtel et al., 2025a;b).", "mimetype": "text/plain", "start_char_idx": 887, "end_char_idx": 1390, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f7afb3af-75f4-40bf-9bf6-97c2be306db0": {"__data__": {"id_": "f7afb3af-75f4-40bf-9bf6-97c2be306db0", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f8949761-d7ef-452b-b6d0-0d1f4c571764", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "98d994daf535408e3d99104325e3503b320f71b2a86dd2d06592422be072bc09", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Furthermore, the unprecedented success of reasoning model with tool-use like OpenAI\u2019s and Gemini\u2019s Deep Research (Citron, 2024; OpenAI, 2025b; Anthropic, 2025) suggests that technology capable of greatly improving forecasting performance has been developed. Based on these recent positive trends, we argue that conditions are now favorable for research on large-scale training of event forecasting LLMs to approach superforecaster-level performance.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 449, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "81a9dff0-d2c8-4e19-b34a-ea54ec89aff4": {"__data__": {"id_": "81a9dff0-d2c8-4e19-b34a-ea54ec89aff4", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f7afb3af-75f4-40bf-9bf6-97c2be306db0", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e7a3f699d53e2a0812e4e50f0bac321aa5e95e53e72f3dc697b72bc934fd37d9", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f8949761-d7ef-452b-b6d0-0d1f4c571764", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "98d994daf535408e3d99104325e3503b320f71b2a86dd2d06592422be072bc09", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Based on these recent positive trends, we argue that conditions are now favorable for research on large-scale training of event forecasting LLMs to approach superforecaster-level performance. This paper presents two key research directions for this purpose: training methodology (Section 4) and large-scale data acquisition (Section 5). For training methodology, we first introduce three unique difficulties in LLM-based event forecasting training.", "mimetype": "text/plain", "start_char_idx": 258, "end_char_idx": 706, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1342e88d-46cb-41fb-a360-5c984b7e4b07": {"__data__": {"id_": "1342e88d-46cb-41fb-a360-5c984b7e4b07", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "81a9dff0-d2c8-4e19-b34a-ea54ec89aff4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5c8f562cb112c7a7c2ac6ff0cdc9fdaa37d1d8424bb1c983928a32c45ef25691", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f8949761-d7ef-452b-b6d0-0d1f4c571764", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "98d994daf535408e3d99104325e3503b320f71b2a86dd2d06592422be072bc09", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This paper presents two key research directions for this purpose: training methodology (Section 4) and large-scale data acquisition (Section 5). For training methodology, we first introduce three unique difficulties in LLM-based event forecasting training. First is the noisiness and sparsity problem, which is the difficulty in learning due to inherent uncertainty in event forecasting outcomes and the sparsity of similar events.", "mimetype": "text/plain", "start_char_idx": 450, "end_char_idx": 881, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "98c4dc26-0fbe-4670-b1b5-d9353b1b19f6": {"__data__": {"id_": "98c4dc26-0fbe-4670-b1b5-d9353b1b19f6", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1342e88d-46cb-41fb-a360-5c984b7e4b07", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f760d83cc0de3944ac0291bf999949f50fac43ad8f7707b8c95bcd44d02cccdf", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f8949761-d7ef-452b-b6d0-0d1f4c571764", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "98d994daf535408e3d99104325e3503b320f71b2a86dd2d06592422be072bc09", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "First is the noisiness and sparsity problem, which is the difficulty in learning due to inherent uncertainty in event forecasting outcomes and the sparsity of similar events. Second is the knowledge cut-off problem, where it is difficult to train or evaluate event forecasting questions about knowledge that LLMs already know internally, greatly limiting usable training data.", "mimetype": "text/plain", "start_char_idx": 707, "end_char_idx": 1083, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "58e79da7-7039-4fe9-93c8-9a4d2119cd19": {"__data__": {"id_": "58e79da7-7039-4fe9-93c8-9a4d2119cd19", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "98c4dc26-0fbe-4670-b1b5-d9353b1b19f6", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6a831be6164f74e37d36c2bf049daf35a0bd9d8b5698e94720acdeebc6a5fff3", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f8949761-d7ef-452b-b6d0-0d1f4c571764", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "98d994daf535408e3d99104325e3503b320f71b2a86dd2d06592422be072bc09", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Second is the knowledge cut-off problem, where it is difficult to train or evaluate event forecasting questions about knowledge that LLMs already know internally, greatly limiting usable training data. Third is the simple reward structure problem, where models can obtain rewards more easily than in other RL tasks without developing proper reasoning capabilities, hindering actual prediction ability improvement. To mitigate these problems, we present several solutions.", "mimetype": "text/plain", "start_char_idx": 882, "end_char_idx": 1353, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d67f47ce-3ca9-4035-95fd-50d76bc5d27a": {"__data__": {"id_": "d67f47ce-3ca9-4035-95fd-50d76bc5d27a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "58e79da7-7039-4fe9-93c8-9a4d2119cd19", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0fe7affb86c9539f968f62c89d0e4570e5c7f8f1ec20afac8b9403cfa1199a5d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f8949761-d7ef-452b-b6d0-0d1f4c571764", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "98d994daf535408e3d99104325e3503b320f71b2a86dd2d06592422be072bc09", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Third is the simple reward structure problem, where models can obtain rewards more easily than in other RL tasks without developing proper reasoning capabilities, hindering actual prediction ability improvement. To mitigate these problems, we present several solutions. We provide theoretical grounds for various training label assignment strategies through hypothetical event Bayesian network modeling, introduce methods of utilizing poorly-recalled data and generating counterfactual events to tackle the knowledge cut-off problem, and discuss ways to solve the simple reward structure problem through auxiliary reward signals and subquestions.", "mimetype": "text/plain", "start_char_idx": 1084, "end_char_idx": 1730, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5aefaae7-5438-4d76-aa50-cea746c00f8c": {"__data__": {"id_": "5aefaae7-5438-4d76-aa50-cea746c00f8c", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5815e249-b092-433f-be95-f8cbe0b3daab", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8b696f514b7a1d29ad8bf9f0d828a9584a96002f79c90366c28812018dea00d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For large-scale data acquisition, we point out that previous research mainly relied on prediction markets and propose aggressive use of three data categories: (1) market dataset - data available from prediction markets like Polymarket and Metaculus, (2) public dataset - structured data available from public databases like GDP and economic indicators, and (3) crawling dataset - unstructured data collected and processed from the web like news.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 445, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bb510eef-d5a7-4b09-9fc6-e91155bceef7": {"__data__": {"id_": "bb510eef-d5a7-4b09-9fc6-e91155bceef7", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5aefaae7-5438-4d76-aa50-cea746c00f8c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7602e701bfea976f51cd3a4685779bbddfa9a609bd4344fc351b268f67154ac0", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5815e249-b092-433f-be95-f8cbe0b3daab", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8b696f514b7a1d29ad8bf9f0d828a9584a96002f79c90366c28812018dea00d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Using these diverse data sources will enable large-scale training and fast evaluation cycles, promoting model performance improvement and development of generalized event forecasting capabilities. Finally, we discuss the broad impacts these technical advances could have on society (Section 6). We examine promising applications, including expanding the scope of AI forecasting, AI-assisted trading systems, future simulation capabilities, and integrating probabilistic reasoning capabilities into general AI agents and AI scientists.", "mimetype": "text/plain", "start_char_idx": 446, "end_char_idx": 980, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e939d74a-1846-4c73-8f6b-9fb5a08e23d5": {"__data__": {"id_": "e939d74a-1846-4c73-8f6b-9fb5a08e23d5", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bb510eef-d5a7-4b09-9fc6-e91155bceef7", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "4d1249f988f2a6feabfa6fcdf3a4c340324e06455b06f00c4eecd31e2f9c6703", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5815e249-b092-433f-be95-f8cbe0b3daab", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8b696f514b7a1d29ad8bf9f0d828a9584a96002f79c90366c28812018dea00d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We examine promising applications, including expanding the scope of AI forecasting, AI-assisted trading systems, future simulation capabilities, and integrating probabilistic reasoning capabilities into general AI agents and AI scientists. We also analyze key challenges, including assessing prediction confidence, user interface design, self-fulfilling prediction effects, and vulnerability to malicious attacks.", "mimetype": "text/plain", "start_char_idx": 741, "end_char_idx": 1154, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a898fed2-472f-49f3-99ac-8fe6cc78117c": {"__data__": {"id_": "a898fed2-472f-49f3-99ac-8fe6cc78117c", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e939d74a-1846-4c73-8f6b-9fb5a08e23d5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "95e9b65360397e4f04539e3798d0a94aa16b66131bb61a1b44028de67ded15a1", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5815e249-b092-433f-be95-f8cbe0b3daab", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8b696f514b7a1d29ad8bf9f0d828a9584a96002f79c90366c28812018dea00d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We also analyze key challenges, including assessing prediction confidence, user interface design, self-fulfilling prediction effects, and vulnerability to malicious attacks. This position paper provides a comprehensive review of event forecasting with LLMs, arguing that recent advances in LLM capabilities have created favorable conditions for large-scale training toward superforecaster- level AI systems.", "mimetype": "text/plain", "start_char_idx": 981, "end_char_idx": 1388, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1793f7cf-183e-4a98-8174-074bc48152bf": {"__data__": {"id_": "1793f7cf-183e-4a98-8174-074bc48152bf", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a898fed2-472f-49f3-99ac-8fe6cc78117c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c0d0f445b51d2b244d5983ceaa4442a146705099a136cf298d330c0bd9deda81", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5815e249-b092-433f-be95-f8cbe0b3daab", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8b696f514b7a1d29ad8bf9f0d828a9584a96002f79c90366c28812018dea00d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This position paper provides a comprehensive review of event forecasting with LLMs, arguing that recent advances in LLM capabilities have created favorable conditions for large-scale training toward superforecaster- level AI systems. We identify and formalize the unique training challenges specific to event forecasting, propose methodological solutions to address these challenges, and develop strategies for performance enhancement 2Term Example Definition Question Today is Dec 12, 2023.", "mimetype": "text/plain", "start_char_idx": 1155, "end_char_idx": 1646, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f9b28e53-7b26-4e01-8e4a-45beb13cc969": {"__data__": {"id_": "f9b28e53-7b26-4e01-8e4a-45beb13cc969", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1793f7cf-183e-4a98-8174-074bc48152bf", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "4302eb7b4f46afa655e984fcc19c14de51640b454acd854a6fe0755e905e083d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5815e249-b092-433f-be95-f8cbe0b3daab", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8b696f514b7a1d29ad8bf9f0d828a9584a96002f79c90366c28812018dea00d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We identify and formalize the unique training challenges specific to event forecasting, propose methodological solutions to address these challenges, and develop strategies for performance enhancement 2Term Example Definition Question Today is Dec 12, 2023. Will SpaceX successfully launch and return a space- craft from Earth orbit by 2024 June?The question which asks about whether a specific event will happen by a certain time. Question date Dec 12, 2023 The date that the question is asked.", "mimetype": "text/plain", "start_char_idx": 1389, "end_char_idx": 1884, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fe584ebf-1e0d-4439-980f-d6d31f5bfb96": {"__data__": {"id_": "fe584ebf-1e0d-4439-980f-d6d31f5bfb96", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f9b28e53-7b26-4e01-8e4a-45beb13cc969", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5b1ae4190c5b104e241afb1eef21366fc5464940b2a25c611bfeacff6dde737d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5815e249-b092-433f-be95-f8cbe0b3daab", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8b696f514b7a1d29ad8bf9f0d828a9584a96002f79c90366c28812018dea00d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Question date Dec 12, 2023 The date that the question is asked. LLM must utilize the knowledge before this date to answer the question.", "mimetype": "text/plain", "start_char_idx": 1821, "end_char_idx": 1956, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cff87716-9c31-4efa-977a-57da71ea9caf": {"__data__": {"id_": "cff87716-9c31-4efa-977a-57da71ea9caf", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b1166cfc-d3a5-4815-acd0-2407106e63f1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "beb2cbd0557b911ff26c6db080858ea162abc3ee5f5d5b6f53f8c1b70c0d0807", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Question date Dec 12, 2023 The date that the question is asked. LLM must utilize the knowledge before this date to answer the question. Therefore, this must be the \u201cevent knowledge cut-off date\u201d for the LLM. Resolution date Mar 14, 2024 The date that the outcome of the event is determined. In other words, the date that the outcome is resolved.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 345, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "82aece2a-57f3-40a3-b965-c1a79180d271": {"__data__": {"id_": "82aece2a-57f3-40a3-b965-c1a79180d271", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cff87716-9c31-4efa-977a-57da71ea9caf", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "320b7f11931c142e12229f2b17ede321f04e4372edc0b82bdc3a4d82f564a8ad", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b1166cfc-d3a5-4815-acd0-2407106e63f1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "beb2cbd0557b911ff26c6db080858ea162abc3ee5f5d5b6f53f8c1b70c0d0807", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Resolution date Mar 14, 2024 The date that the outcome of the event is determined. In other words, the date that the outcome is resolved. Outcome Yes The outcome of the event known and finalized from the resolution date. It remains unknown before the resolution date, leaving the outcome unresolved. LLM knowledge cut-off dateNov 30, 2023 The latest date of the knowledge an LLM is trained on.", "mimetype": "text/plain", "start_char_idx": 208, "end_char_idx": 601, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c0daad12-ed76-45a9-b2ce-079e4927cd52": {"__data__": {"id_": "c0daad12-ed76-45a9-b2ce-079e4927cd52", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "82aece2a-57f3-40a3-b965-c1a79180d271", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "61aa04ab490d2a2a75c93ba9c1e888b7779605621de177f27c1f7825b4883eb4", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b1166cfc-d3a5-4815-acd0-2407106e63f1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "beb2cbd0557b911ff26c6db080858ea162abc3ee5f5d5b6f53f8c1b70c0d0807", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It remains unknown before the resolution date, leaving the outcome unresolved. LLM knowledge cut-off dateNov 30, 2023 The latest date of the knowledge an LLM is trained on. Table 1: Examples and explanations of major terms. The event example is referenced from (Polymarket, 2023). through large-scale dataset expansion.", "mimetype": "text/plain", "start_char_idx": 429, "end_char_idx": 748, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d88747cc-f81d-4571-94b7-4d32f89e6187": {"__data__": {"id_": "d88747cc-f81d-4571-94b7-4d32f89e6187", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c0daad12-ed76-45a9-b2ce-079e4927cd52", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8d9c5f52f71a3349b98c33fb285627526ff277dc3bf820d455b227d122d92a61", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b1166cfc-d3a5-4815-acd0-2407106e63f1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "beb2cbd0557b911ff26c6db080858ea162abc3ee5f5d5b6f53f8c1b70c0d0807", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Table 1: Examples and explanations of major terms. The event example is referenced from (Polymarket, 2023). through large-scale dataset expansion. In addition, we conduct a systematic analysis of the societal implications of event forecasting LLMs, examining both their potential for widespread adoption and associated risks. 2 Background This section provides background on event forecasting using established terminology in the field (Table 1).", "mimetype": "text/plain", "start_char_idx": 602, "end_char_idx": 1048, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d1b99fcd-e0b6-4bc4-b874-e503548a1b2a": {"__data__": {"id_": "d1b99fcd-e0b6-4bc4-b874-e503548a1b2a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d88747cc-f81d-4571-94b7-4d32f89e6187", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d18b1d06eca8d17779d5f94af75450a50c29fcfbaed01dd148313c6a8198a42c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b1166cfc-d3a5-4815-acd0-2407106e63f1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "beb2cbd0557b911ff26c6db080858ea162abc3ee5f5d5b6f53f8c1b70c0d0807", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2 Background This section provides background on event forecasting using established terminology in the field (Table 1). 2.1 Prediction market A prediction market is a platform where users bet on whether specific events will occur. Each market within prediction market platforms corresponds to a specific event and provides market predictions for outcomes at different time periods for that event (Pratt et al., 2024). Market predictions represent the aggregated probability estimates from participants regarding whether a specific event will occur before resolution.", "mimetype": "text/plain", "start_char_idx": 928, "end_char_idx": 1495, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "134ca2a5-6721-444f-8735-3fcbd4279912": {"__data__": {"id_": "134ca2a5-6721-444f-8735-3fcbd4279912", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d1b99fcd-e0b6-4bc4-b874-e503548a1b2a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b59826016d8059c456e86e1b4e9306c04fdabd279429f7b900ddec5c7a14f548", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b1166cfc-d3a5-4815-acd0-2407106e63f1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "beb2cbd0557b911ff26c6db080858ea162abc3ee5f5d5b6f53f8c1b70c0d0807", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Market predictions represent the aggregated probability estimates from participants regarding whether a specific event will occur before resolution. Representative prediction markets include Polymarket, Metaculus, and Manifold Markets. Polymarket uses real money, whereas Metaculus and Manifold Markets use virtual currency.", "mimetype": "text/plain", "start_char_idx": 1347, "end_char_idx": 1671, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c067d04b-7966-4862-9d67-714264a9ba14": {"__data__": {"id_": "c067d04b-7966-4862-9d67-714264a9ba14", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5077d32d-8eb7-4a7e-b626-3736f5ea976e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c96d5fdb583a0a6829c8b79ec59fc5f3244b3a3b6999ca7e1d7793a93c48e6d4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Representative prediction markets include Polymarket, Metaculus, and Manifold Markets. Polymarket uses real money, whereas Metaculus and Manifold Markets use virtual currency. These platforms democratize future knowledge by providing reliable probability estimates for significant global events through various mechanisms (Williams, 2025a; Chen, 2022). For example, Polymarket achieved recognition for delivering more accurate predictions for the 2024 U.S.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 456, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c6fc1767-9a71-474d-a95d-eec42bfdd67d": {"__data__": {"id_": "c6fc1767-9a71-474d-a95d-eec42bfdd67d", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c067d04b-7966-4862-9d67-714264a9ba14", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3759bd2df07a1b30ed455b9847c38206d74ff135223a83cfab38be653631b356", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5077d32d-8eb7-4a7e-b626-3736f5ea976e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c96d5fdb583a0a6829c8b79ec59fc5f3244b3a3b6999ca7e1d7793a93c48e6d4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, Polymarket achieved recognition for delivering more accurate predictions for the 2024 U.S. presidential election compared to expert analysts and political forecasting platforms (Jones, 2024). Prediction markets play a significant role in the field of event forecasting AI. They are widely used as sources of both training and evaluation data for developing such systems.", "mimetype": "text/plain", "start_char_idx": 353, "end_char_idx": 736, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a74a2647-c490-4d09-abaa-43f16952b578": {"__data__": {"id_": "a74a2647-c490-4d09-abaa-43f16952b578", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c6fc1767-9a71-474d-a95d-eec42bfdd67d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "fd5d0ecc3e2be40cb0c21727b32671cd102ced85b34141c30e20d3d0ab00de2c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5077d32d-8eb7-4a7e-b626-3736f5ea976e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c96d5fdb583a0a6829c8b79ec59fc5f3244b3a3b6999ca7e1d7793a93c48e6d4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Prediction markets play a significant role in the field of event forecasting AI. They are widely used as sources of both training and evaluation data for developing such systems. Moreover, matching the forecasting performance of prediction markets and scaling it to a wider range of prediction problems is one of the key motivations for event forecasting AI research.", "mimetype": "text/plain", "start_char_idx": 558, "end_char_idx": 925, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "61f3dbfa-f6f5-4bfb-bcd4-767a0322452a": {"__data__": {"id_": "61f3dbfa-f6f5-4bfb-bcd4-767a0322452a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a74a2647-c490-4d09-abaa-43f16952b578", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e2514ceff89c7565236632926d2f41a8b82469f86407d94f7f59f9918347e468", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5077d32d-8eb7-4a7e-b626-3736f5ea976e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c96d5fdb583a0a6829c8b79ec59fc5f3244b3a3b6999ca7e1d7793a93c48e6d4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "They are widely used as sources of both training and evaluation data for developing such systems. Moreover, matching the forecasting performance of prediction markets and scaling it to a wider range of prediction problems is one of the key motivations for event forecasting AI research. 2.2 Superforecaster Superforecaster (Tetlock and Gardner, 2016) is a term referring to top forecasters who have exceptional talent in prediction compared to the general public.", "mimetype": "text/plain", "start_char_idx": 639, "end_char_idx": 1102, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "659aa38f-8022-4a40-9cb2-48e544b37d93": {"__data__": {"id_": "659aa38f-8022-4a40-9cb2-48e544b37d93", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "61f3dbfa-f6f5-4bfb-bcd4-767a0322452a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dc396d3e9914987108b13dee75e566e3871d24f10cadf4e2a1ec4025e9741be5", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5077d32d-8eb7-4a7e-b626-3736f5ea976e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c96d5fdb583a0a6829c8b79ec59fc5f3244b3a3b6999ca7e1d7793a93c48e6d4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2.2 Superforecaster Superforecaster (Tetlock and Gardner, 2016) is a term referring to top forecasters who have exceptional talent in prediction compared to the general public. The criteria for superforecaster-level vary slightly across different literature and experimental settings, but recent studies define it as the prediction level of collective intelligence of forecasting experts (Karger et al., 2025; Liptay, 2024a).", "mimetype": "text/plain", "start_char_idx": 926, "end_char_idx": 1351, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "17410a37-262c-4bb4-ac80-3131cf1cefbe": {"__data__": {"id_": "17410a37-262c-4bb4-ac80-3131cf1cefbe", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "659aa38f-8022-4a40-9cb2-48e544b37d93", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f8918d8a65cf861c781f393cca2f8e6853384ee1579d05ffe2d5395f9d756226", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5077d32d-8eb7-4a7e-b626-3736f5ea976e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c96d5fdb583a0a6829c8b79ec59fc5f3244b3a3b6999ca7e1d7793a93c48e6d4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Forecasting experts refer to professionals hired as forecasters, while collective intelligence represents the aggregated predictions from multiple experts. 3Karger et al. (2025) asked the general public and forecasting experts a total of 200 questions, with randomly selected 20 questions each, and used their combined answers for comparison with models.", "mimetype": "text/plain", "start_char_idx": 1352, "end_char_idx": 1706, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6fca940a-7f41-4c2d-a5d3-f69b3d1ed098": {"__data__": {"id_": "6fca940a-7f41-4c2d-a5d3-f69b3d1ed098", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07a199dede03ee51c8f457ac0b0d1d0701896839c2e0bf5d17ecbb3db8e37f9f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3Karger et al. (2025) asked the general public and forecasting experts a total of 200 questions, with randomly selected 20 questions each, and used their combined answers for comparison with models. Metaculus AI Benchmarking (Liptay, 2024a; Hickman, 2025) hosted by Metaculus is also an active challenge in this field. In this challenge, the performance of AI systems is compared using approximately 300 questions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 414, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6fec6105-9b7d-470c-a6ce-36ceea0d2491": {"__data__": {"id_": "6fec6105-9b7d-470c-a6ce-36ceea0d2491", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6fca940a-7f41-4c2d-a5d3-f69b3d1ed098", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "4ef0f02cf03d44f88ee9604063141eb2887cb67464d86266c02b1b54f4268a1b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07a199dede03ee51c8f457ac0b0d1d0701896839c2e0bf5d17ecbb3db8e37f9f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In this challenge, the performance of AI systems is compared using approximately 300 questions. Furthermore, the top-performing AI systems from previous competitions are combined into an ensemble, which is then evaluated against groups of approximately 10 expert forecasters using around 100 questions to assess the performance gap. This definition clarifies that, contrary to the common first impression of the term \u201csuperforecaster,\u201d superforecaster-level AI does not mean a prophet who predicts everything perfectly.", "mimetype": "text/plain", "start_char_idx": 319, "end_char_idx": 838, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "91c5d9fe-99e9-4d58-99df-b4bb9029619e": {"__data__": {"id_": "91c5d9fe-99e9-4d58-99df-b4bb9029619e", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6fec6105-9b7d-470c-a6ce-36ceea0d2491", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6d9ae127194a230d8d54049069940d4b4cb88fc83c156fb1b0b6542904c3a02a", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07a199dede03ee51c8f457ac0b0d1d0701896839c2e0bf5d17ecbb3db8e37f9f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This definition clarifies that, contrary to the common first impression of the term \u201csuperforecaster,\u201d superforecaster-level AI does not mean a prophet who predicts everything perfectly. Superforecaster-level simply means the top level of human expert forecasters or the collective intelligence level of expert forecasters.", "mimetype": "text/plain", "start_char_idx": 652, "end_char_idx": 975, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4c8596f3-16b6-4ab3-b9da-f34b710cd6e9": {"__data__": {"id_": "4c8596f3-16b6-4ab3-b9da-f34b710cd6e9", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "91c5d9fe-99e9-4d58-99df-b4bb9029619e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e743f7d7f77f874c4b30600bdbf5f5d9751b98dc53e0aa6b9965529e139ec683", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07a199dede03ee51c8f457ac0b0d1d0701896839c2e0bf5d17ecbb3db8e37f9f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Superforecaster-level simply means the top level of human expert forecasters or the collective intelligence level of expert forecasters. 2.3 Benchmark Static benchmark ForecastQA (Jin et al., 2021), AutoCastQA (Zou et al., 2022), and AutoCast++ (Yan et al., 2024) are early major event forecasting benchmark studies.", "mimetype": "text/plain", "start_char_idx": 839, "end_char_idx": 1155, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "10d56503-07e6-427f-ab7c-06fe148afc35": {"__data__": {"id_": "10d56503-07e6-427f-ab7c-06fe148afc35", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4c8596f3-16b6-4ab3-b9da-f34b710cd6e9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a06f2d05afc3b9c1558d2fca7ea553d86c32f8155e1dcbd7ade1616f5c22eff7", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07a199dede03ee51c8f457ac0b0d1d0701896839c2e0bf5d17ecbb3db8e37f9f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These benchmarks can be classified as static benchmarks because they consist of data from specific periods in the past that have already been resolved (Ye et al., 2024). The main challenge of static benchmarks is that data contamination can easily occur due to the nature of future prediction. If an LLM is developed in 2024 but the evaluation data contains questions about events that occurred in 2023, it cannot be used for evaluation because it may already be contaminated through training.", "mimetype": "text/plain", "start_char_idx": 1156, "end_char_idx": 1649, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "89bb33ac-a79e-44c8-8f66-e0df0fa73c3c": {"__data__": {"id_": "89bb33ac-a79e-44c8-8f66-e0df0fa73c3c", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a3c375a8-9dc5-4a67-b9af-514b1f764e59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b416a75a95d5ab7a878a5a8c7be8fe94e99e47be3540518faa1a760f956ba5c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "If an LLM is developed in 2024 but the evaluation data contains questions about events that occurred in 2023, it cannot be used for evaluation because it may already be contaminated through training. Therefore, static benchmarks soon become outdated and cannot be used to evaluate the latest LLMs. Dynamic benchmark In contrast to static benchmarks, dynamic benchmarks continuously update their question sets and resolution information from the latest databases.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 462, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "90b2626b-b05b-4bc3-b0ab-93d0759e23be": {"__data__": {"id_": "90b2626b-b05b-4bc3-b0ab-93d0759e23be", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89bb33ac-a79e-44c8-8f66-e0df0fa73c3c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "706aa0113a569b4fa7495c07ad9beebc423d13d34dbf3907aa3a75dda02a7292", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a3c375a8-9dc5-4a67-b9af-514b1f764e59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b416a75a95d5ab7a878a5a8c7be8fe94e99e47be3540518faa1a760f956ba5c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Therefore, static benchmarks soon become outdated and cannot be used to evaluate the latest LLMs. Dynamic benchmark In contrast to static benchmarks, dynamic benchmarks continuously update their question sets and resolution information from the latest databases. Here, models answer unresolved questions posted in the database at specific times, and when these questions are resolved after a certain period, the model receives a score based on the resolution outcome. Since previous static benchmarks created reliability issues related to contamination, dynamic benchmarks are considered a major advancement.", "mimetype": "text/plain", "start_char_idx": 200, "end_char_idx": 808, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "07ed3ee9-c6a3-4b5c-98ca-b3d9014df619": {"__data__": {"id_": "07ed3ee9-c6a3-4b5c-98ca-b3d9014df619", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "90b2626b-b05b-4bc3-b0ab-93d0759e23be", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a2f0ee1970db20ef327385b81af98a9b93e41394aad7b1d568e64baf9dd6eb05", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a3c375a8-9dc5-4a67-b9af-514b1f764e59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b416a75a95d5ab7a878a5a8c7be8fe94e99e47be3540518faa1a760f956ba5c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since previous static benchmarks created reliability issues related to contamination, dynamic benchmarks are considered a major advancement. Recently, dynamic benchmarks and related challenges continue to be shared (Karger et al., 2025; Paleka et al., 2025b; Liptay, 2024a). Recent dynamic benchmark studies use market data from prediction markets as a key source for performance evaluation.", "mimetype": "text/plain", "start_char_idx": 668, "end_char_idx": 1059, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "07b5a9e0-bf5e-4da4-9dcf-ba10e87175fb": {"__data__": {"id_": "07b5a9e0-bf5e-4da4-9dcf-ba10e87175fb", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07ed3ee9-c6a3-4b5c-98ca-b3d9014df619", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "bd3c07df5ba12fad1895a14d0d449b4d5e95c01256d809cd8862196118f6df17", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a3c375a8-9dc5-4a67-b9af-514b1f764e59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b416a75a95d5ab7a878a5a8c7be8fe94e99e47be3540518faa1a760f956ba5c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Recent dynamic benchmark studies use market data from prediction markets as a key source for performance evaluation. Metric Benchmarks compare the error between the model\u2019s probability predictions and the actual resolved results using various metrics. The Brier score is a commonly used metric. The Brier score is defined as (f\u2212o)2, wheref\u2208[0,1]is the probabilistic forecast and o\u2208{0,1}is the outcome after the event is resolved.", "mimetype": "text/plain", "start_char_idx": 943, "end_char_idx": 1372, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8fe56c3d-194d-4903-a3ac-371944c5bf77": {"__data__": {"id_": "8fe56c3d-194d-4903-a3ac-371944c5bf77", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07b5a9e0-bf5e-4da4-9dcf-ba10e87175fb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "74aa8f80fcea66755391b63a3636ea8389703548cc67d220520d718a7f8d43d4", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a3c375a8-9dc5-4a67-b9af-514b1f764e59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b416a75a95d5ab7a878a5a8c7be8fe94e99e47be3540518faa1a760f956ba5c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The Brier score is defined as (f\u2212o)2, wheref\u2208[0,1]is the probabilistic forecast and o\u2208{0,1}is the outcome after the event is resolved. Lower Brier scores indicate better performance, and a uniform prediction of 50% creates a Brier score of 0.25 (random baseline).", "mimetype": "text/plain", "start_char_idx": 1238, "end_char_idx": 1501, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0b09c21d-c881-40b8-b873-b0e20d7730d9": {"__data__": {"id_": "0b09c21d-c881-40b8-b873-b0e20d7730d9", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8fe56c3d-194d-4903-a3ac-371944c5bf77", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "da5f903facc4399a3f66f641d6b15a8e64a5ce137505fc94e055be882409a2d2", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a3c375a8-9dc5-4a67-b9af-514b1f764e59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b416a75a95d5ab7a878a5a8c7be8fe94e99e47be3540518faa1a760f956ba5c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Lower Brier scores indicate better performance, and a uniform prediction of 50% creates a Brier score of 0.25 (random baseline). Another metric is the logarithm score, defined as ologf+(1\u2212o)log(1\u2212f). The logarithm score is more sensitive to extreme errors in probability estimates.", "mimetype": "text/plain", "start_char_idx": 1373, "end_char_idx": 1654, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9d8d8f57-95d1-49c8-87e8-fe37cca7127e": {"__data__": {"id_": "9d8d8f57-95d1-49c8-87e8-fe37cca7127e", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2c71a4ba-fb61-4962-bc10-e322980ec04a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2ad1b86c194950b028bc32b84461bc144370c0ca62e260bd70c3c237e9f2d2bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Another metric is the logarithm score, defined as ologf+(1\u2212o)log(1\u2212f). The logarithm score is more sensitive to extreme errors in probability estimates. Expected Calibration Error (ECE) is a metric that measures whether the actual outcome resolution probability of questions the model predicted with probability pis close top.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 326, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "df241559-7c56-43f4-b0c2-7b44caf4371b": {"__data__": {"id_": "df241559-7c56-43f4-b0c2-7b44caf4371b", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9d8d8f57-95d1-49c8-87e8-fe37cca7127e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "cfee8399ad9da97766d31f6b1ab225a1b1d4548077dd73e371437f5ef0bb6e1c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2c71a4ba-fb61-4962-bc10-e322980ec04a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2ad1b86c194950b028bc32b84461bc144370c0ca62e260bd70c3c237e9f2d2bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The logarithm score is more sensitive to extreme errors in probability estimates. Expected Calibration Error (ECE) is a metric that measures whether the actual outcome resolution probability of questions the model predicted with probability pis close top. Generally, specific interval bins (e.g., 5%) are set, and the absolute difference between the actual outcome resolution probabilities for prediction data within that range is used as the average metric. The concurrent position paper by Paleka et al.", "mimetype": "text/plain", "start_char_idx": 71, "end_char_idx": 576, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2179b319-ddfd-43e5-a6b6-67880b53a055": {"__data__": {"id_": "2179b319-ddfd-43e5-a6b6-67880b53a055", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "df241559-7c56-43f4-b0c2-7b44caf4371b", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0c782dab096661294adb7c3347c09230746a95d653ac40d99262317150c0c078", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2c71a4ba-fb61-4962-bc10-e322980ec04a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2ad1b86c194950b028bc32b84461bc144370c0ca62e260bd70c3c237e9f2d2bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Generally, specific interval bins (e.g., 5%) are set, and the absolute difference between the actual outcome resolution probabilities for prediction data within that range is used as the average metric. The concurrent position paper by Paleka et al. (2025a) addresses the difficulties in event forecasting evaluation and provides detailed explanations of these metrics along with comprehensive comparisons of their limitations.", "mimetype": "text/plain", "start_char_idx": 327, "end_char_idx": 754, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0886f1ee-01f2-4054-a49d-a30f2462ed9f": {"__data__": {"id_": "0886f1ee-01f2-4054-a49d-a30f2462ed9f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2179b319-ddfd-43e5-a6b6-67880b53a055", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7a6b602ba7a82f570a613564625894241257a81a4e05e5d033df2d59bcd9d8f1", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2c71a4ba-fb61-4962-bc10-e322980ec04a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2ad1b86c194950b028bc32b84461bc144370c0ca62e260bd70c3c237e9f2d2bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The concurrent position paper by Paleka et al. (2025a) addresses the difficulties in event forecasting evaluation and provides detailed explanations of these metrics along with comprehensive comparisons of their limitations. 2.4 Inference Information retrieval Information retrieval plays an important role in event forecasting systems (Hsieh et al., 2024). The study by Halawi et al. (2024) provides foundational research for current event forecasting and information retrieval pipeline design.", "mimetype": "text/plain", "start_char_idx": 530, "end_char_idx": 1025, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2c8822af-79f7-435b-bac6-e77a454e835e": {"__data__": {"id_": "2c8822af-79f7-435b-bac6-e77a454e835e", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0886f1ee-01f2-4054-a49d-a30f2462ed9f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9566d7dddd39049c64f056d8d3bbd5d35e8c7b4555dfa093722f593ae7a1e758", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2c71a4ba-fb61-4962-bc10-e322980ec04a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2ad1b86c194950b028bc32b84461bc144370c0ca62e260bd70c3c237e9f2d2bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The study by Halawi et al. (2024) provides foundational research for current event forecasting and information retrieval pipeline design. In this study, they used an appropriate LLM-RAG-based pipeline to significantly improve prediction performance compared to cases without search. First, the LLM generates search queries related to the question, which are then used to conduct news searches with the search period restricted to information available before the question date. Then, the retrieved documents are reranked.", "mimetype": "text/plain", "start_char_idx": 888, "end_char_idx": 1409, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9b243eda-64b3-4ebe-890e-e2cf7da7d4fb": {"__data__": {"id_": "9b243eda-64b3-4ebe-890e-e2cf7da7d4fb", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c8822af-79f7-435b-bac6-e77a454e835e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d489bb7b068dce10457d62a3ce1e9e31eb195fe8f4b7510b465bab3e1bf98c21", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2c71a4ba-fb61-4962-bc10-e322980ec04a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2ad1b86c194950b028bc32b84461bc144370c0ca62e260bd70c3c237e9f2d2bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "First, the LLM generates search queries related to the question, which are then used to conduct news searches with the search period restricted to information available before the question date. Then, the retrieved documents are reranked. Finally, answers are generated based on the organized documents.", "mimetype": "text/plain", "start_char_idx": 1171, "end_char_idx": 1474, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "807a94fc-2c07-4fa5-9b7c-f6a16d40b8e1": {"__data__": {"id_": "807a94fc-2c07-4fa5-9b7c-f6a16d40b8e1", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9b243eda-64b3-4ebe-890e-e2cf7da7d4fb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "329067631e3a100553e8f64a525be75c8b54a99bde89421e71a60fe04f277927", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2c71a4ba-fb61-4962-bc10-e322980ec04a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2ad1b86c194950b028bc32b84461bc144370c0ca62e260bd70c3c237e9f2d2bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Then, the retrieved documents are reranked. Finally, answers are generated based on the organized documents. Additionally, Metaculus (Hickman, 2025) 4now provides an integrated information retrieval system with commercial LLM APIs to support forecasting research and practice.1 In practice, ensuring temporal integrity in document retrieval remains a significant challenge in event forecasting systems, particularly when the question date differs from the current time point.", "mimetype": "text/plain", "start_char_idx": 1366, "end_char_idx": 1841, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bf2a084c-54e7-4747-8e04-f4827636db70": {"__data__": {"id_": "bf2a084c-54e7-4747-8e04-f4827636db70", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "37d20bb39b106ec0e6388a83b451491fa699d92274dcad9f660eecdba602b2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It is difficult to guarantee that retrieved documents do not contain information published after the question date, which can lead to data leakage and overestimated performance. Therefore, additional research and system development on future information leakage are required. For example, Wildman et al. (2025) introduced a static benchmark with retrieved documents before the question date for each question using RetroSearch technique (Bosse et al., 2025). 20,000 documents are provided for each question on average.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 518, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fe5f80a4-4584-4cb4-a0f6-c5539025c6bd": {"__data__": {"id_": "fe5f80a4-4584-4cb4-a0f6-c5539025c6bd", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf2a084c-54e7-4747-8e04-f4827636db70", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f670bd161eb1018554eee9fe3d10f1a060133502ff6377ac69d8d3a1a7e5705d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "37d20bb39b106ec0e6388a83b451491fa699d92274dcad9f660eecdba602b2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(2025) introduced a static benchmark with retrieved documents before the question date for each question using RetroSearch technique (Bosse et al., 2025). 20,000 documents are provided for each question on average. On the other hand, Turtel et al. (2025b) reported that they used a specific search API, Exa.ai API, which prevents information leakage.", "mimetype": "text/plain", "start_char_idx": 304, "end_char_idx": 654, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b94fe5c1-8fa1-43b7-9893-b830fcfab3de": {"__data__": {"id_": "b94fe5c1-8fa1-43b7-9893-b830fcfab3de", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fe5f80a4-4584-4cb4-a0f6-c5539025c6bd", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a06572821769489e26ac1a72360b364aed2ba6f1a943fcde6cbce7df1ca63852", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "37d20bb39b106ec0e6388a83b451491fa699d92274dcad9f660eecdba602b2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "20,000 documents are provided for each question on average. On the other hand, Turtel et al. (2025b) reported that they used a specific search API, Exa.ai API, which prevents information leakage. Ensemble Many forecasting studies employ LLM ensemble methods to enhance final performance (Halawi et al., 2024; Karger et al., 2025).", "mimetype": "text/plain", "start_char_idx": 459, "end_char_idx": 789, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4ac0b80f-b80e-489c-b8de-d9856894aa8c": {"__data__": {"id_": "4ac0b80f-b80e-489c-b8de-d9856894aa8c", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b94fe5c1-8fa1-43b7-9893-b830fcfab3de", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f57d6f5d50d81df4a7f2b87d539a8130d77cc636c353b8bf633997674a52e073", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "37d20bb39b106ec0e6388a83b451491fa699d92274dcad9f660eecdba602b2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Ensemble Many forecasting studies employ LLM ensemble methods to enhance final performance (Halawi et al., 2024; Karger et al., 2025). This approach can involve generating multiple predictions from the same model using different prompts or ensembling predictions from multiple distinct models. Schoenegger et al. (2024) investigated ensemble effects using 12 models and compared their performance against human forecasters. Label type This paper explains event forecasting focusing on binary problems.", "mimetype": "text/plain", "start_char_idx": 655, "end_char_idx": 1156, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f1c38983-8d4e-43fd-ae0c-bf32163cd896": {"__data__": {"id_": "f1c38983-8d4e-43fd-ae0c-bf32163cd896", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ac0b80f-b80e-489c-b8de-d9856894aa8c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "fb29a30fdad0798c871a02d52313455e0f1f7dae7e0efde87616cb03ed5329b7", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "37d20bb39b106ec0e6388a83b451491fa699d92274dcad9f660eecdba602b2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Schoenegger et al. (2024) investigated ensemble effects using 12 models and compared their performance against human forecasters. Label type This paper explains event forecasting focusing on binary problems. Many event forecasting studies handle problems in binary classification form, or solve other types of problems by converting them to binary form. However, event forecasting can handle diverse problem types beyond binary classification.", "mimetype": "text/plain", "start_char_idx": 949, "end_char_idx": 1392, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "adf5011f-2293-4bd2-8a97-4b361b4bb6c3": {"__data__": {"id_": "adf5011f-2293-4bd2-8a97-4b361b4bb6c3", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f1c38983-8d4e-43fd-ae0c-bf32163cd896", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2b3f66446ee92edb599001f0695059fd0c5953597a8e3d4658d1fd6c92844501", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "37d20bb39b106ec0e6388a83b451491fa699d92274dcad9f660eecdba602b2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Many event forecasting studies handle problems in binary classification form, or solve other types of problems by converting them to binary form. However, event forecasting can handle diverse problem types beyond binary classification. Multi-option, continuous (usually dates or numbers), entity-type open-ended (similar to multi-option but options are not given as choices), and sentence-type open-ended are problem types that can be handled in event forecasting (Wang et al., 2025).", "mimetype": "text/plain", "start_char_idx": 1157, "end_char_idx": 1641, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7999f46f-e821-46e3-b203-d074345239e1": {"__data__": {"id_": "7999f46f-e821-46e3-b203-d074345239e1", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "adf5011f-2293-4bd2-8a97-4b361b4bb6c3", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "47dc8ee82c54ef3b0a8247a0a069edcc4ca1ca4ec79206de788ddf13816e2dd4", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8005f7a8-6a58-4018-b2d2-c43d4956a5a4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "37d20bb39b106ec0e6388a83b451491fa699d92274dcad9f660eecdba602b2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Most problem types can be relatively easily converted to binary problems.", "mimetype": "text/plain", "start_char_idx": 1642, "end_char_idx": 1715, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e7e6f438-3001-43e9-85ce-4c954cc42ad9": {"__data__": {"id_": "e7e6f438-3001-43e9-85ce-4c954cc42ad9", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0718afa5-46ea-4eda-8c4d-a57fd276fa0f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "784d4395096f346efa94556ffb1cdac53ce54093ee212796ba6335d64356c0bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Most problem types can be relatively easily converted to binary problems. Multi-option or entity-type open-ended problems can be converted to binary problems for each individual option, and continuous problems can be converted to binary problems by dividing the range into appropriate intervals. LLMs can generally perform well across all of these problem types.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 362, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cafb6e9c-8ab2-4de0-97e0-52c4f5f873c3": {"__data__": {"id_": "cafb6e9c-8ab2-4de0-97e0-52c4f5f873c3", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e7e6f438-3001-43e9-85ce-4c954cc42ad9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a3ad1e2db78ab68ba53a2e46a763b91e2486972998070786976ac9e47bcd884d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0718afa5-46ea-4eda-8c4d-a57fd276fa0f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "784d4395096f346efa94556ffb1cdac53ce54093ee212796ba6335d64356c0bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "LLMs can generally perform well across all of these problem types. For example, when asked to infer probabilities of specific dates or numbers (continuous), LLMs can approximate the probability distribution over continuous values by providing probability estimates at regular intervals (e.g., 5% intervals from the 5th to 95th percentile).", "mimetype": "text/plain", "start_char_idx": 296, "end_char_idx": 635, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1566bd9d-d0bc-4db5-b348-ff0f2b1504cd": {"__data__": {"id_": "1566bd9d-d0bc-4db5-b348-ff0f2b1504cd", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cafb6e9c-8ab2-4de0-97e0-52c4f5f873c3", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a69884160b8a4e1e3f902ef1f6a7b1a99747bf6fd01b6e855a07d141ad98a706", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0718afa5-46ea-4eda-8c4d-a57fd276fa0f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "784d4395096f346efa94556ffb1cdac53ce54093ee212796ba6335d64356c0bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "While recent work on training (Halawi et al., 2024; Turtel et al., 2025a;b) for event forecasting have focused on binary outcomes, future work could investigate whether direct training on multi-option or continuous predictions outperforms binarization approaches. Consistency Many reports have mentioned that LLMs exhibit poor consistency in probabilistic reasoning.", "mimetype": "text/plain", "start_char_idx": 636, "end_char_idx": 1002, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c3ace333-fec2-436f-b687-5f84638c3bf9": {"__data__": {"id_": "c3ace333-fec2-436f-b687-5f84638c3bf9", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1566bd9d-d0bc-4db5-b348-ff0f2b1504cd", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f76b0e06d50649c830cbb28549f4420b467bcae5bd4fed82cdeba838b393d7f5", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0718afa5-46ea-4eda-8c4d-a57fd276fa0f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "784d4395096f346efa94556ffb1cdac53ce54093ee212796ba6335d64356c0bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Consistency Many reports have mentioned that LLMs exhibit poor consistency in probabilistic reasoning. The prediction that a candidate will lose by April and the prediction that they will lose after April should sum to 100%, but LLMs often do not (Liptay, 2024b). Lyu et al. (2025) discussed that LLMs have poor probabilistic consistency ability, and suggested the possibility that probability estimation performance could improve if this is handled well.", "mimetype": "text/plain", "start_char_idx": 900, "end_char_idx": 1355, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "01506521-f1d3-4197-a64f-34c6dbe53b75": {"__data__": {"id_": "01506521-f1d3-4197-a64f-34c6dbe53b75", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c3ace333-fec2-436f-b687-5f84638c3bf9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c9ec0ec041787624bfe2bc319d3ba0511da26f26520efa50ab55742236de2b5e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0718afa5-46ea-4eda-8c4d-a57fd276fa0f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "784d4395096f346efa94556ffb1cdac53ce54093ee212796ba6335d64356c0bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Lyu et al. (2025) discussed that LLMs have poor probabilistic consistency ability, and suggested the possibility that probability estimation performance could improve if this is handled well. The winner of Metaculus AI Benchmarking 4Q tackled the consistency problem well to achieve results that surpassed other AI systems (Hickman, 2025).", "mimetype": "text/plain", "start_char_idx": 1164, "end_char_idx": 1503, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8db70806-7aec-4ea4-9ebe-a055a49be4cc": {"__data__": {"id_": "8db70806-7aec-4ea4-9ebe-a055a49be4cc", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "01506521-f1d3-4197-a64f-34c6dbe53b75", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b7ac296a9c99141c18cdafe221b393d966843c63e113fed586a42c6132aafd49", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0718afa5-46ea-4eda-8c4d-a57fd276fa0f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "784d4395096f346efa94556ffb1cdac53ce54093ee212796ba6335d64356c0bc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The winner of Metaculus AI Benchmarking 4Q tackled the consistency problem well to achieve results that surpassed other AI systems (Hickman, 2025). The winner improved model predictions by having the model consider additional related options beyond the two choices presented in binary problems, thereby improving performance in the challenge.", "mimetype": "text/plain", "start_char_idx": 1356, "end_char_idx": 1698, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5c73fba3-4b69-4c3c-bffd-da0e146648d1": {"__data__": {"id_": "5c73fba3-4b69-4c3c-bffd-da0e146648d1", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5dfdb998-f423-445d-8bfc-a68a110eb2db", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07307918ff0274f9f1ad39885c8ed1c467898d130c1371c2971d84e051badeaf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The winner improved model predictions by having the model consider additional related options beyond the two choices presented in binary problems, thereby improving performance in the challenge. For example, if asked whether there would be the first negative GDP growth in the fall, they also asked about growth in winter and summer at the same time. Paleka et al. (2025b), which deeply discussed consistency, not only pointed out existing problems in the event forecasting field but also proposed related datasets.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 515, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "51fe30d5-c30f-4e90-8ccd-170665aa548b": {"__data__": {"id_": "51fe30d5-c30f-4e90-8ccd-170665aa548b", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5c73fba3-4b69-4c3c-bffd-da0e146648d1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "bc3049180ebc452bb670850919bdff34d201b1dfec7f7cd5f67ea94245ebc314", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5dfdb998-f423-445d-8bfc-a68a110eb2db", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07307918ff0274f9f1ad39885c8ed1c467898d130c1371c2971d84e051badeaf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Paleka et al. (2025b), which deeply discussed consistency, not only pointed out existing problems in the event forecasting field but also proposed related datasets. In the proposed dataset, they evaluate whether LLMs follow probabilistic conditions that should be mathematically satisfied for 10 different consistency rules, including negation, paraphrasing, and consequence.", "mimetype": "text/plain", "start_char_idx": 351, "end_char_idx": 726, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d88b291d-e7e2-472e-a1cd-d8528e7b87c4": {"__data__": {"id_": "d88b291d-e7e2-472e-a1cd-d8528e7b87c4", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "51fe30d5-c30f-4e90-8ccd-170665aa548b", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "01cee481fc8856183ea1c63014aba0df9d43a8e485a79869b9704f737d432e4f", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5dfdb998-f423-445d-8bfc-a68a110eb2db", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07307918ff0274f9f1ad39885c8ed1c467898d130c1371c2971d84e051badeaf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In the proposed dataset, they evaluate whether LLMs follow probabilistic conditions that should be mathematically satisfied for 10 different consistency rules, including negation, paraphrasing, and consequence. 3 Past and current state of event forecasting Evaluation problems in previous studies Following the emergence of ChatGPT and similar models, numerous reports emerged claiming that LLM-based systems achieved near-superforecaster performance, 1https://github.com/Metaculus/metac-bot-template/ 5particularly throughout 2024 (Phan et al., 2024).", "mimetype": "text/plain", "start_char_idx": 516, "end_char_idx": 1068, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1de52656-dd9a-45c2-80ea-b3a7aad79d8f": {"__data__": {"id_": "1de52656-dd9a-45c2-80ea-b3a7aad79d8f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d88b291d-e7e2-472e-a1cd-d8528e7b87c4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "4869f06fb7545de902a8bf4fac4853abf8346d8e4a58b5bdb7ede26352cf007d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5dfdb998-f423-445d-8bfc-a68a110eb2db", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07307918ff0274f9f1ad39885c8ed1c467898d130c1371c2971d84e051badeaf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, subsequent analyses identified methodological flaws in these early optimistic analyses (Bosse et al., 2024; Paleka et al., 2025a). First, some studies drew excessive conclusions based on small samples that lacked sufficient statistical power to support their claims.", "mimetype": "text/plain", "start_char_idx": 1069, "end_char_idx": 1344, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "70e3e75a-5eef-4a6c-b798-fa0f3ce85172": {"__data__": {"id_": "70e3e75a-5eef-4a6c-b798-fa0f3ce85172", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1de52656-dd9a-45c2-80ea-b3a7aad79d8f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b08f434d2ccb4826f5aa61b6d877450cc87ef615fcd6a6096c33560678c8a783", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5dfdb998-f423-445d-8bfc-a68a110eb2db", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07307918ff0274f9f1ad39885c8ed1c467898d130c1371c2971d84e051badeaf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "First, some studies drew excessive conclusions based on small samples that lacked sufficient statistical power to support their claims. Second, some studies erroneously used events that were resolved prior to the LLM\u2019s knowledge cut-off as evaluation instances, creating situations where models could simply recall memorized information (Lopez-Lira et al., 2025).", "mimetype": "text/plain", "start_char_idx": 1209, "end_char_idx": 1572, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dc04308a-3eea-4418-ae92-d30d753a0d0d": {"__data__": {"id_": "dc04308a-3eea-4418-ae92-d30d753a0d0d", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "70e3e75a-5eef-4a6c-b798-fa0f3ce85172", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "8edf4ec791fb8dae340f048fa04e56b196d0cee0a49c5a8878294eed66af95e3", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5dfdb998-f423-445d-8bfc-a68a110eb2db", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "07307918ff0274f9f1ad39885c8ed1c467898d130c1371c2971d84e051badeaf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Second, some studies erroneously used events that were resolved prior to the LLM\u2019s knowledge cut-off as evaluation instances, creating situations where models could simply recall memorized information (Lopez-Lira et al., 2025). Third, data contamination cases were also reported where documents from after the prediction resolution time were mixed into search results during web searches (Hendrycks and Mazeika, 2024).", "mimetype": "text/plain", "start_char_idx": 1345, "end_char_idx": 1763, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1fe3ce0b-d366-4501-987a-4bfdf3acf64c": {"__data__": {"id_": "1fe3ce0b-d366-4501-987a-4bfdf3acf64c", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b915ffc9-8d12-45df-9dcd-6789cf6d0126", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "177a810379cfdaafcf26c2600f684a6a8c6792225add313bd88e4224cb1f12dd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Third, data contamination cases were also reported where documents from after the prediction resolution time were mixed into search results during web searches (Hendrycks and Mazeika, 2024). These methodological issues led to criticism that studies systematically overestimated LLM capabilities (Bosse, 2023a).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 310, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c11f5be5-32c5-44b8-b3aa-869d75bd0a34": {"__data__": {"id_": "c11f5be5-32c5-44b8-b3aa-869d75bd0a34", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1fe3ce0b-d366-4501-987a-4bfdf3acf64c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "cf59bb514be68cdc8403bca111824778a85ca425add3e50a1e96d9e54bdbb616", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b915ffc9-8d12-45df-9dcd-6789cf6d0126", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "177a810379cfdaafcf26c2600f684a6a8c6792225add313bd88e4224cb1f12dd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These methodological issues led to criticism that studies systematically overestimated LLM capabilities (Bosse, 2023a). However, Matthews (2025) present a balanced assessment of both promising developments and ongoing challenges in event forecasting, explaining that while there have been limitations in recent academic progress, there are still reasons to pay attention to AI prediction technology development.", "mimetype": "text/plain", "start_char_idx": 191, "end_char_idx": 602, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7d49b8f5-ab44-472e-90f5-ac68db726b50": {"__data__": {"id_": "7d49b8f5-ab44-472e-90f5-ac68db726b50", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c11f5be5-32c5-44b8-b3aa-869d75bd0a34", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "1732504c75d2e89c6a63fd7eecfcde6f9f65438f2121aacbb1b8e4a71c795137", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b915ffc9-8d12-45df-9dcd-6789cf6d0126", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "177a810379cfdaafcf26c2600f684a6a8c6792225add313bd88e4224cb1f12dd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, Matthews (2025) present a balanced assessment of both promising developments and ongoing challenges in event forecasting, explaining that while there have been limitations in recent academic progress, there are still reasons to pay attention to AI prediction technology development. Recent AI performance advances Indeed, positive trends are being observed in recent developments in the event forecasting field, according to recent studies using rigorous evaluation with dynamic benchmarks.", "mimetype": "text/plain", "start_char_idx": 311, "end_char_idx": 810, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a50b5997-c789-484c-892b-ca34806fd4b4": {"__data__": {"id_": "a50b5997-c789-484c-892b-ca34806fd4b4", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7d49b8f5-ab44-472e-90f5-ac68db726b50", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ae53cc340f5b04779de9097aeceec9db0d8df756111b72c605212fd656e862ef", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b915ffc9-8d12-45df-9dcd-6789cf6d0126", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "177a810379cfdaafcf26c2600f684a6a8c6792225add313bd88e4224cb1f12dd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Recent AI performance advances Indeed, positive trends are being observed in recent developments in the event forecasting field, according to recent studies using rigorous evaluation with dynamic benchmarks. The ForecastBench paper (Karger et al., 2025) created a dynamic benchmark and evaluated various LLM systems in summer 2024. They showed that while LLMs are still far from reaching superforecaster-level, LLM performance in event forecasting develops along with LLM performance improvements.", "mimetype": "text/plain", "start_char_idx": 603, "end_char_idx": 1100, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6c2e8972-8180-4956-8458-2f5e2a3ae9fe": {"__data__": {"id_": "6c2e8972-8180-4956-8458-2f5e2a3ae9fe", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a50b5997-c789-484c-892b-ca34806fd4b4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "344952e3bdda8381faa241b8abe78372e679e6ed0ab0202ab6a8790a7a00b623", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b915ffc9-8d12-45df-9dcd-6789cf6d0126", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "177a810379cfdaafcf26c2600f684a6a8c6792225add313bd88e4224cb1f12dd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "They showed that while LLMs are still far from reaching superforecaster-level, LLM performance in event forecasting develops along with LLM performance improvements. Specifically, the authors highlighted strong correlations between event forecasting Brier scores and both (a) Chatbot Arena (Chiang et al., 2024) scores and (b) estimates of pretraining compute, implying that increases in general LLM performance directly affect improvements in event forecasting performance.", "mimetype": "text/plain", "start_char_idx": 935, "end_char_idx": 1409, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7ca6856e-1e79-4780-9597-b70d983ccc81": {"__data__": {"id_": "7ca6856e-1e79-4780-9597-b70d983ccc81", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "e96a93da-42b0-486f-921a-eaefd380df59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5fb382dd16c9102c4ea40976da91321fd5fa47f3d09cc3cf36e01ccd12662480", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Compared to early open-source models like GPT-3.5-Turbo and Llama-2-70B which had Brier scores exceeding 0.2, recent high-performance models like GPT-4o (Brier score 0.133 in the paper) and Claude-3.5-Sonnet (Brier score 0.122) have significantly narrowed the gap to Superforecaster AI (Brier score 0.096).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 306, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c8470257-32dc-40c2-84af-1ce80a7b2311": {"__data__": {"id_": "c8470257-32dc-40c2-84af-1ce80a7b2311", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7ca6856e-1e79-4780-9597-b70d983ccc81", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "08a133eeeafc3298ca67703a4e68cadb8994d4a0021a4cd8cffb5f9da377c859", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "e96a93da-42b0-486f-921a-eaefd380df59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5fb382dd16c9102c4ea40976da91321fd5fa47f3d09cc3cf36e01ccd12662480", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This analysis also evaluated the collective intelligence of the general public, finding that when aggregating forecasts from general public participants, the median prediction achieved a Brier score of 0.121, similar to the best AI level. Generally, collective median predictions offset individual participants\u2019 biases and errors, performing much better than individual predictions; at least in the paper\u2019s benchmark, AI performance has likely already significantly surpassed average individual performance.", "mimetype": "text/plain", "start_char_idx": 307, "end_char_idx": 814, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3bf34f78-400a-4357-817e-ccbd99fabf43": {"__data__": {"id_": "3bf34f78-400a-4357-817e-ccbd99fabf43", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c8470257-32dc-40c2-84af-1ce80a7b2311", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b6cd1a5cc9134b140b424ab8864d2666a1f022b9eab1d69b16b4bc4a39dabf65", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "e96a93da-42b0-486f-921a-eaefd380df59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5fb382dd16c9102c4ea40976da91321fd5fa47f3d09cc3cf36e01ccd12662480", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Generally, collective median predictions offset individual participants\u2019 biases and errors, performing much better than individual predictions; at least in the paper\u2019s benchmark, AI performance has likely already significantly surpassed average individual performance. Furthermore, recent insightful reports on the Metaculus AI Benchmarking Series examine performance differences between evaluation experts and AI systems, sharing the trends that the latest models like OpenAI o1 and o3 (OpenAI, 2024; 2025a) consistently and significantly outperform previous models in these challenges (Liptay, 2024a; Hickman, 2025; Wilson and Bash, 2025; Williams, 2025b).", "mimetype": "text/plain", "start_char_idx": 546, "end_char_idx": 1204, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f456e7c2-6ee0-4349-a699-3d591248fe77": {"__data__": {"id_": "f456e7c2-6ee0-4349-a699-3d591248fe77", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3bf34f78-400a-4357-817e-ccbd99fabf43", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b43f5a6555202ecd439ecc4769ffcb52e498f70de5f52cf04454f50c6f74e882", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "e96a93da-42b0-486f-921a-eaefd380df59", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "5fb382dd16c9102c4ea40976da91321fd5fa47f3d09cc3cf36e01ccd12662480", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Performance improvement through RL Recent achievements by Turtel et al. (2025a;b) regarding training are also noteworthy. These studies showed that reinforcement learning with verifiable rewards (RLVR) (Lambert et al., 2024; Guo et al., 2025) on outcomes can increase model performance.", "mimetype": "text/plain", "start_char_idx": 1205, "end_char_idx": 1491, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "69f22d16-cb3b-4044-833d-88b59cc6c693": {"__data__": {"id_": "69f22d16-cb3b-4044-833d-88b59cc6c693", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "22b58cc1-4f09-4bcd-ae98-ca507709fa3a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ff49a9bb196c5d1311d2ed81a04c0ce6b4c6d000d6d33ba70e1b951d7ce81333", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These studies showed that reinforcement learning with verifiable rewards (RLVR) (Lambert et al., 2024; Guo et al., 2025) on outcomes can increase model performance. They conducted training and evaluation of the R1-14B model based on Polymarket datasets, showing that the R1-14B model with an original Brier score of 0.214 could reach OpenAI o1\u2019s 0.197 level through learning.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 375, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1b42ec54-8165-4702-bbca-52099bdf3c4f": {"__data__": {"id_": "1b42ec54-8165-4702-bbca-52099bdf3c4f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "69f22d16-cb3b-4044-833d-88b59cc6c693", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6dd5ac04886f4ec7178998d732f6f40ce44c7f49fdaff487073119fd4554a503", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "22b58cc1-4f09-4bcd-ae98-ca507709fa3a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ff49a9bb196c5d1311d2ed81a04c0ce6b4c6d000d6d33ba70e1b951d7ce81333", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Furthermore, they showed that additional data augmentation could further slightly improve performance, reduce algorithmic variance, and lower the model\u2019s overall ECE. Additionally, they showed in backtest experiments on Polymarket \u2014 experiments evaluating making money by betting on Polymarket\u2019s market in a virtual environment \u2014 that OpenAI o1 model and their trained algorithms could generate profits. They simulated trading by conducting trades when there were differences between the model\u2019s predicted values and market predicted values.", "mimetype": "text/plain", "start_char_idx": 376, "end_char_idx": 917, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef7c8c26-2e41-4bb4-a26e-50570b057687": {"__data__": {"id_": "ef7c8c26-2e41-4bb4-a26e-50570b057687", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1b42ec54-8165-4702-bbca-52099bdf3c4f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c567f5520868e5e52181f941ab35f31fd76755ec3e50ca9cb4aa56086e786028", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "22b58cc1-4f09-4bcd-ae98-ca507709fa3a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ff49a9bb196c5d1311d2ed81a04c0ce6b4c6d000d6d33ba70e1b951d7ce81333", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "They simulated trading by conducting trades when there were differences between the model\u2019s predicted values and market predicted values. While the long-term viability of LLM-based algorithmic trading in prediction markets requires further validation through real-world implementation, this result supports the argument that trained LLM models are getting closer to superforecaster-level AI.", "mimetype": "text/plain", "start_char_idx": 780, "end_char_idx": 1171, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0e246a18-28de-48c0-a966-d09a06822fd5": {"__data__": {"id_": "0e246a18-28de-48c0-a966-d09a06822fd5", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef7c8c26-2e41-4bb4-a26e-50570b057687", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "b3a2b49599ebc1dd67a880215a2cde94f188fcb6bf59cd07b363b42e5313b350", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "22b58cc1-4f09-4bcd-ae98-ca507709fa3a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ff49a9bb196c5d1311d2ed81a04c0ce6b4c6d000d6d33ba70e1b951d7ce81333", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "While the long-term viability of LLM-based algorithmic trading in prediction markets requires further validation through real-world implementation, this result supports the argument that trained LLM models are getting closer to superforecaster-level AI. Deep Research Recent reasoning models with tool use like Deep Research (Citron, 2024; OpenAI, 2025b; Anthropic, 2025), o3, etc., also have the potential to be a major breakthrough for the event forecasting field.", "mimetype": "text/plain", "start_char_idx": 918, "end_char_idx": 1384, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fc174872-b179-44c1-8143-c7e59c96be01": {"__data__": {"id_": "fc174872-b179-44c1-8143-c7e59c96be01", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0e246a18-28de-48c0-a966-d09a06822fd5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "df4947e4c0e869ec0c823250dff48d922b2f1ef6e760732fc78861eb6482f3cc", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "22b58cc1-4f09-4bcd-ae98-ca507709fa3a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ff49a9bb196c5d1311d2ed81a04c0ce6b4c6d000d6d33ba70e1b951d7ce81333", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "There are grounds to think their model structures could be suitable for event forecasting, especially when they are further trained with event forecasting-specific objective functions.", "mimetype": "text/plain", "start_char_idx": 1385, "end_char_idx": 1569, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f184f6e9-9f46-4a2d-a412-9b8e398f2b00": {"__data__": {"id_": "f184f6e9-9f46-4a2d-a412-9b8e398f2b00", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9ab2e3f1-f9ff-4080-915a-0444f695af0d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "560835adb11b2aff7cb97e3c4232f18b97fb48c7f3b196d7f4b7ffebf9fedb4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "There are grounds to think their model structures could be suitable for event forecasting, especially when they are further trained with event forecasting-specific objective functions. They try various search and reasoning strategies on their own and attempt to solve problems by themselves, departing from the standardized prompt engineering-based or template-based reasoning used previously (Futuresearch, 2025).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 414, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dacb713e-5773-4425-bb40-0accaaa094be": {"__data__": {"id_": "dacb713e-5773-4425-bb40-0accaaa094be", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f184f6e9-9f46-4a2d-a412-9b8e398f2b00", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "311fc0d79647e772a29bc1bb99dc3fd82c97a94ecf8de28c470eed25ac1c08dc", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9ab2e3f1-f9ff-4080-915a-0444f695af0d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "560835adb11b2aff7cb97e3c4232f18b97fb48c7f3b196d7f4b7ffebf9fedb4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "They try various search and reasoning strategies on their own and attempt to solve problems by themselves, departing from the standardized prompt engineering-based or template-based reasoning used previously (Futuresearch, 2025). Furthermore, regression 6tests that infer current data values based on previous data are an important technique in event forecasting, and Deep research models have the capability to perform programming-based regression tests well (Liu et al., 2025).", "mimetype": "text/plain", "start_char_idx": 185, "end_char_idx": 664, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1cb9fe24-627d-40fa-8b2c-4d5734d2eee0": {"__data__": {"id_": "1cb9fe24-627d-40fa-8b2c-4d5734d2eee0", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dacb713e-5773-4425-bb40-0accaaa094be", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a36e946f168ef478535fee08a4f25f25699c51fa79f3377c347712d589532d6b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9ab2e3f1-f9ff-4080-915a-0444f695af0d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "560835adb11b2aff7cb97e3c4232f18b97fb48c7f3b196d7f4b7ffebf9fedb4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Furthermore, regression 6tests that infer current data values based on previous data are an important technique in event forecasting, and Deep research models have the capability to perform programming-based regression tests well (Liu et al., 2025). Therefore, using these models as a foundation model while incorporating event forecasting-specific training and inference strategies could yield substantial performance improvements. Proposal for large-scale training Based on these positive trends, we propose large-scale training for event forecasting LLM development.", "mimetype": "text/plain", "start_char_idx": 415, "end_char_idx": 984, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4980577f-97d2-41ef-a27a-761f41225875": {"__data__": {"id_": "4980577f-97d2-41ef-a27a-761f41225875", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1cb9fe24-627d-40fa-8b2c-4d5734d2eee0", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c5cc40ef9618ea1a0a46f66aa6932e9eee95bb58bfd5899ebad65a092a60b1b1", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9ab2e3f1-f9ff-4080-915a-0444f695af0d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "560835adb11b2aff7cb97e3c4232f18b97fb48c7f3b196d7f4b7ffebf9fedb4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Therefore, using these models as a foundation model while incorporating event forecasting-specific training and inference strategies could yield substantial performance improvements. Proposal for large-scale training Based on these positive trends, we propose large-scale training for event forecasting LLM development. The current situation where model performance continues to improve and various training-related technologies are being developed suggests that opportunities have emerged to close the gap to superforecaster-level performance through comprehensive large-scale training.", "mimetype": "text/plain", "start_char_idx": 665, "end_char_idx": 1252, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "89ca1f59-64b8-4a3f-a0bd-1dc4c18b9c51": {"__data__": {"id_": "89ca1f59-64b8-4a3f-a0bd-1dc4c18b9c51", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4980577f-97d2-41ef-a27a-761f41225875", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "4279e290d737cfe4b18946158d502b778d6ba1e2c4f260fd5433011934cd2be7", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9ab2e3f1-f9ff-4080-915a-0444f695af0d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "560835adb11b2aff7cb97e3c4232f18b97fb48c7f3b196d7f4b7ffebf9fedb4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The current situation where model performance continues to improve and various training-related technologies are being developed suggests that opportunities have emerged to close the gap to superforecaster-level performance through comprehensive large-scale training. We address two key research directions for large-scale training in the next two sections: training (Section 4) and dataset (Section 5). Section 4 covers reward signal strategies and synthetic data generation methods to enhance efficiency within existing datasets, and Section 5 focuses on large-scale data collection.", "mimetype": "text/plain", "start_char_idx": 985, "end_char_idx": 1570, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7412b6d1-756e-41ee-91d3-0f62943e3d09": {"__data__": {"id_": "7412b6d1-756e-41ee-91d3-0f62943e3d09", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89ca1f59-64b8-4a3f-a0bd-1dc4c18b9c51", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "41fc679506946fc87a1e8f4835a0341424cd798369d593b2d91fd9089fe54ead", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9ab2e3f1-f9ff-4080-915a-0444f695af0d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "560835adb11b2aff7cb97e3c4232f18b97fb48c7f3b196d7f4b7ffebf9fedb4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Section 4 covers reward signal strategies and synthetic data generation methods to enhance efficiency within existing datasets, and Section 5 focuses on large-scale data collection. While these approaches can function independently, several algorithms from Section 4 create synergies with Section 5. In particular, solutions for the knowledge cut-off problem discussed in Section 4.2 enable models to effectively learn from historical patterns from the training instances before the knowledge cut-off, as discussed in Section 5.", "mimetype": "text/plain", "start_char_idx": 1389, "end_char_idx": 1917, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ac94e726-9fc9-4598-866c-be5eeb8a19e8": {"__data__": {"id_": "ac94e726-9fc9-4598-866c-be5eeb8a19e8", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "18f3a1f8e8c7ce753494ef62bc38cad38af6f71b21656ff71750140eb0e8572d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In particular, solutions for the knowledge cut-off problem discussed in Section 4.2 enable models to effectively learn from historical patterns from the training instances before the knowledge cut-off, as discussed in Section 5. 4 Training algorithm improvements for future event forecasting In this section, we introduce three difficulties of event forecasting tasks that other AI tasks do not have when it comes to model training.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 432, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "533b5dd0-38da-4d13-9304-7938b016c0da": {"__data__": {"id_": "533b5dd0-38da-4d13-9304-7938b016c0da", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ac94e726-9fc9-4598-866c-be5eeb8a19e8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e9308492cbfe6f212d940e41b60ce80b8e17d40ddfdf284d56ad506772d48634", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "18f3a1f8e8c7ce753494ef62bc38cad38af6f71b21656ff71750140eb0e8572d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4 Training algorithm improvements for future event forecasting In this section, we introduce three difficulties of event forecasting tasks that other AI tasks do not have when it comes to model training. Then, for the purpose of understanding these difficulties and enabling people to think about additional research directions based on this, we introduce several training ideas to mitigate these difficulties. The first training difficulty is the noisiness and sparsity problem of event forecasting outcomes (Kendall and Gal, 2017).", "mimetype": "text/plain", "start_char_idx": 229, "end_char_idx": 762, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e29b52c9-9060-40ab-adb4-31d7d30491a9": {"__data__": {"id_": "e29b52c9-9060-40ab-adb4-31d7d30491a9", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "533b5dd0-38da-4d13-9304-7938b016c0da", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dbb0d6d89ee4e729975225680f12809757e437e80e978adfc5f89f2646221436", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "18f3a1f8e8c7ce753494ef62bc38cad38af6f71b21656ff71750140eb0e8572d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The first training difficulty is the noisiness and sparsity problem of event forecasting outcomes (Kendall and Gal, 2017). For example, consider the problem of predicting the outcome of a US presidential election based on the initial situation. Since we can only make probabilistic inferences, not logical ones, based on information about the initial situation, the prediction label is noisy.", "mimetype": "text/plain", "start_char_idx": 640, "end_char_idx": 1032, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "10cb0e8f-2c50-402c-b7b4-0a46cd655ba2": {"__data__": {"id_": "10cb0e8f-2c50-402c-b7b4-0a46cd655ba2", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e29b52c9-9060-40ab-adb4-31d7d30491a9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7f4aadeb285c678ac97e21deb9d6fd104e5a085328a2740dc5ea0653a1c05779", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "18f3a1f8e8c7ce753494ef62bc38cad38af6f71b21656ff71750140eb0e8572d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since we can only make probabilistic inferences, not logical ones, based on information about the initial situation, the prediction label is noisy. Also, since presidential elections only occur once every four years, similar cases that can be used for training are sparse, making it difficult for models to learn sufficient patterns. We introduce the concept of hypothetical event Bayesian networks that can model this series of problems, and based on this, we discuss what kind of reward signals can be used for training.", "mimetype": "text/plain", "start_char_idx": 885, "end_char_idx": 1407, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5e7c3a27-ab1d-4162-8c57-410c678dc6de": {"__data__": {"id_": "5e7c3a27-ab1d-4162-8c57-410c678dc6de", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10cb0e8f-2c50-402c-b7b4-0a46cd655ba2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "16431fb49f390031dd91addf2db7afd1084e732d6aa4fa14031af99fe96924b7", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "18f3a1f8e8c7ce753494ef62bc38cad38af6f71b21656ff71750140eb0e8572d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We introduce the concept of hypothetical event Bayesian networks that can model this series of problems, and based on this, we discuss what kind of reward signals can be used for training. The second training difficulty is the knowledge cut-off problem, which is the difficulty of training or evaluating event forecasting questions about knowledge that LLMs already know internally. This greatly reduces the amount of data that LLMs can train on.", "mimetype": "text/plain", "start_char_idx": 1219, "end_char_idx": 1665, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f5128987-775b-480e-a9b5-7f162afd1132": {"__data__": {"id_": "f5128987-775b-480e-a9b5-7f162afd1132", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5e7c3a27-ab1d-4162-8c57-410c678dc6de", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "154829653b3426410bb8bfab963dca38de848d981c105626032028109f0c9ee0", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "18f3a1f8e8c7ce753494ef62bc38cad38af6f71b21656ff71750140eb0e8572d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The second training difficulty is the knowledge cut-off problem, which is the difficulty of training or evaluating event forecasting questions about knowledge that LLMs already know internally. This greatly reduces the amount of data that LLMs can train on. As one approach to this problem, we introduce utilizing events that LLMs do not recall well, such as comparative outcomes between two items.", "mimetype": "text/plain", "start_char_idx": 1408, "end_char_idx": 1806, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7bbd5992-de2a-4648-8c84-c9ee77eeee49": {"__data__": {"id_": "7bbd5992-de2a-4648-8c84-c9ee77eeee49", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c66f7c50-d609-4182-af3b-864ded6b5b70", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "853232996bd2020c22e2cfb1adf9568f6c90d0794dd3846a0e84db0b2b88bc47", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This greatly reduces the amount of data that LLMs can train on. As one approach to this problem, we introduce utilizing events that LLMs do not recall well, such as comparative outcomes between two items. As another approach, we present the idea of training counterfactual events together so that models can focus more on search and reasoning.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 343, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dc34b97a-ab03-4082-8cff-a6445520e426": {"__data__": {"id_": "dc34b97a-ab03-4082-8cff-a6445520e426", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7bbd5992-de2a-4648-8c84-c9ee77eeee49", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ae5637882cb531a5c2a192da145a031a669d761e1af0fa9e18c20e7f8332882c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c66f7c50-d609-4182-af3b-864ded6b5b70", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "853232996bd2020c22e2cfb1adf9568f6c90d0794dd3846a0e84db0b2b88bc47", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "As another approach, we present the idea of training counterfactual events together so that models can focus more on search and reasoning. The third training difficulty is the simple reward structure problem, where models can obtain rewards more easily than in other RL tasks without proper reasoning, hindering actual prediction ability improvement. To mitigate this problem, we propose auxiliary label training that can provide additional reward signals.", "mimetype": "text/plain", "start_char_idx": 205, "end_char_idx": 661, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e27f06d3-38b6-4362-bd97-8436a55a2414": {"__data__": {"id_": "e27f06d3-38b6-4362-bd97-8436a55a2414", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dc34b97a-ab03-4082-8cff-a6445520e426", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9b5cfb0f7b59af376295b224f650d4115be2be719f881df020dec3a4d3d237a0", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c66f7c50-d609-4182-af3b-864ded6b5b70", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "853232996bd2020c22e2cfb1adf9568f6c90d0794dd3846a0e84db0b2b88bc47", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To mitigate this problem, we propose auxiliary label training that can provide additional reward signals. One example of auxiliary labels is evaluating the consistency of reasoning, and another is having the model answer additional questions related to the main question. 4.1 Modeling hidden probability of future event forecasting Let\u2019s say we want to train on whether \u201cToday is Dec 12, 2023.", "mimetype": "text/plain", "start_char_idx": 556, "end_char_idx": 949, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5ae7250c-3613-4177-bd2e-498eb743de05": {"__data__": {"id_": "5ae7250c-3613-4177-bd2e-498eb743de05", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e27f06d3-38b6-4362-bd97-8436a55a2414", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "eb2b8d1e2cccaf9b499f3fb21e56188b42a10c68ef66c140b50f29f618873f10", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c66f7c50-d609-4182-af3b-864ded6b5b70", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "853232996bd2020c22e2cfb1adf9568f6c90d0794dd3846a0e84db0b2b88bc47", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.1 Modeling hidden probability of future event forecasting Let\u2019s say we want to train on whether \u201cToday is Dec 12, 2023. Will SpaceX successfully launch and return a spacecraft from Earth orbit by 2024 June?\u201d What should we use as the label for training and what training method should we use?", "mimetype": "text/plain", "start_char_idx": 828, "end_char_idx": 1122, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b52683be-a1cd-40d4-861e-fd619d8b79f5": {"__data__": {"id_": "b52683be-a1cd-40d4-861e-fd619d8b79f5", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5ae7250c-3613-4177-bd2e-498eb743de05", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0ee30fd79e320b7ce524e074c6fb9871210decdb0fd5cefb7351fa4b90c7a196", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c66f7c50-d609-4182-af3b-864ded6b5b70", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "853232996bd2020c22e2cfb1adf9568f6c90d0794dd3846a0e84db0b2b88bc47", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Will SpaceX successfully launch and return a spacecraft from Earth orbit by 2024 June?\u201d What should we use as the label for training and what training method should we use? Timeline: t0(Dec)\u2192t1(Feb)\u2192t2(Mar) Information: S0(initial situation) \u2192S1(intermediate update) \u2192S2(final result) Available: m0(market)\u2192m1(market)\u2192o(outcome) 7S0S1m0m1o Figure 1: A hypothetical event Bayesian network.", "mimetype": "text/plain", "start_char_idx": 950, "end_char_idx": 1338, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f79e69c1-9bac-4083-92a2-1c0e6bf0ee3f": {"__data__": {"id_": "f79e69c1-9bac-4083-92a2-1c0e6bf0ee3f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b52683be-a1cd-40d4-861e-fd619d8b79f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "635ff87d65c677a1e870eb353cb15e64b42f93fb36eddcfc3a40e4d0b6f4c03c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c66f7c50-d609-4182-af3b-864ded6b5b70", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "853232996bd2020c22e2cfb1adf9568f6c90d0794dd3846a0e84db0b2b88bc47", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The state S0at timet0changes to S1at timet1, and the probability of outcome ochanges. At time t0, we get market prediction value m0, and at time t1, we getm1.", "mimetype": "text/plain", "start_char_idx": 1339, "end_char_idx": 1497, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4442f3a1-3dfb-449c-a15d-852e24414c41": {"__data__": {"id_": "4442f3a1-3dfb-449c-a15d-852e24414c41", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "eb5d3a53-a45e-4097-845b-a18ce54f9cec", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f294da9f278345a925ffb9e9116e04ba0344df9c84d710780b6af4c7c5d502ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "At time t0, we get market prediction value m0, and at time t1, we getm1. When training models, the natural and intuitive label in event forecasting is the outcome that can be known after the event is resolved. For example, since SpaceX successfully completed orbital flight on March 14, 2024, the actual outcome is 1.0 (success).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 329, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "02668298-18e8-44bb-93d7-19da4b9b3790": {"__data__": {"id_": "02668298-18e8-44bb-93d7-19da4b9b3790", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4442f3a1-3dfb-449c-a15d-852e24414c41", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "fd795100e47c9e1fdf6ed6461f1184614a6cb91f250c1cff807d9850d6f44344", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "eb5d3a53-a45e-4097-845b-a18ce54f9cec", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f294da9f278345a925ffb9e9116e04ba0344df9c84d710780b6af4c7c5d502ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, since SpaceX successfully completed orbital flight on March 14, 2024, the actual outcome is 1.0 (success). However, if the prediction probability of a training instance becomes 1.0 during the actual training process, it suggests that the LLM may not be conducting good search and reasoning. Since the purpose of training is to generalize search and reasoning abilities, such extreme predictions hinder the development of core abilities in event forecasting.", "mimetype": "text/plain", "start_char_idx": 210, "end_char_idx": 680, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "55b09120-0922-4df4-ad14-50ae22a2f0e2": {"__data__": {"id_": "55b09120-0922-4df4-ad14-50ae22a2f0e2", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "02668298-18e8-44bb-93d7-19da4b9b3790", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2cf47d1570f311c6c9cf957e0503b077929d432287d72d307d0527a589a91b58", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "eb5d3a53-a45e-4097-845b-a18ce54f9cec", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f294da9f278345a925ffb9e9116e04ba0344df9c84d710780b6af4c7c5d502ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since the purpose of training is to generalize search and reasoning abilities, such extreme predictions hinder the development of core abilities in event forecasting. From the perspective of assigning appropriate probabilities to training instances, market prediction obtained from prediction markets would be a good estimate for that event through collective intelligence. However, if we train only on market predictions, it becomes difficult to create event forecasting prediction models that surpass market predictions.", "mimetype": "text/plain", "start_char_idx": 514, "end_char_idx": 1036, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "26e4455f-0d4e-488e-a544-9f5625380731": {"__data__": {"id_": "26e4455f-0d4e-488e-a544-9f5625380731", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "55b09120-0922-4df4-ad14-50ae22a2f0e2", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "41a54f74576861dca5e950f0d44e49afb58e2b45f8cc0e6ca567ce406066b17d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "eb5d3a53-a45e-4097-845b-a18ce54f9cec", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f294da9f278345a925ffb9e9116e04ba0344df9c84d710780b6af4c7c5d502ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, if we train only on market predictions, it becomes difficult to create event forecasting prediction models that surpass market predictions. In this subsection, we first discuss the level of noisiness and sparsity of this problem to explain how this dilemma makes event forecasting problems difficult from a machine learning perspective. Then we introduce hypothetical event Bayesian networks that can theoretically understand this problem.", "mimetype": "text/plain", "start_char_idx": 888, "end_char_idx": 1336, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "509b1e58-b476-4a27-9ded-777abf739514": {"__data__": {"id_": "509b1e58-b476-4a27-9ded-777abf739514", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "26e4455f-0d4e-488e-a544-9f5625380731", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "12f63ac88ecfa22b79216a25de91833873e5285847839e845400bf3fb13c61e3", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "eb5d3a53-a45e-4097-845b-a18ce54f9cec", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f294da9f278345a925ffb9e9116e04ba0344df9c84d710780b6af4c7c5d502ad", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Then we introduce hypothetical event Bayesian networks that can theoretically understand this problem. Based on this conceptual analysis, we discuss how each approach to assigning labels in event forecasting can be explained and what label construction strategies and their variations can be used. 4.1.1 Noisiness and sparsity Event forecasting labels have two difficulties related to uncertainty built into them: the first is noisiness, and the second is sparsity.", "mimetype": "text/plain", "start_char_idx": 1234, "end_char_idx": 1699, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "33348eb5-0677-4387-b789-c9ff60480007": {"__data__": {"id_": "33348eb5-0677-4387-b789-c9ff60480007", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c3852fdd-7c7c-4592-bf72-0a655646bec5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7f477dae4ea6aca24b23eb488c928606ce2b7d75e653ec7af0bb06644a95a123", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.1.1 Noisiness and sparsity Event forecasting labels have two difficulties related to uncertainty built into them: the first is noisiness, and the second is sparsity. Regarding noisiness, consider the problem of predicting which candidate will win the 2024 US presidential election based on information available during the early stages of a competitive electoral campaign.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 374, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ff062373-d901-443d-b8e2-7171d9d6fab4": {"__data__": {"id_": "ff062373-d901-443d-b8e2-7171d9d6fab4", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "33348eb5-0677-4387-b789-c9ff60480007", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "278c73d86977d7ff45c039e2682d77b3a7c0f3bd4cacfe8ecf79db2e909f4998", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c3852fdd-7c7c-4592-bf72-0a655646bec5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7f477dae4ea6aca24b23eb488c928606ce2b7d75e653ec7af0bb06644a95a123", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Regarding noisiness, consider the problem of predicting which candidate will win the 2024 US presidential election based on information available during the early stages of a competitive electoral campaign. No matter how much a smart expert analyzes available information from the early stages of the election, they cannot know for certain who will become president or what the probability is in percent. This means that the outcomes or market predictions we can use are inherently uncertain and noisy in explaining events.", "mimetype": "text/plain", "start_char_idx": 168, "end_char_idx": 691, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3771e800-f5e0-468b-bf9e-66c996acd849": {"__data__": {"id_": "3771e800-f5e0-468b-bf9e-66c996acd849", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ff062373-d901-443d-b8e2-7171d9d6fab4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "72311bf02e0b273738a72d109659b0e7e20a33a54409094bedc77585dab94cfa", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c3852fdd-7c7c-4592-bf72-0a655646bec5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7f477dae4ea6aca24b23eb488c928606ce2b7d75e653ec7af0bb06644a95a123", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This means that the outcomes or market predictions we can use are inherently uncertain and noisy in explaining events. Regarding sparsity, US presidential elections are events that happen once every four years, making them very sparse events. Presidential elections exist for each country and each cycle, so we might be able to achieve generalization through this, but the context of presidential elections differs for each event, and it is difficult to generalize from one case to other cases.", "mimetype": "text/plain", "start_char_idx": 573, "end_char_idx": 1067, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "337584ff-0a73-48fb-98ef-48c0246e2518": {"__data__": {"id_": "337584ff-0a73-48fb-98ef-48c0246e2518", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3771e800-f5e0-468b-bf9e-66c996acd849", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2b06d5ad9765906d5e2fe1f2cbb0151ff063f9934cd2639c75fda14c0285b108", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c3852fdd-7c7c-4592-bf72-0a655646bec5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7f477dae4ea6aca24b23eb488c928606ce2b7d75e653ec7af0bb06644a95a123", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Presidential elections exist for each country and each cycle, so we might be able to achieve generalization through this, but the context of presidential elections differs for each event, and it is difficult to generalize from one case to other cases. Although event frequency varies by domain, this illustrates the inherent sparsity of comparable training instances in event forecasting problems.", "mimetype": "text/plain", "start_char_idx": 816, "end_char_idx": 1213, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2f780ae3-b5b8-4fab-ba53-5bc0e811f981": {"__data__": {"id_": "2f780ae3-b5b8-4fab-ba53-5bc0e811f981", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "337584ff-0a73-48fb-98ef-48c0246e2518", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "70ca8fc7e21f6b522bd78ef04e8cce3dd6dd8d8478100c5cd79d704b00d721dc", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c3852fdd-7c7c-4592-bf72-0a655646bec5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7f477dae4ea6aca24b23eb488c928606ce2b7d75e653ec7af0bb06644a95a123", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Although event frequency varies by domain, this illustrates the inherent sparsity of comparable training instances in event forecasting problems. From a traditional ML perspective, the former (noisiness) corresponds to aleatoric uncertainty, and the latter (sparsity) is related to epistemic uncertainty: events for which we have less data will have higher associated epistemic uncertainty (Kendall and Gal, 2017).", "mimetype": "text/plain", "start_char_idx": 1068, "end_char_idx": 1482, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f77e394c-7c29-4b63-81dc-af15bd0e66f3": {"__data__": {"id_": "f77e394c-7c29-4b63-81dc-af15bd0e66f3", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2f780ae3-b5b8-4fab-ba53-5bc0e811f981", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6d4d468312286f383cb9bb2b760650e992369909eb6883f91b1242946dd4dd83", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c3852fdd-7c7c-4592-bf72-0a655646bec5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7f477dae4ea6aca24b23eb488c928606ce2b7d75e653ec7af0bb06644a95a123", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The combination of these factors means that event forecasting faces higher uncertainty than many other ML problems. 4.1.2 Hypothetical event Bayesian networks We posed the question of what should be used as labels for event forecasting problems at the beginning of this subsection.", "mimetype": "text/plain", "start_char_idx": 1483, "end_char_idx": 1764, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c4b2c7ef-1930-4255-acf6-bc1f652dafdc": {"__data__": {"id_": "c4b2c7ef-1930-4255-acf6-bc1f652dafdc", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "540c70b6-2abc-4c67-9556-0c10b87b742a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7c29efe98bd8eed0c838f7055c5f6bf5efc8cbecbaf8715307e110c2ecccf296", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.1.2 Hypothetical event Bayesian networks We posed the question of what should be used as labels for event forecasting problems at the beginning of this subsection. As a conceptual framework for understanding this problem, let\u2019s construct a simple hypothetical event Bayesian network.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 285, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "13883121-5801-4bbc-84bf-5d235841e0fa": {"__data__": {"id_": "13883121-5801-4bbc-84bf-5d235841e0fa", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c4b2c7ef-1930-4255-acf6-bc1f652dafdc", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d868291feae115b660ae91e50e8d9f3662040802b29ec25093cdd30863d5466a", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "540c70b6-2abc-4c67-9556-0c10b87b742a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7c29efe98bd8eed0c838f7055c5f6bf5efc8cbecbaf8715307e110c2ecccf296", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "As a conceptual framework for understanding this problem, let\u2019s construct a simple hypothetical event Bayesian network. Using the SpaceX example mentioned earlier, we model a situation where there is intermediate information in February ( t1)\u2014the success or failure of initial tests and reports\u2014between the question date t0in December and the resolution date t2in March.", "mimetype": "text/plain", "start_char_idx": 166, "end_char_idx": 536, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6fc6cc15-ff76-46c1-bbd1-3e9458afb757": {"__data__": {"id_": "6fc6cc15-ff76-46c1-bbd1-3e9458afb757", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "13883121-5801-4bbc-84bf-5d235841e0fa", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e4739bf349c8f15b2f29a5e4c40aed2af93ec9a8935f6ff7c60e5cade53b77fe", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "540c70b6-2abc-4c67-9556-0c10b87b742a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7c29efe98bd8eed0c838f7055c5f6bf5efc8cbecbaf8715307e110c2ecccf296", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Using the SpaceX example mentioned earlier, we model a situation where there is intermediate information in February ( t1)\u2014the success or failure of initial tests and reports\u2014between the question date t0in December and the resolution date t2in March. In our model, we define three core probabilities: \u03b1: final success probability when initial test fails (negative), \u03b2: final success probability when initial test succeeds (positive), \u03c0: probability that initial test succeeds (positive).", "mimetype": "text/plain", "start_char_idx": 286, "end_char_idx": 773, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ac8c847f-de9b-4eab-a8f0-66c4cd60c4e3": {"__data__": {"id_": "ac8c847f-de9b-4eab-a8f0-66c4cd60c4e3", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6fc6cc15-ff76-46c1-bbd1-3e9458afb757", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "be0757c24a787f7af8e6fa7ed26a310474ae8b6f222ee8949359db99e49b9c64", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "540c70b6-2abc-4c67-9556-0c10b87b742a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7c29efe98bd8eed0c838f7055c5f6bf5efc8cbecbaf8715307e110c2ecccf296", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In our model, we define three core probabilities: \u03b1: final success probability when initial test fails (negative), \u03b2: final success probability when initial test succeeds (positive), \u03c0: probability that initial test succeeds (positive). Figure 1 is a diagram of our 8hypothetical event Bayesian network.", "mimetype": "text/plain", "start_char_idx": 537, "end_char_idx": 840, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7877ca51-85bd-40d2-96f7-2e6f9f2383b1": {"__data__": {"id_": "7877ca51-85bd-40d2-96f7-2e6f9f2383b1", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ac8c847f-de9b-4eab-a8f0-66c4cd60c4e3", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "bd489127f9867208baf78bb89e80db70285657a8830a301d8a4dd9ef99c37da4", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "540c70b6-2abc-4c67-9556-0c10b87b742a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7c29efe98bd8eed0c838f7055c5f6bf5efc8cbecbaf8715307e110c2ecccf296", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Figure 1 is a diagram of our 8hypothetical event Bayesian network. Equations are as follows: \u03b1=P(o= 1|S1=negative ) \u03b2=P(o= 1|S1=positive ) \u03c0=P(S1=positive|S0=initial ) We seek to estimate an accurate probability for this question. Since the question date is t0, we need to estimate the probability that the outcome will occur at the S0point.", "mimetype": "text/plain", "start_char_idx": 774, "end_char_idx": 1115, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "46ab98fc-8d19-47df-9741-ecb36253fde1": {"__data__": {"id_": "46ab98fc-8d19-47df-9741-ecb36253fde1", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7877ca51-85bd-40d2-96f7-2e6f9f2383b1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "37fd3b18d520de90733f08e586e4924fed601efbfa041c1ce241151df3e72dbc", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "540c70b6-2abc-4c67-9556-0c10b87b742a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7c29efe98bd8eed0c838f7055c5f6bf5efc8cbecbaf8715307e110c2ecccf296", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since the question date is t0, we need to estimate the probability that the outcome will occur at the S0point. We refer to this probability we are interested in as \u201chidden probability.\u201d The hidden probability Phiddenat the question date is as follows: Phidden =P(o= 1|S0=initial ) = (1\u2212\u03c0)\u03b1+\u03c0\u03b2 To estimate Phidden, we cannot observe these underlying probabilities \u03b1,\u03b2, and\u03c0directly, and instead need to infer these probabilities.", "mimetype": "text/plain", "start_char_idx": 1005, "end_char_idx": 1433, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6bda768b-04d6-42e0-a0e0-61b6c2846b7a": {"__data__": {"id_": "6bda768b-04d6-42e0-a0e0-61b6c2846b7a", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "46ab98fc-8d19-47df-9741-ecb36253fde1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2ba6ec8876c4724e8b5f5c974076e8de745bfff30b6eb9d9878b422cf46db1dc", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "540c70b6-2abc-4c67-9556-0c10b87b742a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "7c29efe98bd8eed0c838f7055c5f6bf5efc8cbecbaf8715307e110c2ecccf296", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "One good estimate for Phiddenis a market prediction obtained through the collective intelligence of human forecasters.", "mimetype": "text/plain", "start_char_idx": 1434, "end_char_idx": 1552, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ae37413a-987a-45f1-ac83-85e86906dc24": {"__data__": {"id_": "ae37413a-987a-45f1-ac83-85e86906dc24", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a166db30-c2e0-4ee6-961d-c55174141f73", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "58e7285059a3b17d10ee60b3daf3a0d0275f2038155bd4536679677e87be4872", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "One good estimate for Phiddenis a market prediction obtained through the collective intelligence of human forecasters. Market predictions m0andm1are estimates of P(o= 1|S0)and P(o= 1|S1), respectively, and we can assume they estimate values based on noisy observation of the actual parameters \u03b1,\u03b2, and\u03c0.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 303, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3cec132b-2354-471e-b143-28f66c24ffda": {"__data__": {"id_": "3cec132b-2354-471e-b143-28f66c24ffda", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ae37413a-987a-45f1-ac83-85e86906dc24", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3fd662ba08799ba002cc937138a36657456107f041f7ec028c2bdd6e256fac8d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a166db30-c2e0-4ee6-961d-c55174141f73", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "58e7285059a3b17d10ee60b3daf3a0d0275f2038155bd4536679677e87be4872", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In this hypothetical modeling, we can analyze how the accuracy of Phiddenestimation differs according to noise level and Nby sampling m0,m1,o Ntimes each (i.e., we simulate Nsimilar events, yielding {m0,n,m1,n,on}n=1,\u00b7\u00b7\u00b7,N).Nrepresents the number of hypothetical simulation trials.", "mimetype": "text/plain", "start_char_idx": 304, "end_char_idx": 585, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "784e4f95-3d47-4c94-8bcb-b3ffc2b20b99": {"__data__": {"id_": "784e4f95-3d47-4c94-8bcb-b3ffc2b20b99", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3cec132b-2354-471e-b143-28f66c24ffda", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "75c225e75a24259d749e6142176fda0d4394eef730d81784dbe99f79a954a744", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a166db30-c2e0-4ee6-961d-c55174141f73", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "58e7285059a3b17d10ee60b3daf3a0d0275f2038155bd4536679677e87be4872", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, in each trial,S1is sampled as positive with probability \u03c0. We can then compute separate estimates of Phidden by averaging the m0values,m1values, and ovalues, respectively (i.e.,1 N/summationtextN n=1m0,n,1 N/summationtextN n=1m1,n, and 1 N/summationtextN n=1on).", "mimetype": "text/plain", "start_char_idx": 586, "end_char_idx": 861, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "78b4572e-8d75-486c-b0cc-d001f906f947": {"__data__": {"id_": "78b4572e-8d75-486c-b0cc-d001f906f947", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "784e4f95-3d47-4c94-8bcb-b3ffc2b20b99", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ff91c39e2b45460d8fbf66b1824f64d0b3ebe50648a59657c219853e076d9bf6", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a166db30-c2e0-4ee6-961d-c55174141f73", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "58e7285059a3b17d10ee60b3daf3a0d0275f2038155bd4536679677e87be4872", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "How does the relative accuracy of each estimate differ at different Nvalues? First, let\u2019s think about the case whereN= 1. Sinceohas values of 0.0 or 1.0, there will be a considerable gap from Phidden. In this case, m0 is likely to be a much stronger estimate than o. However, let\u2019s think about the case where Nis sufficiently large.", "mimetype": "text/plain", "start_char_idx": 862, "end_char_idx": 1194, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9a3e3c8f-fbba-4417-8877-018258745278": {"__data__": {"id_": "9a3e3c8f-fbba-4417-8877-018258745278", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "78b4572e-8d75-486c-b0cc-d001f906f947", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "90b8e2718a19633c4f0adab865be53a48d5539846e74e359cf9ff6678798664e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a166db30-c2e0-4ee6-961d-c55174141f73", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "58e7285059a3b17d10ee60b3daf3a0d0275f2038155bd4536679677e87be4872", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In this case, m0 is likely to be a much stronger estimate than o. However, let\u2019s think about the case where Nis sufficiently large. The estimation of m0contains prediction uncertainty noise, and this noise will slow convergence to Phidden.", "mimetype": "text/plain", "start_char_idx": 1063, "end_char_idx": 1302, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ab98e195-eb5e-4ed6-9a70-d344757e63bf": {"__data__": {"id_": "ab98e195-eb5e-4ed6-9a70-d344757e63bf", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2ba5b336-cde8-49ef-a2f5-c655bbf4b151", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a2a5d57ba34b250693698c7b9e2fff62e3262c0ca3b1ea267a58929db94062cf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The estimation of m0contains prediction uncertainty noise, and this noise will slow convergence to Phidden. In this case, owill be a better estimate compared to m0. Can we use m1to estimate Phidden? Market predictions at the intermediate time m1occupy a middle ground betweenm0ando. Unlikem0, which must account for uncertainty about whether the intermediate state S1 will be positive or negative, m1is made after this uncertainty is resolved.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 443, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d85a4458-1a16-4407-ade7-3c2b5aa33bdb": {"__data__": {"id_": "d85a4458-1a16-4407-ade7-3c2b5aa33bdb", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ab98e195-eb5e-4ed6-9a70-d344757e63bf", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c23544a7bbfd3f4fa66f306068fc41bc824daa7eb1da477b1e1b997c5851418b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2ba5b336-cde8-49ef-a2f5-c655bbf4b151", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a2a5d57ba34b250693698c7b9e2fff62e3262c0ca3b1ea267a58929db94062cf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Unlikem0, which must account for uncertainty about whether the intermediate state S1 will be positive or negative, m1is made after this uncertainty is resolved. However, unlike the final outcome o, m1still reflects the collective judgment of forecasters rather than a binary result.", "mimetype": "text/plain", "start_char_idx": 283, "end_char_idx": 565, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7952f00d-bbc1-4a84-9017-c477ea9100bc": {"__data__": {"id_": "7952f00d-bbc1-4a84-9017-c477ea9100bc", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d85a4458-1a16-4407-ade7-3c2b5aa33bdb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f3b3748cd6f5a4a95d3a4b059d6f923dcdf5a8a306f20ba7144ae6069121e9a8", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2ba5b336-cde8-49ef-a2f5-c655bbf4b151", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a2a5d57ba34b250693698c7b9e2fff62e3262c0ca3b1ea267a58929db94062cf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, unlike the final outcome o, m1still reflects the collective judgment of forecasters rather than a binary result. This positioning can make m1a superior estimate of Phiddenunder certain conditions, particularly when there is significant uncertainty in the transition from S0toS1(high estimation error for \u03c0) and when we have a moderate number of observations N. We provide detailed assumptions and simulation results demonstrating these trade-offs in Appendix A. Based on the hypothetical settings discussed above, let\u2019s now consider real scenarios of event forecasting tasks and address the question of whether to use outcome oor market prediction m0.", "mimetype": "text/plain", "start_char_idx": 444, "end_char_idx": 1104, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e4ed83f7-38fa-4f45-9736-8eca5668e997": {"__data__": {"id_": "e4ed83f7-38fa-4f45-9736-8eca5668e997", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7952f00d-bbc1-4a84-9017-c477ea9100bc", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2c8f82408db27fff3b89d70d8e92a6886bbcc9ddd0797acbdf9c58b2ed0b3cb3", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2ba5b336-cde8-49ef-a2f5-c655bbf4b151", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a2a5d57ba34b250693698c7b9e2fff62e3262c0ca3b1ea267a58929db94062cf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Applying the hypothetical event Bayesian network framework, for data where there are few similar problems in the training data (small N), it would be good to use market prediction m0at question date time t0, and for cases where there are many similar problems (large N), it would be good to use outcome oat resolution date time t2. In practice, using both together could also be a way to get better estimates in some cases.", "mimetype": "text/plain", "start_char_idx": 1105, "end_char_idx": 1528, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b1d619cb-53e3-46f0-b0ad-a4372afa43d0": {"__data__": {"id_": "b1d619cb-53e3-46f0-b0ad-a4372afa43d0", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ad3be8a6-aac9-451d-8483-8b16fc4671ff", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c573696465a96adcc30831ce133319655835a555c85b0bdefdefe3be3dc5f5a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In practice, using both together could also be a way to get better estimates in some cases. According to the simulation in Appendix A, interestingly, there are also cases where using the market prediction value m1at timet1 betweent0andt2as a label for questions at time t0has advantages, and m1does not function merely as an approximation of o. The next subsubsection examines label assignment strategies that can be used based on this discussion.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 447, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8916e982-5a90-4d15-969c-65e7f0e0a16c": {"__data__": {"id_": "8916e982-5a90-4d15-969c-65e7f0e0a16c", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1d619cb-53e3-46f0-b0ad-a4372afa43d0", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e87db552aa3c00d18da8e651f62d6ecc9b6c2113689d9837b0313983a118a315", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ad3be8a6-aac9-451d-8483-8b16fc4671ff", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c573696465a96adcc30831ce133319655835a555c85b0bdefdefe3be3dc5f5a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.1.3 Outcome as a reward signal The most direct method in event forecasting is using outcomes as rewards in RL. For example, we can use the negative Brier score between the probability predicted by the model and the actual outcome as a reward term (Turtel et al., 2025b), or give higher rewards to predictions closer to outcomes (Turtel et al., 2025a). 9Turtel et al.", "mimetype": "text/plain", "start_char_idx": 448, "end_char_idx": 816, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0ae4b470-79c3-4f69-bdac-bd5915ee5223": {"__data__": {"id_": "0ae4b470-79c3-4f69-bdac-bd5915ee5223", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8916e982-5a90-4d15-969c-65e7f0e0a16c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9af8f12a132b8cfab1fbfa27f71f3928d2244b41d87b45684dbd95c71e42646a", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ad3be8a6-aac9-451d-8483-8b16fc4671ff", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c573696465a96adcc30831ce133319655835a555c85b0bdefdefe3be3dc5f5a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "9Turtel et al. (2025b;a) achieved 5-10% Brier score improvement with training on outcomes; using outcomes in situations where an appropriately scaled dataset is secured can be a powerful baseline and practical approach. However, outcome-based training has the risk of models making extreme predictions approaching 0% or 100% after sufficient training epochs (Turtel et al., 2025b).", "mimetype": "text/plain", "start_char_idx": 802, "end_char_idx": 1183, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d638a830-8ac5-4174-82a7-be5eaf341ee4": {"__data__": {"id_": "d638a830-8ac5-4174-82a7-be5eaf341ee4", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0ae4b470-79c3-4f69-bdac-bd5915ee5223", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "adf0741da91f017e0db8f3bfc1ac31a374aea49905d522ee809872c898d75f60", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ad3be8a6-aac9-451d-8483-8b16fc4671ff", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c573696465a96adcc30831ce133319655835a555c85b0bdefdefe3be3dc5f5a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, outcome-based training has the risk of models making extreme predictions approaching 0% or 100% after sufficient training epochs (Turtel et al., 2025b). More importantly, extreme predictions approaching 0% or 100% are likely signals that the LLM is not actually performing proper search and reasoning.", "mimetype": "text/plain", "start_char_idx": 1022, "end_char_idx": 1332, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8605bedc-51ff-4e99-b9f0-86888e23332d": {"__data__": {"id_": "8605bedc-51ff-4e99-b9f0-86888e23332d", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d638a830-8ac5-4174-82a7-be5eaf341ee4", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "40f611349cc5a2b2dcfbb799ae220e5d096a6003c51187b943093d3e726082b5", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "ad3be8a6-aac9-451d-8483-8b16fc4671ff", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c573696465a96adcc30831ce133319655835a555c85b0bdefdefe3be3dc5f5a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "More importantly, extreme predictions approaching 0% or 100% are likely signals that the LLM is not actually performing proper search and reasoning. The ultimate goal of event forecasting training is to learn good search and reasoning abilities and transfer them to test inference time, but extreme predictions hinder the development of these core abilities. Various regularization methods, such as early stopping, can be used to prevent this.", "mimetype": "text/plain", "start_char_idx": 1184, "end_char_idx": 1627, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f05a8110-c1e8-44c1-8148-cf387813423c": {"__data__": {"id_": "f05a8110-c1e8-44c1-8148-cf387813423c", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "11edbd09-dceb-4d7a-936d-c5b63e1320cb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c4f2bf40801c732be905b4413f2e306b24e33e769f8b2c770ea70218e37119a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Various regularization methods, such as early stopping, can be used to prevent this. 4.1.4 Market prediction as a reward signal Prediction markets serve as effective platforms for obtaining expert estimates of hidden probability Phidden in a scalable way. Each market prediction is a good estimate for that event, and from the hypothetical event Bayesian network perspective discussed earlier, it is an advantageous estimate to use when similar events occur infrequently.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 471, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e426f93a-2cdd-4643-a68e-aed3ac84197f": {"__data__": {"id_": "e426f93a-2cdd-4643-a68e-aed3ac84197f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f05a8110-c1e8-44c1-8148-cf387813423c", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "606ef049b3024885bdcda6f6082378f230135987c44828b0f0b540fd4357f515", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "11edbd09-dceb-4d7a-936d-c5b63e1320cb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c4f2bf40801c732be905b4413f2e306b24e33e769f8b2c770ea70218e37119a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Each market prediction is a good estimate for that event, and from the hypothetical event Bayesian network perspective discussed earlier, it is an advantageous estimate to use when similar events occur infrequently. However, if we train only with market prediction, it becomes difficult to create event forecasting prediction models that surpass market prediction. Therefore, market prediction should be used as a reward signal in parallel with outcomes. In the research by Halawi et al.", "mimetype": "text/plain", "start_char_idx": 256, "end_char_idx": 743, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "39f03018-d143-4b90-96e0-1c72f0a252fd": {"__data__": {"id_": "39f03018-d143-4b90-96e0-1c72f0a252fd", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e426f93a-2cdd-4643-a68e-aed3ac84197f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d60fe540dcef365dd4b6b3faad5a63d4d6b862730ba5bc0d65990d05077fbcd3", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "11edbd09-dceb-4d7a-936d-c5b63e1320cb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c4f2bf40801c732be905b4413f2e306b24e33e769f8b2c770ea70218e37119a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Therefore, market prediction should be used as a reward signal in parallel with outcomes. In the research by Halawi et al. (2024), they used a specific interval between market prediction and outcome as the ground truth label. Specifically, they defined a 15% interval from the market prediction value in the direction of the actual outcome, and treated predictions within this range as correct answers.", "mimetype": "text/plain", "start_char_idx": 621, "end_char_idx": 1023, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d31452c3-fad9-4265-a515-982d866fe71f": {"__data__": {"id_": "d31452c3-fad9-4265-a515-982d866fe71f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "39f03018-d143-4b90-96e0-1c72f0a252fd", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "255ebe8040fbbd1ea13fa67861762cb6ef6f4139fb754f22ae71c7508e4e72d0", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "11edbd09-dceb-4d7a-936d-c5b63e1320cb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c4f2bf40801c732be905b4413f2e306b24e33e769f8b2c770ea70218e37119a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Specifically, they defined a 15% interval from the market prediction value in the direction of the actual outcome, and treated predictions within this range as correct answers. For example, if market prediction is 60% and outcome is 100%, they treated model predictions between 60% and 75% as correct. Additionally, various other methods for using market prediction and outcomes together in training can be considered.", "mimetype": "text/plain", "start_char_idx": 847, "end_char_idx": 1265, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c8a98fbf-eb5b-49cf-ae46-79e8fa49ad83": {"__data__": {"id_": "c8a98fbf-eb5b-49cf-ae46-79e8fa49ad83", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d31452c3-fad9-4265-a515-982d866fe71f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c4f77977b8c6c4009b5f1c62b156a676cf2b7f057e3b24449cbba71282121926", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "11edbd09-dceb-4d7a-936d-c5b63e1320cb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c4f2bf40801c732be905b4413f2e306b24e33e769f8b2c770ea70218e37119a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Additionally, various other methods for using market prediction and outcomes together in training can be considered. One method involves adding a KL-divergence term between model predictions and market predictions to the objective function, alongside the existing outcome-based reward signal. In another method, market predictions can be included directly as model inputs. The reliability of each market is also an important consideration. For example, markets with limited participation may exhibit higher noise levels (Bosse, 2023b).", "mimetype": "text/plain", "start_char_idx": 1149, "end_char_idx": 1684, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8275affe-d885-49c8-8008-fa2f9a85e949": {"__data__": {"id_": "8275affe-d885-49c8-8008-fa2f9a85e949", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c8a98fbf-eb5b-49cf-ae46-79e8fa49ad83", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ca33fd32899d53edce10bdb11568ce3291c8df7f1872774447af9f7af454033f", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "11edbd09-dceb-4d7a-936d-c5b63e1320cb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c4f2bf40801c732be905b4413f2e306b24e33e769f8b2c770ea70218e37119a6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In another method, market predictions can be included directly as model inputs. The reliability of each market is also an important consideration. For example, markets with limited participation may exhibit higher noise levels (Bosse, 2023b). In (Halawi et al., 2024), they filtered out market data with few participants.", "mimetype": "text/plain", "start_char_idx": 1442, "end_char_idx": 1763, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "99e02a18-40e1-41b6-96cf-c723ea00d9eb": {"__data__": {"id_": "99e02a18-40e1-41b6-96cf-c723ea00d9eb", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dc2f2b9c372f1d9b1dd4428e764f0e75e04ea2fce032313058b2889fae33d700", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, markets with limited participation may exhibit higher noise levels (Bosse, 2023b). In (Halawi et al., 2024), they filtered out market data with few participants. Market reliability can be incorporated based on the specific approach used for market prediction. When using KL-divergence, the weight on the KL-divergence can be reduced for training instances corresponding to markets with few participants.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 416, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f5130f5e-b5f9-4e70-b3f0-9f2013d4e2af": {"__data__": {"id_": "f5130f5e-b5f9-4e70-b3f0-9f2013d4e2af", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "99e02a18-40e1-41b6-96cf-c723ea00d9eb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "71bc5177e5cad3dc74ef8a86ad9b32a249693d7d2057c43709ce853726414800", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dc2f2b9c372f1d9b1dd4428e764f0e75e04ea2fce032313058b2889fae33d700", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Market reliability can be incorporated based on the specific approach used for market prediction. When using KL-divergence, the weight on the KL-divergence can be reduced for training instances corresponding to markets with few participants. When inputting market prediction values, related information about reliability can also be added together. Market predictions are available only when a prediction market exists for the specific event in question.", "mimetype": "text/plain", "start_char_idx": 175, "end_char_idx": 629, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2f705498-ca27-4f7c-9fd5-5f770ca72e64": {"__data__": {"id_": "2f705498-ca27-4f7c-9fd5-5f770ca72e64", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f5130f5e-b5f9-4e70-b3f0-9f2013d4e2af", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0889a45af90d76a21102c69d5a4409791e338249df03ca1f3cd536cb069cd0d1", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dc2f2b9c372f1d9b1dd4428e764f0e75e04ea2fce032313058b2889fae33d700", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "When inputting market prediction values, related information about reliability can also be added together. Market predictions are available only when a prediction market exists for the specific event in question. When training on datasets containing both instances with available market predictions and instances without market data, reward signals derived from market predictions would be applied solely to those training instances where market prediction values are available.", "mimetype": "text/plain", "start_char_idx": 417, "end_char_idx": 895, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e66b0dee-d1fd-4330-9d19-def6628417b8": {"__data__": {"id_": "e66b0dee-d1fd-4330-9d19-def6628417b8", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2f705498-ca27-4f7c-9fd5-5f770ca72e64", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f9ddb9fb32792131665d0f5c3b164a39cf75e14c8579f98c9fafe0be67a8c595", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dc2f2b9c372f1d9b1dd4428e764f0e75e04ea2fce032313058b2889fae33d700", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "When training on datasets containing both instances with available market predictions and instances without market data, reward signals derived from market predictions would be applied solely to those training instances where market prediction values are available. 4.1.5 Using prediction after the question time A considerable number of event forecasting questions in the world may not have outcomes determined yet at the current time point when we are training.", "mimetype": "text/plain", "start_char_idx": 630, "end_char_idx": 1093, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "73c3b4ce-76eb-412d-a7a7-a138434ac2eb": {"__data__": {"id_": "73c3b4ce-76eb-412d-a7a7-a138434ac2eb", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e66b0dee-d1fd-4330-9d19-def6628417b8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "2666ed26db78e7139b21064276888fd85b02ec991fc25d96eee71ca500957190", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dc2f2b9c372f1d9b1dd4428e764f0e75e04ea2fce032313058b2889fae33d700", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.1.5 Using prediction after the question time A considerable number of event forecasting questions in the world may not have outcomes determined yet at the current time point when we are training. Also, these forecasting questions may not have clearly defined resolution conditions, or there may be no pipeline to automatically extract outcomes for data construction because events are not registered in markets or databases. Can we train from such data where outcomes are not clearly obtained?", "mimetype": "text/plain", "start_char_idx": 896, "end_char_idx": 1391, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "46c2615c-9ce0-4efa-96fa-3678f0edf050": {"__data__": {"id_": "46c2615c-9ce0-4efa-96fa-3678f0edf050", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73c3b4ce-76eb-412d-a7a7-a138434ac2eb", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "1c510ba1a73583a9cb9d601871e9917e920aa47b0d584e90af94bcf911c7d4b6", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "dc2f2b9c372f1d9b1dd4428e764f0e75e04ea2fce032313058b2889fae33d700", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Can we train from such data where outcomes are not clearly obtained? If we can obtain market prediction m1at time point t1after question date t0, we can obtain reward signals from such data as well. There are two perspectives we can think about regarding the validity of using m1. The first is thinking of m1as a more accurate approximation of othanm0.", "mimetype": "text/plain", "start_char_idx": 1323, "end_char_idx": 1675, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "728835ac-2a2d-4994-87c0-9468e82f4dba": {"__data__": {"id_": "728835ac-2a2d-4994-87c0-9468e82f4dba", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "55f139d1-e089-4158-875f-be649f023996", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a63d187fbccb82a5b77faf9ae1991f5d018bd291b44490bbd745b5eb9c7b04ac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "There are two perspectives we can think about regarding the validity of using m1. The first is thinking of m1as a more accurate approximation of othanm0. Especially if the value of m1is close to 0.0 or 1.0, and if m1\u2019s estimation of ois close to unbiased (if the model\u2019s ECE is low), we can statistically say thatopredicts well at the probability that m1suggests.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 363, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "139e6c95-59e4-4b78-9e3e-9549c1d0722b": {"__data__": {"id_": "139e6c95-59e4-4b78-9e3e-9549c1d0722b", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "728835ac-2a2d-4994-87c0-9468e82f4dba", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "0d63882e6890027fe35b42fa94ec1cf354b8e598a56ef7074c311bedfdbdbe63", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "55f139d1-e089-4158-875f-be649f023996", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a63d187fbccb82a5b77faf9ae1991f5d018bd291b44490bbd745b5eb9c7b04ac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "From that perspective, when we get m1that is sufficiently different from m0and close to 0.0 and 1.0, we can use m1for training. The statistical validity can be established through empirical data analysis. The second is understanding m1as an approximate estimate of Phiddenwhere uncertainty before t1has been resolved, as discussed in Section 4.1.2 earlier.", "mimetype": "text/plain", "start_char_idx": 364, "end_char_idx": 720, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fbe01bbb-ff31-4480-84cf-3dae7be082dd": {"__data__": {"id_": "fbe01bbb-ff31-4480-84cf-3dae7be082dd", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "139e6c95-59e4-4b78-9e3e-9549c1d0722b", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "bbbfa80fc3bfc78a1ac1f655aea3b924c3660fb99077dd0049b601cbaf2a2232", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "55f139d1-e089-4158-875f-be649f023996", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a63d187fbccb82a5b77faf9ae1991f5d018bd291b44490bbd745b5eb9c7b04ac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The statistical validity can be established through empirical data analysis. The second is understanding m1as an approximate estimate of Phiddenwhere uncertainty before t1has been resolved, as discussed in Section 4.1.2 earlier. In 10this interpretation, m1has meaning beyond being an estimate of o, and has the potential to provide better signals than oin certain scenarios.", "mimetype": "text/plain", "start_char_idx": 492, "end_char_idx": 867, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c30e5b3e-2ae3-4737-8921-3f3ea68877f1": {"__data__": {"id_": "c30e5b3e-2ae3-4737-8921-3f3ea68877f1", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fbe01bbb-ff31-4480-84cf-3dae7be082dd", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "f24b5f8ec11af2db0fbf3dffa21ccc8644d9b299f81fe0be05f9cdb893595db0", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "55f139d1-e089-4158-875f-be649f023996", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a63d187fbccb82a5b77faf9ae1991f5d018bd291b44490bbd745b5eb9c7b04ac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In 10this interpretation, m1has meaning beyond being an estimate of o, and has the potential to provide better signals than oin certain scenarios. Next, we discuss whether the model\u2019s prediction q1at timet1can be used for model prediction where the question date is t0. When market prediction m1at timet1cannot be obtained because the prediction market does not handle that event, the use of model prediction q1becomes a consideration.", "mimetype": "text/plain", "start_char_idx": 721, "end_char_idx": 1156, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "97678d71-ea37-4e77-bb46-cdcf6b3bef75": {"__data__": {"id_": "97678d71-ea37-4e77-bb46-cdcf6b3bef75", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c30e5b3e-2ae3-4737-8921-3f3ea68877f1", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3c4d144a0beaf48b5b1dc95e878285a97302fd436e6b8a07eba748b2ec4e150b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "55f139d1-e089-4158-875f-be649f023996", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a63d187fbccb82a5b77faf9ae1991f5d018bd291b44490bbd745b5eb9c7b04ac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "When market prediction m1at timet1cannot be obtained because the prediction market does not handle that event, the use of model prediction q1becomes a consideration. Our hypothetical Bayesian network framework extends naturally from market predictions ( m0,m1) to model predictions (q0,q1).", "mimetype": "text/plain", "start_char_idx": 991, "end_char_idx": 1281, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4901693c-df30-4c8c-ab43-417154ba1e05": {"__data__": {"id_": "4901693c-df30-4c8c-ab43-417154ba1e05", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "edf14a7e-432c-4aab-a664-7a0b40a5e13e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "80f477774ce4cecbea43218ca827ec15c3d2a96846b036fa5088306fde7ee2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Our hypothetical Bayesian network framework extends naturally from market predictions ( m0,m1) to model predictions (q0,q1). Critically, while q0offers no new information for training purposes, q1can leverage the temporal information gain between t0andt1, making it a viable training signal similar to m \u2081. The applicability of q1 can be evaluated using similar criteria as those for m1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 387, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a8b484a1-2343-493a-9b2c-50c2ebb5ec4b": {"__data__": {"id_": "a8b484a1-2343-493a-9b2c-50c2ebb5ec4b", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4901693c-df30-4c8c-ab43-417154ba1e05", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "883b62d834138acbd1c5237aed518acba0682c1a2873d3791ea172db38ebff84", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "edf14a7e-432c-4aab-a664-7a0b40a5e13e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "80f477774ce4cecbea43218ca827ec15c3d2a96846b036fa5088306fde7ee2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Regarding the effectiveness of using q1, we need to additionally consider the performance of the predicting LLM itself. If the prediction model\u2019s predictions are not sufficiently accurate and have high noise, it may be difficult to use q1due to the high noise. Even when asking LLMs at time points after resolution date t2, if the LLM\u2019s search/RAG performance or fact checking performance is not 100%, the LLM may not achieve 100% accuracy.", "mimetype": "text/plain", "start_char_idx": 388, "end_char_idx": 828, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0f5b974e-f657-4360-8ea7-6bd11d43c8e6": {"__data__": {"id_": "0f5b974e-f657-4360-8ea7-6bd11d43c8e6", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a8b484a1-2343-493a-9b2c-50c2ebb5ec4b", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "3c489162ab7d8cc131ba10076d7b3aaf5008a1a242c981d9c422fbc380ba14b9", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "edf14a7e-432c-4aab-a664-7a0b40a5e13e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "80f477774ce4cecbea43218ca827ec15c3d2a96846b036fa5088306fde7ee2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Even when asking LLMs at time points after resolution date t2, if the LLM\u2019s search/RAG performance or fact checking performance is not 100%, the LLM may not achieve 100% accuracy. Notably, the model\u2019s prediction q1can be applied to forecasting questions where outcome resolution conditions are not rigorously defined.", "mimetype": "text/plain", "start_char_idx": 649, "end_char_idx": 966, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "38717897-3269-43f2-973e-540622079d25": {"__data__": {"id_": "38717897-3269-43f2-973e-540622079d25", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0f5b974e-f657-4360-8ea7-6bd11d43c8e6", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "953061b39c9bd05ddddc4a623718e527241178725fbdedb3e4874c2a64bb9053", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "edf14a7e-432c-4aab-a664-7a0b40a5e13e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "80f477774ce4cecbea43218ca827ec15c3d2a96846b036fa5088306fde7ee2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Notably, the model\u2019s prediction q1can be applied to forecasting questions where outcome resolution conditions are not rigorously defined. For instance, this value can be used for questions with ambiguous resolution conditions like \u201cDid ChatGPT released in 2023 have a positive impact on English education?\u201d or \u201cWill COVID vaccines effectively prevent COVID?\u201d This approach extends event forecasting from questions with clear resolution criteria to more general questions about the future by leveraging the information gap between past (S0) and present ( S1) states as training signals.", "mimetype": "text/plain", "start_char_idx": 829, "end_char_idx": 1414, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e6e7ca7d-bacf-44d9-9ca9-5923dffdfe93": {"__data__": {"id_": "e6e7ca7d-bacf-44d9-9ca9-5923dffdfe93", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "38717897-3269-43f2-973e-540622079d25", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "920cc5158d3c70370ce74be9d64e929c031399a852380197bab462576bc6fc98", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "edf14a7e-432c-4aab-a664-7a0b40a5e13e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "80f477774ce4cecbea43218ca827ec15c3d2a96846b036fa5088306fde7ee2cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.2 Training from data before knowledge cut-off In this part, we discuss the knowledge cut-off problem and introduce ideas to mitigate this problem, including (1) using events that LLMs do not remember well and (2) training counterfactual events together.", "mimetype": "text/plain", "start_char_idx": 1415, "end_char_idx": 1670, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0d6eb3be-a4ef-43dc-ba46-72e04779a732": {"__data__": {"id_": "0d6eb3be-a4ef-43dc-ba46-72e04779a732", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "56dc8265-cdb6-46d9-9ee5-d6c9dc798056", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4231435026602d89e8547d74edaac91fbc146c6dfe2957ac8de672c8265489c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.2.1 Knowledge cut-off problem When evaluating event forecasting problems using data from before the knowledge cut-off period, models can provide accurate responses by relying on their internal knowledge without employing search and reasoning capabilities. Since these memorization-based responses do not generalize to questions where the model has not observed the outcomes during training, data from before the knowledge cut-off loses its value for evaluation purposes. The same limitation applies to training.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 513, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "22abeffe-1304-407e-beb1-44c3a9fd4fa7": {"__data__": {"id_": "22abeffe-1304-407e-beb1-44c3a9fd4fa7", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0d6eb3be-a4ef-43dc-ba46-72e04779a732", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6f5a9a6884351f52d4a356d0296e521bb2db8f39564095bbf5760e401810832f", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "56dc8265-cdb6-46d9-9ee5-d6c9dc798056", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4231435026602d89e8547d74edaac91fbc146c6dfe2957ac8de672c8265489c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since these memorization-based responses do not generalize to questions where the model has not observed the outcomes during training, data from before the knowledge cut-off loses its value for evaluation purposes. The same limitation applies to training. Models have reduced motivation to acquire additional information through search when they already possess the relevant knowledge internally, and similarly lack motivation to engage in reasoning processes for answers they have already memorized. Consequently, neither search capabilities nor reasoning abilities are enhanced through this training approach.", "mimetype": "text/plain", "start_char_idx": 258, "end_char_idx": 869, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "20c5ad66-47b2-4351-a2d0-b2c4042f2ff5": {"__data__": {"id_": "20c5ad66-47b2-4351-a2d0-b2c4042f2ff5", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "22abeffe-1304-407e-beb1-44c3a9fd4fa7", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "aef1d0c5cf4ce4bf016fe98b9725b4acbb5418b75b7fc231c10dbc8ad586501e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "56dc8265-cdb6-46d9-9ee5-d6c9dc798056", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4231435026602d89e8547d74edaac91fbc146c6dfe2957ac8de672c8265489c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Consequently, neither search capabilities nor reasoning abilities are enhanced through this training approach. If we use past models with earlier knowledge cut-offs for event forecasting training, we can utilize more training data compared to the latest models. However, there are two major disadvantages to using past models. First, since the latest models outperform past models, we cannot leverage the capability improvements from LLM development (Karger et al., 2025).", "mimetype": "text/plain", "start_char_idx": 759, "end_char_idx": 1231, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "78bc3360-41e9-4d3e-a816-7e5d7914eabf": {"__data__": {"id_": "78bc3360-41e9-4d3e-a816-7e5d7914eabf", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "20c5ad66-47b2-4351-a2d0-b2c4042f2ff5", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d103bb3cc2dfbd7c5718291fe92f1ee51001da0ca61747aff99ae0a145fb95b8", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "56dc8265-cdb6-46d9-9ee5-d6c9dc798056", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4231435026602d89e8547d74edaac91fbc146c6dfe2957ac8de672c8265489c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, there are two major disadvantages to using past models. First, since the latest models outperform past models, we cannot leverage the capability improvements from LLM development (Karger et al., 2025). Second, the latest models possess the most recent knowledge. Models with more up-to-date knowledge will make better future predictions for questions that require recent trends as context, even without searching for that specific knowledge.", "mimetype": "text/plain", "start_char_idx": 1021, "end_char_idx": 1471, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0d804174-3b08-4fd1-ac1d-eac32cc650f9": {"__data__": {"id_": "0d804174-3b08-4fd1-ac1d-eac32cc650f9", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "78bc3360-41e9-4d3e-a816-7e5d7914eabf", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "a9b15ff3df39d5a4ebc3ed88dc3c515d579fdc37bbf5b37d2ccc75d199a44ad0", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "56dc8265-cdb6-46d9-9ee5-d6c9dc798056", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4231435026602d89e8547d74edaac91fbc146c6dfe2957ac8de672c8265489c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Second, the latest models possess the most recent knowledge. Models with more up-to-date knowledge will make better future predictions for questions that require recent trends as context, even without searching for that specific knowledge. Whether training can be conducted using data from before the knowledge cut-off is an important question. First, since substantially more data exists before the knowledge cut-off than after, the feasibility of utilizing pre-cutoff data determines the scale of available training data.", "mimetype": "text/plain", "start_char_idx": 1232, "end_char_idx": 1755, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2a85ef71-2638-4918-9650-1ab5cdff23c8": {"__data__": {"id_": "2a85ef71-2638-4918-9650-1ab5cdff23c8", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0d804174-3b08-4fd1-ac1d-eac32cc650f9", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "98922793a002173a7000d485e71b80ec5320574fc725d3c7685fcf05e871b2b6", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "56dc8265-cdb6-46d9-9ee5-d6c9dc798056", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d4231435026602d89e8547d74edaac91fbc146c6dfe2957ac8de672c8265489c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "First, since substantially more data exists before the knowledge cut-off than after, the feasibility of utilizing pre-cutoff data determines the scale of available training data. Another issue is that if training data is constructed within a limited period after the knowledge cut-off, we end up training on data that exhibits biases specific to that particular period.", "mimetype": "text/plain", "start_char_idx": 1577, "end_char_idx": 1946, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8b85f05c-56eb-43f6-8072-33bc9783a316": {"__data__": {"id_": "8b85f05c-56eb-43f6-8072-33bc9783a316", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "72e13c48-1857-4244-900f-9e7a1f7e6763", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "217757993c6cd45d521fff52ce4bc2e2e0e27d8c4cd56ac1ef3a1868733b5d18", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Another issue is that if training data is constructed within a limited period after the knowledge cut-off, we end up training on data that exhibits biases specific to that particular period. For example, consider predicting numerous economic indicators during an economic boom period. Such a prediction model may not perform adequately during economic downturns.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 362, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "558be939-068f-4390-945a-28cef910cbff": {"__data__": {"id_": "558be939-068f-4390-945a-28cef910cbff", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b85f05c-56eb-43f6-8072-33bc9783a316", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "c8c421f2da5b1b9e50cebf1574ffcafbd330ac915934f4c325bfd59c480dfff7", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "72e13c48-1857-4244-900f-9e7a1f7e6763", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "217757993c6cd45d521fff52ce4bc2e2e0e27d8c4cd56ac1ef3a1868733b5d18", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, consider predicting numerous economic indicators during an economic boom period. Such a prediction model may not perform adequately during economic downturns. 4.2.2 Using events LLMs poorly recall One approach to addressing the knowledge cut-off problem is to use events that happened in the past but that LLMs cannot answer well through memorization as training data.", "mimetype": "text/plain", "start_char_idx": 191, "end_char_idx": 572, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ffda4781-e364-49ad-9903-36dec832e44e": {"__data__": {"id_": "ffda4781-e364-49ad-9903-36dec832e44e", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "558be939-068f-4390-945a-28cef910cbff", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e74b038e422c63a9ab993d4f75a5bea5282fc76773bc3bde38684c1a8e9c96fb", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "72e13c48-1857-4244-900f-9e7a1f7e6763", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "217757993c6cd45d521fff52ce4bc2e2e0e27d8c4cd56ac1ef3a1868733b5d18", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.2.2 Using events LLMs poorly recall One approach to addressing the knowledge cut-off problem is to use events that happened in the past but that LLMs cannot answer well through memorization as training data. We can explore what knowledge LLMs 11do not answer well through memorization by asking LLMs questions about various domains and use this approach to identify suitable training data.", "mimetype": "text/plain", "start_char_idx": 363, "end_char_idx": 754, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b9741048-0bcf-49fa-b8ee-ce7f6cea6a81": {"__data__": {"id_": "b9741048-0bcf-49fa-b8ee-ce7f6cea6a81", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ffda4781-e364-49ad-9903-36dec832e44e", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "faad75540705e85373749048a0acacd6d9d22dcb2f6a47da5ad5eae78cda1e52", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "72e13c48-1857-4244-900f-9e7a1f7e6763", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "217757993c6cd45d521fff52ce4bc2e2e0e27d8c4cd56ac1ef3a1868733b5d18", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We can explore what knowledge LLMs 11do not answer well through memorization by asking LLMs questions about various domains and use this approach to identify suitable training data. Types of information that LLMs do not memorize well are cases where LLMs know individual facts but do not memorize the relationships or comparison results between them. Wen et al. (2025) created an event forecasting task about which of two research ideas would show better performance on benchmarks.", "mimetype": "text/plain", "start_char_idx": 573, "end_char_idx": 1054, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "810c43b0-cfca-4998-8584-bb70ee120696": {"__data__": {"id_": "810c43b0-cfca-4998-8584-bb70ee120696", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b9741048-0bcf-49fa-b8ee-ce7f6cea6a81", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "255a301d62445904dfd082fdcd76b396526f2661f93fa065de709bbf4d9d4ec8", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "72e13c48-1857-4244-900f-9e7a1f7e6763", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "217757993c6cd45d521fff52ce4bc2e2e0e27d8c4cd56ac1ef3a1868733b5d18", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Wen et al. (2025) created an event forecasting task about which of two research ideas would show better performance on benchmarks. Existing LLM agents without special training showed only random baseline level (50%) performance in the above prediction task comparing the relative performance of two ideas, even though they had knowledge about individual papers. In that paper, they improved performance by training on 7,000 paper idea pairs based on open-source models.", "mimetype": "text/plain", "start_char_idx": 924, "end_char_idx": 1393, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ff63f380-3595-4180-b636-5a380e924651": {"__data__": {"id_": "ff63f380-3595-4180-b636-5a380e924651", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "810c43b0-cfca-4998-8584-bb70ee120696", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "d3659466edd7781d3b4e658a62c1527b27d6e0a11c3bf7e1d0ae3adece83a632", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "72e13c48-1857-4244-900f-9e7a1f7e6763", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "217757993c6cd45d521fff52ce4bc2e2e0e27d8c4cd56ac1ef3a1868733b5d18", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In that paper, they improved performance by training on 7,000 paper idea pairs based on open-source models. The trained model was able to achieve 77% accuracy forecasting performance on 1,500 pairs after the knowledge cut-off by retrieving related past papers and knowledge.", "mimetype": "text/plain", "start_char_idx": 1286, "end_char_idx": 1560, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "47e1d198-bb83-44b4-b265-a42a3583f23f": {"__data__": {"id_": "47e1d198-bb83-44b4-b265-a42a3583f23f", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "204c3fb6-154c-4508-9774-68fd1f274e01", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "845332175e4a9ebb9ba3e5cd25ec8260f70ace153c6d84caa8bac70fd79c5708", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The trained model was able to achieve 77% accuracy forecasting performance on 1,500 pairs after the knowledge cut-off by retrieving related past papers and knowledge. If we apply this approach of predicting comparison results of two indicators from the same period to data from more domains, we should be able to create data that can be used for training to increase event forecasting performance, even though it is data from before the knowledge cut-off date.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 460, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "13814057-a813-48ef-88a5-4ac5616376c8": {"__data__": {"id_": "13814057-a813-48ef-88a5-4ac5616376c8", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "47e1d198-bb83-44b4-b265-a42a3583f23f", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "9b33ee7cb6b18841a204a3227900278142f40a661bef11d8663d4866b760ff56", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "204c3fb6-154c-4508-9774-68fd1f274e01", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "845332175e4a9ebb9ba3e5cd25ec8260f70ace153c6d84caa8bac70fd79c5708", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, we can consider (1) future relative market performance of products released at the same time, (2) comparison of specific future indicators of companies with similar backgrounds, and (3) comparison of future citation counts of papers presented at academic conferences. However, it remains an open empirical question whether training on such poorly-recalled historical events improves performance on general event forecasting tasks. Validating this transfer represents an important direction for future research.", "mimetype": "text/plain", "start_char_idx": 461, "end_char_idx": 984, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "18abf32b-3d18-4271-9924-c50acf8154a6": {"__data__": {"id_": "18abf32b-3d18-4271-9924-c50acf8154a6", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "13814057-a813-48ef-88a5-4ac5616376c8", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "6016a73760c520a1830b2045d4fbf5ff1ef296c103a3e28f552ca7ac9f72c2ee", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "204c3fb6-154c-4508-9774-68fd1f274e01", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "845332175e4a9ebb9ba3e5cd25ec8260f70ace153c6d84caa8bac70fd79c5708", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, it remains an open empirical question whether training on such poorly-recalled historical events improves performance on general event forecasting tasks. Validating this transfer represents an important direction for future research. 4.2.3 Putting counterfactual events Another approach is to use counterfactual events to make LLMs utilize retrieved knowledge for reasoning and probability prediction even when training from data before the knowledge cut-off.", "mimetype": "text/plain", "start_char_idx": 742, "end_char_idx": 1210, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7d8532ed-9156-4344-8487-a8afb326ea52": {"__data__": {"id_": "7d8532ed-9156-4344-8487-a8afb326ea52", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "18abf32b-3d18-4271-9924-c50acf8154a6", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "67d7ec6dfb1686bd8106b0cd4846f6a2f2f11dc7ed80e3e3c1f404a5a020f564", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "204c3fb6-154c-4508-9774-68fd1f274e01", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "845332175e4a9ebb9ba3e5cd25ec8260f70ace153c6d84caa8bac70fd79c5708", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.2.3 Putting counterfactual events Another approach is to use counterfactual events to make LLMs utilize retrieved knowledge for reasoning and probability prediction even when training from data before the knowledge cut-off. In this idea, we use counterfactual events that have outcomes opposite to the actual events that happened in the past.", "mimetype": "text/plain", "start_char_idx": 985, "end_char_idx": 1329, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ebafaaf0-1b03-42af-b797-ac464052d90d": {"__data__": {"id_": "ebafaaf0-1b03-42af-b797-ac464052d90d", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7d8532ed-9156-4344-8487-a8afb326ea52", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "13e59297068490eec5b7d6a0cf807723e0ee850a7ef5ee6865de40b7897fae20", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "204c3fb6-154c-4508-9774-68fd1f274e01", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "845332175e4a9ebb9ba3e5cd25ec8260f70ace153c6d84caa8bac70fd79c5708", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In this idea, we use counterfactual events that have outcomes opposite to the actual events that happened in the past. The key insight of this approach is that since LLMs must reason based on retrieved information even in counterfactual scenarios, they develop actual reasoning abilities rather than simple memorization. Related research in the question answering field that used counterfactual event-based retrieved knowledge utilization can be referenced (Paranjape et al., 2022).", "mimetype": "text/plain", "start_char_idx": 1211, "end_char_idx": 1693, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e237093e-779e-4c5b-9b17-93a82b6575dd": {"__data__": {"id_": "e237093e-779e-4c5b-9b17-93a82b6575dd", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ebafaaf0-1b03-42af-b797-ac464052d90d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "ec2e1038879d4716b726fb9429920678520c00031d930f44c3234e4aec51242b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "204c3fb6-154c-4508-9774-68fd1f274e01", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "845332175e4a9ebb9ba3e5cd25ec8260f70ace153c6d84caa8bac70fd79c5708", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Related research in the question answering field that used counterfactual event-based retrieved knowledge utilization can be referenced (Paranjape et al., 2022). For example, Neeman et al. (2023) showed that training on counterfactual knowledge can increase models\u2019 search grounding and reduce hallucination.", "mimetype": "text/plain", "start_char_idx": 1532, "end_char_idx": 1840, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9cddb9dd-5b78-4d09-9172-3fa43c4dcd17": {"__data__": {"id_": "9cddb9dd-5b78-4d09-9172-3fa43c4dcd17", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "65f85521-e243-4b44-842b-bfebfce7cc2a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "11ef898cc98f74311e8ec7289de4f166c00ffee9033d664455f4d63c0b18c12a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, Neeman et al. (2023) showed that training on counterfactual knowledge can increase models\u2019 search grounding and reduce hallucination. In this research, counterfactual documents were constructed by modifying the correct answer entity in search documents. Specific ideas for creating counterfactual events are as follows. First, we need to create fictional search documents that support counterfactual events.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 420, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d3182eb9-b7ca-4419-aed0-c1ed4b717f6d": {"__data__": {"id_": "d3182eb9-b7ca-4419-aed0-c1ed4b717f6d", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9cddb9dd-5b78-4d09-9172-3fa43c4dcd17", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "042cd932a9b9197528f48cd95eb6683b3fb4fc7c584ddfec2c06ba61993f2b7a", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "65f85521-e243-4b44-842b-bfebfce7cc2a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "11ef898cc98f74311e8ec7289de4f166c00ffee9033d664455f4d63c0b18c12a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Specific ideas for creating counterfactual events are as follows. First, we need to create fictional search documents that support counterfactual events. We can make LLMs generate fictional news articles reflecting counterfactualoutcomesandusethemasiftheyweresearchresults.Forexample,wecancreateacounterfactual event of \u201cSpaceX Starship 3rd launch failure in March 2024,\u201d which is the opposite outcome of \u201cSpaceX Starship 3rd launch success in March 2024,\u201d and create related fictional news articles.", "mimetype": "text/plain", "start_char_idx": 267, "end_char_idx": 767, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b655faac-56fc-4430-99cc-da0a5388efc8": {"__data__": {"id_": "b655faac-56fc-4430-99cc-da0a5388efc8", "embedding": null, "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "080a2c8d-8a7b-4159-8258-e093b9765f96", "node_type": "4", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "433d1892c1e571f1e721ce0f06d796ce22ce14fc5c2fbcda3dcbdbaff9100349", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d3182eb9-b7ca-4419-aed0-c1ed4b717f6d", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "e416c81da06629b0c4a8899ab84646281762460de08f17d443abd90b30e6caf2", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "65f85521-e243-4b44-842b-bfebfce7cc2a", "node_type": "1", "metadata": {"arxiv_id": "2507.19477v1", "title": "Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts", "authors": ["Sang-Woo Lee", "Sohee Yang", "Donghyun Kwak", "Noah Y. Siegel"], "published_date": "2025-07-25", "categories": ["cs.LG"], "pdf_url": "https://arxiv.org/pdf/2507.19477v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19477v1", "source": "arxiv", "definitions_count": 170, "has_definitions": true, "text_length": 50000, "abstract_length": 1000}, "hash": "11ef898cc98f74311e8ec7289de4f166c00ffee9033d664455f4d63c0b18c12a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Here is an example of an implementable pipeline: Step 1: Base event selection and counterfactual divergence point setting For each base event, we set a specific time point (divergence date) where actual events and counterfactual events split. We use actual search documents until this poi", "mimetype": "text/plain", "start_char_idx": 768, "end_char_idx": 1056, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "db249a26-87b5-4afb-a1b8-a2e030b78e56": {"__data__": {"id_": "db249a26-87b5-4afb-a1b8-a2e030b78e56", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cc630bfb-bac1-40b2-87e0-7d7500de63c5", "node_type": "1", "metadata": {}, "hash": "9f0621c003112aa94e4aaa748dbf7ed7d3280f26acdde8a7faf6ace64c2b3709", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "e98eac31-9c3c-4ebe-8f13-59e55f710d10", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f34842178f284bdd920033e777bcda703f4cd37a34082567e3150b5c077befc6", "class_name": "RelatedNodeInfo"}, {"node_id": "fdb2e7f0-24e9-407c-8cf9-52243751ad4e", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9dc6a5ef52b10ef673ab42ce5e97a94791a1135fa84ca885eb1b79fe2094c4a4", "class_name": "RelatedNodeInfo"}, {"node_id": "2db9fece-00a1-4a6f-aaae-6a4933998147", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "13a21813d82dc486e7c0ee215dfecd29f9f0a549e788f2ae9061aa0a48389918", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "TITLE: Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization\n\nAUTHORS: Anton Pembek, Artem Fatkulin, Anton Klenitskiy, Alexey Vasilev\n\nABSTRACT: Many sequential recommender systems suffer from the cold start problem, where\nitems with few or no interactions cannot be effectively used by the model due\nto the absence of a trained embedding. Content-based approaches, which leverage\nitem metadata, are commonly used in such scenarios. One possible way is to use\nembeddings derived from content features such as textual descriptions as\ninitialization for the model embeddings. However, directly using frozen content\nembeddings often results in suboptimal performance, as they may not fully adapt\nto the recommendation task. On the other hand, fine-tuning these embeddings can\ndegrade performance for cold-start items, as item representations may drift far\nfrom their original structure after training. We propose a novel approach to\naddress this limitation.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1015, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cc630bfb-bac1-40b2-87e0-7d7500de63c5": {"__data__": {"id_": "cc630bfb-bac1-40b2-87e0-7d7500de63c5", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "db249a26-87b5-4afb-a1b8-a2e030b78e56", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "da1b67262e56212dc7898cf18384a8e39d2a44aab093b09755c2d194db34b6a4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "node_type": "1", "metadata": {}, "hash": "9f6b9a4d1906c51f6abd81502fb193695c3a55b4319be7c0b879aad798ca3315", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "66256c0e-8c94-488e-bf00-1da903703df0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d7efc71e85a5778ebe99274f15d1e05edd6d5ead0060bd2c46b8293d29c1f7fd", "class_name": "RelatedNodeInfo"}, {"node_id": "e90dcff2-5517-43c2-a6a1-4ba1d21a4656", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7a4150933be90ff626d64b09d5a374adcb73b4cf32a9c4610679454308bd19b8", "class_name": "RelatedNodeInfo"}, {"node_id": "5693045b-afdf-4a0e-9505-33be4be69a3c", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "53962d918b9957069a37b7c12bc31a8f625a5d35910391741bbd54421ce251fb", "class_name": "RelatedNodeInfo"}, {"node_id": "44085962-76ba-48da-90ee-697d9e7fc54a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7b65151044a25a45a31fec966f520a5193b9bb9c7c97766790de90d0df53ed6d", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "On the other hand, fine-tuning these embeddings can\ndegrade performance for cold-start items, as item representations may drift far\nfrom their original structure after training. We propose a novel approach to\naddress this limitation. Instead of entirely freezing the content embeddings or\nfine-tuning them extensively, we introduce a small trainable delta to frozen\nembeddings that enables the model to adapt item representa\n\nKEY DEFINITIONS: way: to use embeddings derived from content features such as textual descrip- tions as initialization for the model embeddings | This: the author\u2019s version of the work | interactions: the model cannot learn effective representations for these items, leading to poor recommendation quality | issue: to leverage content- based features, such as textual descriptions, to construct embed- dings for cold items | solution: to substitute content embeddings for cold items into a trained model | component: frozen content embeddings with a fixed norm | ponent: a small trainable delta vector with a bounded norm | work: as follows: \u2022We investigate the impact of content-based embedding ini- tialization on the cold start problem in transformer-based sequential recommendation | embeddings: a common strategy for addressing the item cold start problem | objective: to predict the next item the user will interact with\n\nFULL TEXT: Let It Go?", "mimetype": "text/plain", "start_char_idx": 782, "end_char_idx": 2157, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9f2b5105-17d5-46b8-b73c-9b7672e026b3": {"__data__": {"id_": "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc630bfb-bac1-40b2-87e0-7d7500de63c5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e23394951f43da04bad39e40cc42828cdbbc3e7c08b69f108b9bdd6089cfb972", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "88e12252-5fec-46c2-a2ae-6fc241f89a76", "node_type": "1", "metadata": {}, "hash": "68cff4d6d12b5de9ab1e9af8af94214a3f8aae2edff0b5886cb3f9f2bde4d35b", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "2673e9dd-96d1-42f5-903c-bf289afc91a0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a8545f7587481306e9b7875dcf76a5c981492d1982935aa4dabe94b797f26069", "class_name": "RelatedNodeInfo"}, {"node_id": "36f1afb1-b558-4531-9cdc-616558dcfaee", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7d0ff482cd40868ad8e6e23b26d466ca66e6df463c0bf4ef715c4bf09ad2b5b2", "class_name": "RelatedNodeInfo"}, {"node_id": "65eb96c0-affd-4497-9c15-0272053042e2", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a0c5362b364f623992cfbf4d6d56328b46fbd38bea3c9816f16a913bb9446e01", "class_name": "RelatedNodeInfo"}, {"node_id": "a1ca29c1-9e8d-484b-9415-dc3107357580", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e0f789e5bf63f30e28fdbf773c82c0604ac57b968ba27cfa9206c5e2b8022b80", "class_name": "RelatedNodeInfo"}, {"node_id": "e4dc984c-e3f2-4923-8645-5fcb9ab3e78e", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "ca0c9799c503ef3a576738f3e98d032f3f7fabf9cb4442700e8ea372104afb5b", "class_name": "RelatedNodeInfo"}, {"node_id": "017ffcb0-64fd-4717-bfb4-dd0029d24a77", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "5eb2fc09204437e3243291e8f0c784262d796f5b89fb084d9fe27f62b19ab29b", "class_name": "RelatedNodeInfo"}, {"node_id": "a0c428d4-9bdb-4837-84c4-0e4d1cc8c134", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "5f6e38c07e38a72700d4ea31a88b1302cfa1ad2971b251ea5632f7ed1de43ef5", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization Anton Pembek apembek@bk.ru Sber AI Lab, Lomonosov Moscow State University (MSU) Moscow, Russian FederationArtem Fatkulin artem42fatkulin@gmail.com Sber AI Lab, HSE University Moscow, Russian Federation Anton Klenitskiy antklen@gmail.com Sber AI Lab Moscow, Russian FederationAlexey Vasilev alexxl.vasilev@yandex.ru Sber AI Lab, HSE University Moscow, Russian Federation Figure 1: Illustration of the proposed approach. Abstract Many sequential recommender systems suffer from the cold start problem, where items with few or no interactions cannot be effec- tively used by the model due to the absence of a trained embed- ding. Content-based approaches, which leverage item metadata, are commonly used in such scenarios. One possible way is to use embeddings derived from content features such as textual descrip- tions as initialization for the model embeddings. However, directly using frozen content embeddings often results in suboptimal per- formance, as they may not fully adapt to the recommendation task. On the other hand, fine-tuning these embeddings can degrade per- formance for cold-start items, as item representations may drift far from their original structure after training. We propose a novel approach to address this limitation. Instead of entirely freezing the content embeddings or fine-tuning them extensively, we introduce a small trainable delta to frozen embed- dings that enables the model to adapt item representations without letting them go too far from their original semantic structure.", "mimetype": "text/plain", "start_char_idx": 2158, "end_char_idx": 3777, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "88e12252-5fec-46c2-a2ae-6fc241f89a76": {"__data__": {"id_": "88e12252-5fec-46c2-a2ae-6fc241f89a76", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "be03fd97b06563bae1fcd3d306b00940631e397d5610ee902bcbe9780c56fb3f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de", "node_type": "1", "metadata": {}, "hash": "294290500910797869840416ebb5e6b171d3222077a8d5602dfb6003eeb13b60", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "d938c1e9-40cf-4541-8f86-471f4f006481", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f14a5bdd381426bad4c2bf89470a62a80e0dc30f7a5ec6292b590c0249adb74a", "class_name": "RelatedNodeInfo"}, {"node_id": "5da3506c-fac9-4eb3-8288-0998c9026a57", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cf350e0c353f824820a4a3c35582a8ad22a95a8643f3fc364061cab41840aa56", "class_name": "RelatedNodeInfo"}, {"node_id": "1a93036f-9a6b-49b8-8e4e-85375e507a10", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d72155e07806e9b90f69aa4bb498e949e5ca532777e36531e4221023644b327b", "class_name": "RelatedNodeInfo"}, {"node_id": "f19243eb-b1ce-4903-b5a3-284412d9e872", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b0487fd24c9a076fac8e18d91c1b5eb693862f2ec51089b1c4326152fd205843", "class_name": "RelatedNodeInfo"}, {"node_id": "e7cfb727-258a-4e21-a9c5-0e0ae4195c18", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7d32e9a6328056239144240738c92be7248efc7b1ca877c10679b8008d51a742", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Instead of entirely freezing the content embeddings or fine-tuning them extensively, we introduce a small trainable delta to frozen embed- dings that enables the model to adapt item representations without letting them go too far from their original semantic structure. This approach demonstrates consistent improvements across multiple datasets and modalities, including e-commerce datasets with textual descriptions and a music dataset with audio-based representation. RecSys \u201925, Prague, Czech Republic \u00a92025 Copyright held by the owner/author(s). Publication rights licensed to ACM. This is the author\u2019s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in Proceedings of the Nineteenth ACM Conference on Recommender Systems (RecSys \u201925), September 22\u201326, 2025, Prague, Czech Republic , https://doi.org/10.1145/3705328.3748038.CCS Concepts \u2022Information systems \u2192Recommender systems . Keywords Recommender Systems, Sequential Recommendations, Cold-start ACM Reference Format: Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev. 2025. Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recom- mendations with Content-Based Initialization. In Proceedings of the Nine- teenth ACM Conference on Recommender Systems (RecSys \u201925), September 22\u201326, 2025, Prague, Czech Republic. ACM, New York, NY, USA, 6 pages.", "mimetype": "text/plain", "start_char_idx": 3508, "end_char_idx": 4926, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de": {"__data__": {"id_": "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "88e12252-5fec-46c2-a2ae-6fc241f89a76", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3c45b330891265bd1c9e1909b6d484581f392cc3811ecc7652b838e79a27e597", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bb7534db-e25f-428a-8778-6cb5b6f5ad95", "node_type": "1", "metadata": {}, "hash": "c93b5b6604b3959c579bc49bf3533ffeb5cee8e1feb561a37edda94945b47660", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "18d5406c-5efd-4928-845a-25db3d586722", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b11ba17f02f2292eba8caebcbce0f361c1a343555f9b0a73f44d726ea18eed87", "class_name": "RelatedNodeInfo"}, {"node_id": "257f60ef-b0ad-4fbc-b605-6d181656a11a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "c5f787edb48a1e092ccda6b81b121e3d3737123d0a5a3fcb5dacf285cb356b7e", "class_name": "RelatedNodeInfo"}, {"node_id": "f4e57e09-98a3-45cf-9ebf-1c9897d4370b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "c25f1588b35d7b6176847d8febb6ba8596142925ac5270864fb90f5f63e2f671", "class_name": "RelatedNodeInfo"}, {"node_id": "55086b99-4947-4d9e-abb2-c96ba69ff0dd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "32acf87fb3a2ea01265c8216462d625fc322f3799d5faad711d84b5cf3f7f282", "class_name": "RelatedNodeInfo"}, {"node_id": "ebf6015f-27fd-481d-aa92-de46f7f861e3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "5e5ab5a987127a36b1b61a30d9db274b07eea9f16c9a0daea84dac8349b9b3fb", "class_name": "RelatedNodeInfo"}, {"node_id": "267f4c36-c2e6-42f9-8915-8ea6c18fed83", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f795d843d7a4446c19653a685a3ee875e1d7390abaeb7c0c078c3251ca2cc5b0", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "ACM, New York, NY, USA, 6 pages. https://doi.org/10.1145/3705328.3748038 1 Introduction The cold start problem remains a significant challenge for recom- mender systems in general and sequential recommender systems in particular. These systems aim to predict a user\u2019s next interac- tion based on their history, but struggle when encountering cold items with few or no interactions. This lack of interactions means the model cannot learn effective representations for these items, leading to poor recommendation quality. A common strategy to address this issue is to leverage content- based features, such as textual descriptions, to construct embed- dings for cold items. However, this approach introduces a distri- bution gap: the embeddings of warm items, learned during model training, may differ significantly from content-based embeddings used for cold items. To bridge this gap, various techniques have been explored, including learning transformations from cold embeddingsv1 [cs.IR] 25 Jul 2025RecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev to the warm item embedding space [ 21,23,27], employing con- trastive learning [ 26], adversarial training [ 3], and distillation [ 7] to encourage similarity between cold and warm item representations. Recent works [ 1,5] demonstrated that using text embeddings as initialization for transformer-based sequential recommendation models like SASRec [ 10] and BERT4Rec [ 18] improves overall rec- ommendation quality.", "mimetype": "text/plain", "start_char_idx": 4894, "end_char_idx": 6435, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bb7534db-e25f-428a-8778-6cb5b6f5ad95": {"__data__": {"id_": "bb7534db-e25f-428a-8778-6cb5b6f5ad95", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0a542dabfdd965760e0127e10fa41fb6b4063da88447a1e3fea916c0308a56f9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "node_type": "1", "metadata": {}, "hash": "1507d72809ae639e154e7fb4ce636f406492a671222d1c2670b84f2f6111e696", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "93c2b70a-135f-496e-b14e-45caa053bf73", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0f6809cad0cde45bce850bf264cf5ec0ef362b9a8ec9d39f5bde4ec8075485e1", "class_name": "RelatedNodeInfo"}, {"node_id": "67e94527-9263-4837-b131-a4799f7e51e9", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "86ed56cacbf29ddefeca2dddd26d291df167d2eebc0769fd4134de20fec7801c", "class_name": "RelatedNodeInfo"}, {"node_id": "62923145-ce3a-40a8-b0c4-c499785f29a6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "ba6c7e4c0a01a5a846b05685f0665c677fc598ca9ea3cb44f462cfa94ebb114c", "class_name": "RelatedNodeInfo"}, {"node_id": "00cd7f5b-7518-4ade-81a2-63ab6f97aabc", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "c1a7f67a675ec23774eaaafd81ca9bc45a3f0efeccde7c14376c5a854cb80a15", "class_name": "RelatedNodeInfo"}, {"node_id": "8038baa3-f888-4c86-9e5d-fb963c4ce5fd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "39561cc1e96e90d208a390cce7e3c7ab73e38d442eb198f038daeb6557b19058", "class_name": "RelatedNodeInfo"}, {"node_id": "61c8cea0-fafd-48a7-874d-f597795d15a8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "ffa99881c794af4692b8d9baf290df6737456bbdd1cc6088b39252cb903fb9ff", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Recent works [ 1,5] demonstrated that using text embeddings as initialization for transformer-based sequential recommendation models like SASRec [ 10] and BERT4Rec [ 18] improves overall rec- ommendation quality. In our work, we investigate how content- based initialization, not limited to text but also including audio- based features, affects the cold start problem in sequential rec- ommendation. A straightforward solution is to substitute content embeddings for cold items into a trained model. However, allowing full fine-tuning of these embeddings during training can hurt per- formance on cold items, as the embeddings may drift significantly from their initial content-based representation. On the other hand, fully freezing content embeddings limits the model\u2019s flexibility and hurts overall performance, as it cannot fully adapt to the interaction data. To address these limitations, we propose an approach where item embeddings consist of two components. The first component is frozen content embeddings with a fixed norm. The second com- ponent is a small trainable delta vector with a bounded norm. This setup allows the model to adapt item representations to the interac- tion data without letting them go far from their original semantic structure derived from content. As a result, it improves recommen- dation quality on new items without sacrificing performance on those seen during training. The main contributions of our work are as follows: \u2022We investigate the impact of content-based embedding ini- tialization on the cold start problem in transformer-based sequential recommendation. \u2022We propose a method that learns a small trainable delta with bounded norm on top of frozen content embeddings.", "mimetype": "text/plain", "start_char_idx": 6223, "end_char_idx": 7943, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6df56ab1-fcff-4ae7-901a-9a5f555b123d": {"__data__": {"id_": "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bb7534db-e25f-428a-8778-6cb5b6f5ad95", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "182a79fe6e1d1ccefc83937560c25883e0d17d9acabae970e400e7d733cef54d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b48d73f-7b7d-48ee-b07c-c7803a538edd", "node_type": "1", "metadata": {}, "hash": "0c0ceee08f2a10339b3ae83d342113fd2109419eab2f3cb3ddb1ecaf6dbc1859", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "d5781ced-bcdf-46e5-8e63-877991d14207", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f31ac9efce8a11cd661fe95d564199e7dffb03837840ffe529ae806b97a78ba9", "class_name": "RelatedNodeInfo"}, {"node_id": "8af3a283-7382-4582-b416-6d0cef2edfa6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "af3396c87ecbef865995780da59f9d6acca3abd50f2a13a3f552ff4c9fc9217e", "class_name": "RelatedNodeInfo"}, {"node_id": "51918c55-025f-4906-bfb0-b0bfe491171c", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9a65f83ee7729c45b763576f3c1ea5d836e8fd51851e8f7c55a1ebba3a41b30c", "class_name": "RelatedNodeInfo"}, {"node_id": "870c0c78-3dc0-438e-a7c3-01243e73e58a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3f35109a7c6ef6a3911023feec680d8ede1395f8fdf50d458abaaa356cd3ba6c", "class_name": "RelatedNodeInfo"}, {"node_id": "d8d747b8-d81a-419d-8083-7f8523d53feb", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "01eb4db1289b82aebbce2640b6a9fc945fba513b9084ef646ff8dc649090736b", "class_name": "RelatedNodeInfo"}, {"node_id": "a8f1e88e-ff95-496f-81d6-17e468412c91", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "660345f2eb69f9736b9620342ca1b721f04b20d76f854085f0ec4031bb49a45f", "class_name": "RelatedNodeInfo"}, {"node_id": "2b0058fc-1a45-474e-9544-ec4e9faae58c", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cd5f4e366a8c72394a60e1a74dd2e24af671ec8e09376e5b4639ae497bfc4090", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\u2022We propose a method that learns a small trainable delta with bounded norm on top of frozen content embeddings. \u2022We demonstrate that this approach consistently improves performance on cold items across different data modalities, including textual item descriptions and audio representations of songs. 2 Related Work Using content-based representations to derive model embeddings is a common strategy for addressing the item cold start problem. Different approaches have been proposed to align cold item em- beddings with the warm embedding space. The work [ 21] predicts latent factors directly from a song\u2019s audio content. DropoutNet [ 23] takes both latent preference factors and content features as input and applies input dropout to the latent factors during training, forcing the model to rely on content when preference information is missing. The paper [ 27] uses meta networks to generate item- specific scaling and shifting functions that transform cold item embeddings into the warm feature space. CLCRec [ 26] applies con- trastive learning to maximize the mutual information between item content representations and collaborative embeddings. GAR [ 3] em- ploys adversarial training between a generator and a recommender to ensure that generated cold item embeddings have a similar distri- bution to warm ones. ALDI [ 7] introduces a distillation framework where warm items act as \"teachers\" and cold items as \"students,\" aligning the students\u2019 content-based predictions with the teachers\u2019behavior-based predictions. These works mainly focus on collabo- rative filtering models rather than sequential recommendations. For sequential recommendations, M2TRec [ 15] introduces an item-ID-free framework that learns item representations directly from metadata and uses multi-task learning.", "mimetype": "text/plain", "start_char_idx": 7832, "end_char_idx": 9628, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0b48d73f-7b7d-48ee-b07c-c7803a538edd": {"__data__": {"id_": "0b48d73f-7b7d-48ee-b07c-c7803a538edd", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "27a59c5ab4b6fccb1f670fb18b2f2d58a2b596690bad8c622cd94e7ddf6e7391", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd", "node_type": "1", "metadata": {}, "hash": "60d3cf08cb46aaf9c00a8576168faa583739cba9999adae5aedfeaacfe1eeb47", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "96bdd5d3-a773-482d-a30d-06d7d77395aa", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "02ca7df05dbcc6c428e2fc8f881f9f2f9db81a6bd698644e40af4d7bb7213509", "class_name": "RelatedNodeInfo"}, {"node_id": "ef94c2bc-3eb7-4146-85bc-5713adff1302", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d86af8e6ce1f5faf07f3c5cec10461c9f641984d3759cec799f4cf4421fb82c3", "class_name": "RelatedNodeInfo"}, {"node_id": "c05bca4c-5716-479f-9d85-6b9593fd13d8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "ebec9844273c29158cc58ad39cd18c573cfe030e9b38e87c9cffdc34c79be059", "class_name": "RelatedNodeInfo"}, {"node_id": "d3739567-9d85-4d3e-b562-9b18a0fe7718", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "132d6970ade9590cadee98bd5339da2e134c0d53587626457248733b0c0daa2d", "class_name": "RelatedNodeInfo"}, {"node_id": "81b11a8d-9cd6-4b83-9dfd-d06fb630e5f3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "23c4e5efd02464a681340b480cfd74d6652caea60ecb0ade4ad34872adfd98af", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These works mainly focus on collabo- rative filtering models rather than sequential recommendations. For sequential recommendations, M2TRec [ 15] introduces an item-ID-free framework that learns item representations directly from metadata and uses multi-task learning. Recformer [ 13] models items and user preferences using language representations derived solely from item textual attributes. This approach, however, in- creases computational complexity compared to ID-based methods due to much longer input sequences. In contrast to these works, we focus on leveraging content embeddings within classic ID-based models like SASRec. SimRec [ 2] and the work [ 25] incorporate item similarities derived from textual embeddings into the training process of such models using customized loss functions. Unlike our approach, they consider tail items - those with very few in- teractions but not completely new - as cold. The works [ 1,5] use textual embeddings to initialize the transformer embedding layer and show that this approach improves recommendation metrics. However, they do not specifically address the cold start problem. The paper [ 20] explores the usage of frozen pretrained audio repre- sentations for music recommendations without any fine-tuning. 3 Approach 3.1 Task formulation LetUbe the set of users and Ibe the set of items. In the sequential recommendation setting, we are given an ordered history of user interactions with items. The objective is to predict the next item the user will interact with.", "mimetype": "text/plain", "start_char_idx": 9360, "end_char_idx": 10882, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd": {"__data__": {"id_": "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b48d73f-7b7d-48ee-b07c-c7803a538edd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "70ff16738ffbbd01dd90d5a35e8594cc952353abfa683af4723e228df28f2daa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5", "node_type": "1", "metadata": {}, "hash": "edc3890b54c3ab7bf5cf861a8cb3238ac037a6b21b6b9abb9060156c26aee006", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "47a07172-514d-4d6d-8d70-98c529ca03e7", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a83f4daec7f6c2ec04aa1243892fa4ac23407e7e633d58cdf6c98b82d3b36d34", "class_name": "RelatedNodeInfo"}, {"node_id": "49f949a8-0735-49af-870e-1ffde8de81c9", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a00bdb373f810b6c0b87550968f34a9312c9d6cc66e1a1985550e45a2af0dfb4", "class_name": "RelatedNodeInfo"}, {"node_id": "eedc9a90-b5d5-4912-9092-9d2490f79c24", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "45b27161a44c9c16ff3bc8e4d0717baed81fb3dd9320fc94fe39a8b61da82dcb", "class_name": "RelatedNodeInfo"}, {"node_id": "7ab2825a-5f7c-4550-afe8-901081e154f6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f60a1a0e28e6aa2624538a25745a41dcc55afcfeae19b167bb5a31f08fc12c7d", "class_name": "RelatedNodeInfo"}, {"node_id": "62c5299b-1bf0-4bf1-8c51-116c95825420", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "342b0766cc37e05eb36d70d9f6fb4dcc134c081858945e8e5aa39b5b08540fa3", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In the sequential recommendation setting, we are given an ordered history of user interactions with items. The objective is to predict the next item the user will interact with. State-of-the-art sequential recommender systems (e.g., SASRec and BERT4Rec) typically define a learnable embedding function \ud835\udc38:I\u2192R\ud835\udc5a, which maps each item \ud835\udc56\u2208Ito a vector representation e\ud835\udc56\u2208R\ud835\udc5a. A transformer-based architecture aggregates a sequence of user interactions into a user representation h\ud835\udc62\u2208R\ud835\udc5a. This representation is then used in a Maximum Inner Product Search (MIPS) to compute relevance scores for all items: \ud835\udc5f(\ud835\udc62,\ud835\udc56)=h\ud835\udc62\u00b7e\ud835\udc56(1) While demonstrating superior overall performance, such models fail to handle new items due to the absence of trained embeddings for them \u2014 a problem called item cold start. At the same time, enabling the model to make use of cold items can increase recom- mendation diversity, improve overall performance by leveraging interactions with newly introduced content, and extend the model\u2019s deployment lifetime by reducing the need for frequent retraining. Addressing this limitation is therefore crucial for building robust and efficient recommender systems. 3.2 Content-based initialization In many domains, items are accompanied by additional information, such as textual descriptions for goods or sound-based embeddings for music tracks. In the absence of trained embeddings for new items, it is reasonable to utilize this content information to gener- ate initial representations.", "mimetype": "text/plain", "start_char_idx": 10705, "end_char_idx": 12196, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5": {"__data__": {"id_": "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7bae6336d1987ef51f49a27907b1e437c612369799e9f7b3b455b6736d26c6b1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2855e277-9266-4da9-a41b-62970f13924a", "node_type": "1", "metadata": {}, "hash": "e7c510af5a57dd5d75aa2f895ac2596b177d70a2c59c73e9a82446b0999f014e", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "164847cd-f3fe-4ff4-a218-4c3272542352", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "6ecbddfac184f530ef487d689a20d6dda7e19156b160906c84d5997772fe9749", "class_name": "RelatedNodeInfo"}, {"node_id": "7171672f-3d76-4671-b19a-0d002c808b11", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "64a09a0aad6ba54aa74a453b28c713eda635fb4408a9140cd5afcdc9021bc5e5", "class_name": "RelatedNodeInfo"}, {"node_id": "07364ea6-e560-49e5-8f36-3d64a72d9f38", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "597994176b73dabbb2fe9ebecf6e9ccdf290380fa2803e749763ac4f71d3306c", "class_name": "RelatedNodeInfo"}, {"node_id": "36cbc85e-6884-415e-8239-c4ad7ac472e1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "63309ba7ca7e8fafcddf5b12e8d279a4ef2a0691bb5c2a5b567985b2983a029b", "class_name": "RelatedNodeInfo"}, {"node_id": "04c2eed4-7b4c-46e4-a197-0a22bf5357eb", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "dbe8d893a3e2e035d53491a12a4535036a150a9c6c3725a94e54f261a94947cf", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In the absence of trained embeddings for new items, it is reasonable to utilize this content information to gener- ate initial representations. For cold items, these representations can be used as-is during inference, while for warm items, they can be fine-tuned along with other parts of the model during training. Prior works have shown [ 1,5] that initializing the model with text-based embeddings can significantly improve recommendation quality.Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization RecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Nevertheless, the effectiveness of content-based initialization de- pends critically on both the quality of the source information and the capabilities of the encoder model. For example, as previously shown in [ 20], different audio encoding techniques demonstrate various performance when used to generate music track represen- tations. Furthermore, the direct use of content-based embeddings comes with a major drawback: freezing them during training leads to degraded model performance, while allowing them to be updated makes the approach less suitable for the item cold start scenario. That is, once training is complete, the content-based embeddings of cold items remain outside the learned representation space, re- sulting in poor generalization to unseen items. 3.3 Representation adjustment To overcome this limitation, we propose freezing content-based item embeddings, fixing their norm, and training only a small delta layer. This allows the model to adjust item representations slightly while keeping them close to the original embeddings. di ei ci\u03b8 \u03b3 Figure 2: Geometric representation of the proposed approach.", "mimetype": "text/plain", "start_char_idx": 12053, "end_char_idx": 13800, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2855e277-9266-4da9-a41b-62970f13924a": {"__data__": {"id_": "2855e277-9266-4da9-a41b-62970f13924a", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "eabe9e88a8098b712d8494defdf592fbe801549145734a040b04500c1f8fe038", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8401cdeb-6662-48aa-beae-b4bb5f06a885", "node_type": "1", "metadata": {}, "hash": "e08e42a63f5c8ff724a45c60ff3dbace3977fa0cdd407120c60081ee9fe24cff", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "71aa0155-3650-424b-80d3-d39b8c47f0f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2fe70c984e2d68ca5fac9c50a61d0f3fee7e0dbe74915a9dc190dbf9eacdcf01", "class_name": "RelatedNodeInfo"}, {"node_id": "e66d8f48-4744-4c7c-af37-f336f2106dc0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d6069d2b3bee92f31f900be64f8f78089a8f37519c939a9c412e5aaab31fba7a", "class_name": "RelatedNodeInfo"}, {"node_id": "271872ae-f2e5-43c7-9ede-e4a01d149ada", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a7695702a51dcaf44547957d5ad937d95448b12de0e0cb24d142861ae1b17fe6", "class_name": "RelatedNodeInfo"}, {"node_id": "3d234c0b-4bc1-4565-8944-328cf3c2c90e", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "bac9b358bd997f4bc5fdfa8469d46c9ba0ab1c0aa277ba4d4f4a981afe4941c2", "class_name": "RelatedNodeInfo"}, {"node_id": "67614e3e-03e1-4acb-adaf-edb0c6b8f21b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f93705b4d4131ffabbb10171576dbdc7eb3bf10b63422bd2d68ae4ffcf1412ae", "class_name": "RelatedNodeInfo"}, {"node_id": "217fb68d-c222-405e-9cc5-530acc1d60cb", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "85861688a31acf390eb7266bfaa533e3c5a0ec6070920d1339a9355d6c6ac52f", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This allows the model to adjust item representations slightly while keeping them close to the original embeddings. di ei ci\u03b8 \u03b3 Figure 2: Geometric representation of the proposed approach. c\ud835\udc56is a frozen content-based item embedding, d\ud835\udc56is the corre- sponding trainable correction vector and e\ud835\udc56is the final item representation. Formally, given a content-based embedding c\ud835\udc56\u2208R\ud835\udc5aof an item \ud835\udc56\u2208Iwith unit norm\u2225c\ud835\udc56\u2225=1, and a trainable delta vector d\ud835\udc56\u2208R\ud835\udc5a with\u2225d\ud835\udc56\u2225=\ud835\udeff\ud835\udc56, where 0\u2264\ud835\udeff\ud835\udc56<1, we consider the cosine similarity between the original embedding and its adjusted form e\ud835\udc56=c\ud835\udc56+d\ud835\udc56: sim(c\ud835\udc56,e\ud835\udc56)=cos\ud835\udefe=\u221a\ufe03 1\u2212sin2\ud835\udefe (2) where\ud835\udefedenotes the angle between c\ud835\udc56ande\ud835\udc56. Although the minimum cosine similarity can be obtained by straightforward differentiation, here we present a more elegant and intuitive derivation using the law of sines: \u2225d\ud835\udc56\u2225 sin\ud835\udefe=\u2225c\ud835\udc56\u2225 sin\ud835\udf03=\u21d2 sin\ud835\udefe=\ud835\udeff\ud835\udc56sin\ud835\udf03 (3) where\ud835\udf03is the interior angle of the triangle opposite the side repre- sented by vector c\ud835\udc56(see Figure 2).", "mimetype": "text/plain", "start_char_idx": 13613, "end_char_idx": 14564, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8401cdeb-6662-48aa-beae-b4bb5f06a885": {"__data__": {"id_": "8401cdeb-6662-48aa-beae-b4bb5f06a885", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2855e277-9266-4da9-a41b-62970f13924a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8bdb1d78714f66ef76ff3ffa7aa204566a0b14bcd9316c73cae4ede09ad93ff0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "14effdc0-fe79-40b8-ae47-1d97a86b2018", "node_type": "1", "metadata": {}, "hash": "9eb8a5d08c6233e76a12a4b61e9863567e92f2243245d0a66af91300d9df2773", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "4b6e2f0c-cd70-401d-9c38-e4dd4a510006", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "182e6447cec68b2b3157f167c876a96b8b5869d4fbd66aee4f5d71592c27f647", "class_name": "RelatedNodeInfo"}, {"node_id": "03872e73-1622-4624-9157-0cf489f0e13d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "5e5414423b0e95f87d85f0fc3e135f82a559d6f65907985c481d1a287a1cf4b6", "class_name": "RelatedNodeInfo"}, {"node_id": "cd528d2d-349b-4636-951e-7c63480b6a20", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "ed63c946c35bec0fe5292ffacca6469a7b5ef2f06f1566450360fb6fc594ad31", "class_name": "RelatedNodeInfo"}, {"node_id": "a44a846e-1368-4dcf-b24e-cb249e06d290", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3c608367ba3d444a0c58914a2859368f349395dda7a9e86a497427852146b45b", "class_name": "RelatedNodeInfo"}, {"node_id": "fef7d2f7-47b0-4201-b0cd-bc66f8b983d4", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8d050b970df53d88be0217c7329d0af5cd8503c1ebb55983d4e510006a1b5d9c", "class_name": "RelatedNodeInfo"}, {"node_id": "f21d4276-a6c9-48b9-8169-ea1da2252944", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a7f0eea47288af766c26ad763c60322343abf2bce8f2a44c30a1a825a408d3ef", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Applying this substitution to Equation 2 gives an explicit rela- tionship between cosine similarity and the norm of the correction vector: sim(c\ud835\udc56,e\ud835\udc56)=\u221a\ufe03 1\u2212\ud835\udeff2 \ud835\udc56sin2\ud835\udf03 (4) The minimum cosine similarity occurs when \ud835\udf03=\ud835\udf0b/2and is equal: min \ud835\udf03sim(c\ud835\udc56,e\ud835\udc56)=\u221a\ufe03 1\u2212\ud835\udeff2 \ud835\udc56(5)Geometrically, if we visualize the endpoint of e\ud835\udc56tracing a sphere of radius\ud835\udeff\ud835\udc56around the endpoint of c\ud835\udc56, the case where the vector d\ud835\udc56 is orthogonal to e\ud835\udc56corresponds to this minimum (see Figure 2). Thus, by varying the norm \ud835\udeff\ud835\udc56, we can control how close the item representation is to the original content-based embedding. We apply the following strategy to constrain the correction vectors during training: we introduce a hyperparameter \ud835\udeffmaxand clip the norm of each vector if it exceeds this threshold. In the item cold start scenario, maintaining proximity to content- based embeddings enables direct use of these representations for cold items. Additionally, the proposed technique also serves as a form of regularization. Since sequential recommenders rely on MIPS, where the embedding norm directly influences item scores, it is important to manage the variation in norms across items, which we found to be substantial. 4 Experiments 4.1 Experimental settings Table 1: Statistics of the datasets after preprocessing, includ- ing average sequence length and the percentage of cold items in the ground truth (GT).", "mimetype": "text/plain", "start_char_idx": 14565, "end_char_idx": 15936, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "14effdc0-fe79-40b8-ae47-1d97a86b2018": {"__data__": {"id_": "14effdc0-fe79-40b8-ae47-1d97a86b2018", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8401cdeb-6662-48aa-beae-b4bb5f06a885", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a4eabc3b1d8f7a3cd2161e90d0b9cc8e5554df1bd0f7f85b785d34398c25e8f4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9322dd63-adad-4546-91dc-b82fb1ea8fef", "node_type": "1", "metadata": {}, "hash": "a3a574d61f13fa198394cad1371c6ef19fa9e0cdbc06d9dda64e1a3ce830f889", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "10beae5b-b1a9-488e-a38e-d20cf0f57c3a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "dc292c8e0106015b2b97f5490e260aafa017b557e40532e3416b70f7321d72d7", "class_name": "RelatedNodeInfo"}, {"node_id": "0f0324ce-b500-483f-8127-4ab86cd0b517", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0ceee1c8852c7c1ce4b337c3ba22664d5d85036ac3b1e8ed9d21848dc1215b4e", "class_name": "RelatedNodeInfo"}, {"node_id": "b0412f56-acb4-40b4-bb73-3eac0d4655fd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "34ca9058b91c3c440cdddf3caef0a413e40429077a60dddb19c134721c6757bc", "class_name": "RelatedNodeInfo"}, {"node_id": "0d008531-2a6c-4491-96b9-f8230675d5b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2e1fa76b59f3ea30d48c3ac0ef4b3772ffffa10c1e8afd1802f08dacbf9a6f04", "class_name": "RelatedNodeInfo"}, {"node_id": "d33b4179-66f9-4811-91c5-b2a7efd792ab", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f92cb8f3849db9ae098c72e9aaab161879da628033cce6318de9d36c95dd3535", "class_name": "RelatedNodeInfo"}, {"node_id": "9d1a25ea-00c8-4605-9954-1c1323e22e4b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f3a4d9992e5e76352566e0be625d7e786e5f9858b655adbadcb40f17443b4ffc", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4 Experiments 4.1 Experimental settings Table 1: Statistics of the datasets after preprocessing, includ- ing average sequence length and the percentage of cold items in the ground truth (GT). Dataset # Users # Items # Interact.Avg. Cold items length in GT Amazon-M2 FR [9] 129,983 44,049 566,806 4.3 7% Beauty [14] 21,029 11,733 149,147 7.1 25% Zvuk [16] 9,076 131,085 3,236,653 356.6 13% 4.1.1 Datasets. We evaluate our approach on three datasets from different domains. Amazon-M2 [ 9] is a dataset from the KDD Cup 2023 competition1. It comprises customer shopping sessions from six locales and includes textual item descriptions. Beauty, one of the most widely used datasets in sequential recommendation with inherent sequential patterns [ 12], contains customer reviews and is also rich in textual information. To verify that our method general- izes across modalities, we additionally examine Zvuk [ 16], a dataset with strong sequential structure [ 12] from the music streaming service containing audio-based item representations. For Amazon-M2, we use the original data provided by the au- thors, restricting our evaluation to the France locale (specifically, Task 2, Phase 1). Following [ 6,12], we remove consecutive dupli- cated items from the user sequence for all datasets.", "mimetype": "text/plain", "start_char_idx": 15745, "end_char_idx": 17030, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9322dd63-adad-4546-91dc-b82fb1ea8fef": {"__data__": {"id_": "9322dd63-adad-4546-91dc-b82fb1ea8fef", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "14effdc0-fe79-40b8-ae47-1d97a86b2018", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "1555fb3485e63369c352170c1a78d9a1972547e9d5cf674e4d25256875b186b5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "76a288f9-53f4-4e84-8d97-b368d41bd698", "node_type": "1", "metadata": {}, "hash": "98e52e2634dd3f13a63a3f106575aac8644d365de7b1bc73f2e344db494c4aea", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "c0a2b1ba-261c-4c16-b2ec-c27f47dd37d8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7208968769f07154716299643195c116805312be26f21b7908c7b4da92622486", "class_name": "RelatedNodeInfo"}, {"node_id": "fc34b30e-072c-4512-8b77-e266c67ffeb4", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b76a4ce5c48222fbd350fa0fdbd8d152a4dd077ddd9cea6854081ceb07201cb1", "class_name": "RelatedNodeInfo"}, {"node_id": "1f3039bb-27da-4e34-b4e7-3b14bd2483e1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fa83af922478610f7a3f047c2ba3f875dff7da935f7098e26592b12bb1bc91fc", "class_name": "RelatedNodeInfo"}, {"node_id": "4a409ce0-60b0-46a7-aac9-e0069a1d1a45", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "4876779517db8ffb93ce76002a5cca93decbca7b7108858fc9315efcf60db82e", "class_name": "RelatedNodeInfo"}, {"node_id": "7ba4d891-959f-449e-8179-f1521d58278b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "4c296686d883703cf07d6ed42164179b88a558925876413fd13237469a3d9e0d", "class_name": "RelatedNodeInfo"}, {"node_id": "464a52ee-13cc-4b31-a684-7d9d56b077f4", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2ce1226a137e377d6b3d60eb0aa292f8f68530ce8bc1047459dd93eccb9fb6bb", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Following [ 6,12], we remove consecutive dupli- cated items from the user sequence for all datasets. For the Zvuk dataset, we consider interactions longer than 60 seconds as positive and retain only those, while for Beauty, we filter out reviews with a rating lower than 4. Additionally, for Zvuk, we randomly sample 10,000 users to obtain a representative yet computationally efficient subset. Finally, we apply \ud835\udc5b-core filtering [ 19] with\ud835\udc5b=3to the train/validation data for Zvuk and Beauty. The final statistics of the datasets after preprocessing are summarized in Table 1. 4.1.2 Evaluation. For Amazon-M2, we use the original train-test split configuration with a 2-week training period followed by a 1-week test period. For Beauty and Zvuk, we use a global temporal split to prevent data leakage [ 8,17] with the temporal boundary set at 90% of the interactions. The validation set consists of sequences from 10% of randomly sampled users for all datasets. The last inter- action is used as the ground truth for validation and test sets, while 1https://kddcup23.github.ioRecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev Table 2: Performance on cold, warm, and all ground -truth items. Bold numbers mark the best model; the second best is underlined . Abbreviations: c.i. \u2013 content initialization, t.d.", "mimetype": "text/plain", "start_char_idx": 16930, "end_char_idx": 18312, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "76a288f9-53f4-4e84-8d97-b368d41bd698": {"__data__": {"id_": "76a288f9-53f4-4e84-8d97-b368d41bd698", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9322dd63-adad-4546-91dc-b82fb1ea8fef", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d8666d1ca684ce64d01b3b7d84146221fa392c41b3c46f6815df71d0f248f8d5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a513b767-e451-410c-b79a-380601bc5888", "node_type": "1", "metadata": {}, "hash": "1eaaea63b67e9212e407afa24c8e1eb7e5602e631aa444fe02fa9cab931cf379", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "f268ff23-4ef0-40d4-8930-334329d426ff", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9fc3cf5bc52772ff7ca38c287a4cf4efc526ddbd63e03e2d58b7b0ab2913cecb", "class_name": "RelatedNodeInfo"}, {"node_id": "5cf8fd08-0342-48d7-be27-4435c1996190", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "68ac68210d2c52ab37af93d8dc19aba9cee40431127a12f1747d4be933f1bb9d", "class_name": "RelatedNodeInfo"}, {"node_id": "50efc748-fd69-4dc4-b5e9-67712fc6c1a1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "c3e5749741fdad34ca3532b840e358bcef184d65c97a5f6bf418f6c30c946906", "class_name": "RelatedNodeInfo"}, {"node_id": "3065ba83-65ce-469a-9bc9-569c22f7502b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "562e05ee180a042ae3d505a7b2233dae040b700e6955658776bc2bb79094e781", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Bold numbers mark the best model; the second best is underlined . Abbreviations: c.i. \u2013 content initialization, t.d. \u2013 trainable delta, GT \u2013 ground truth. Metric ModelAmazon-M2 Beauty Zvuk Cold GT Warm GT Total Cold GT Warm GT Total Cold GT Warm GT Total HR@10Content-based KNN 0.454 \u00b10.000 0.383\u00b10.000 0.388\u00b10.000 0.043\u00b10.000 0.044\u00b10.000 0.044\u00b10.000 0.009\u00b10.000 0.000\u00b10.000 0.001\u00b10.000 SASRec 0.000 \u00b10.000 0.610\u00b10.003 0.567\u00b10.002 0.000\u00b10.000 0.072\u00b10.001 0.054\u00b10.001 0.000\u00b10.000 0.094\u00b10.003 0.082\u00b10.003 SASRec with c.i. 0.435 \u00b10.015 0.620\u00b10.002 0.607\u00b10.001 0.032\u00b10.004 0.088\u00b10.002 0.074\u00b10.002 0.023\u00b10.003 0.088\u00b10.002 0.080\u00b10.002 SASRec with t.d.", "mimetype": "text/plain", "start_char_idx": 18196, "end_char_idx": 18841, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a513b767-e451-410c-b79a-380601bc5888": {"__data__": {"id_": "a513b767-e451-410c-b79a-380601bc5888", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "76a288f9-53f4-4e84-8d97-b368d41bd698", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fecc2d7f7bae84392dde2ed06f90ae3f4ea884408d835ed41dfc00d26adbcfda", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9eaef3ff-f04f-444b-bb7f-84ada902b046", "node_type": "1", "metadata": {}, "hash": "e925ea57ac87671df32c12c4952b17d30a0a9654281b44577d331d086945dcf4", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "3cb07a26-fdd1-4774-b0f8-29aa21e8fb76", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fb2522fda9bfaf4f92dd8b4d34f75d9bc68f026bcd2b5b14c7aa2bcc2b5dbb11", "class_name": "RelatedNodeInfo"}, {"node_id": "2d95dc7b-2b64-4bb0-b581-6f0bb18ae0bd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e193b64ec32adf2bea1c3ed747c20128c42fb71df5b55e2a1d80d3f71f484239", "class_name": "RelatedNodeInfo"}, {"node_id": "3e23d28c-240e-4d79-8cd6-4781172dfa54", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3a87d4002838e358cec2a202470f1809ff843126190f20912d7f0d17eb9b1f25", "class_name": "RelatedNodeInfo"}, {"node_id": "7c440d64-bcd6-4811-9a1f-f70a29f65c0d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "695c10eaf6b8ecee3547507eeb51be1ba39b1709f2ee7b7aa85b45c4c357f640", "class_name": "RelatedNodeInfo"}, {"node_id": "35d04f89-ee46-445b-8cc5-daf903360930", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "70b5e3b1a11774627c42ff8ae8bf4b97dafe91db5ac8fca6a173e0c8d4cd3321", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(ours) 0.509\u00b10.005 0.617\u00b10.002 0.609\u00b10.002 0.038\u00b10.008 0.092\u00b10.002 0.078\u00b10.003 0.034\u00b10.002 0.094\u00b10.002 0.087\u00b10.002 NDCG@10Content-based KNN 0.312 \u00b10.000 0.232\u00b10.000 0.238\u00b10.000 0.022\u00b10.000 0.024\u00b10.000 0.024\u00b10.000 0.006\u00b10.000 0.000\u00b10.000 0.001\u00b10.000 SASRec 0.000 \u00b10.000 0.438\u00b10.002 0.407\u00b10.002 0.000\u00b10.000 0.043\u00b10.001 0.033\u00b10.001 0.000\u00b10.000 0.063\u00b10.001 0.055\u00b10.001 SASRec with c.i. 0.297 \u00b10.010 0.448\u00b10.001 0.438\u00b10.000 0.018\u00b10.002 0.053\u00b10.001 0.044\u00b10.001 0.014\u00b10.002 0.058\u00b10.002 0.052\u00b10.001 SASRec with t.d.", "mimetype": "text/plain", "start_char_idx": 18842, "end_char_idx": 19349, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9eaef3ff-f04f-444b-bb7f-84ada902b046": {"__data__": {"id_": "9eaef3ff-f04f-444b-bb7f-84ada902b046", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a513b767-e451-410c-b79a-380601bc5888", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9ca3fba71bd2a59a702b158eb82f6cf7e3b844f68c71ea9a1ef1ea16679defa5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc", "node_type": "1", "metadata": {}, "hash": "e4885214cb2a7d3b88085f7aea4c127ec6517844b1e1fa6e07ca653d217d7094", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "1cff163b-f8d9-49bf-8ec0-0c03e7994dd1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "115298f3d4e01a0fefcf7efe928d2a606c42351f239f58747fd2ec69c8066e3b", "class_name": "RelatedNodeInfo"}, {"node_id": "15199290-499d-482f-be5d-8846ec3f1177", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3cf578e50be6320ba77ead862663375efcf9a3ff4f859a15c187c83aafcc62db", "class_name": "RelatedNodeInfo"}, {"node_id": "84a1c9a3-0caa-42e1-961d-1d0e470a190c", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cdb3c98e9b028e40ae47975c0e0eb872f6fc2c49d00c896142d9b67e703a315e", "class_name": "RelatedNodeInfo"}, {"node_id": "7d225255-9701-49d2-ba99-d2880e6fe9af", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "dcf4c78597690fefed349dd7856bf3168f17c05b30c2af7767b3a5457b4263ed", "class_name": "RelatedNodeInfo"}, {"node_id": "bcca71aa-7fe8-4348-bb1e-dfcb91db8b11", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0ed372ea79a37c26a6a423513d8cc35438fcb541238666731c303021f9653c6d", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(ours) 0.359\u00b10.000 0.446\u00b10.002 0.440\u00b10.002 0.022\u00b10.004 0.054\u00b10.001 0.046\u00b10.002 0.021\u00b10.002 0.060\u00b10.002 0.055\u00b10.002 the previous part of the sequence is used as input to the model. This setup is appropriate for next-item prediction according to [4]. To evaluate the quality of the recommendation, we use Nor- malized Discounted Cumulative Gain (NDCG@10) and Hit Rate (HR@10) from the Replay library [ 22]. We distinguish between warm items, which are present in the training set, and cold items appearing only in the test set. To evaluate the impact on the cold- start problem, we measure the performance separately for users with warm ground-truth items and users with cold ground-truth items. Table 1 shows the proportion of such users. 4.1.3 Implementation Details. We perform the experiments with the SASRec model [ 10]. All models are trained using full cross- entropy loss following [ 11], with a batch size of 128. We employ the Adam optimizer with a learning rate of 1e-3. SASRec is configured with two transformer blocks, a single attention head, and a dropout rate of 0.3. The embedding dimension is set to 128 for Beauty and Zvuk, and to 64 for Amazon-M2. The maximum input sequence length is limited to 128 for Zvuk, and to 64 for Amazon-M2 and Beauty.", "mimetype": "text/plain", "start_char_idx": 19350, "end_char_idx": 20613, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc": {"__data__": {"id_": "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9eaef3ff-f04f-444b-bb7f-84ada902b046", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cbfbb5c20011f3c74a4b3573d4f57738733679de7abeac24c76cbe88ad8dff4a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "70a88b27-013f-479f-b346-c5064d447678", "node_type": "1", "metadata": {}, "hash": "9e1f890cade98c4b952053d3a4adf89ffc78365d81cdaf32a765a6a544578edf", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "73a668b8-64b4-41bc-b4a8-add81af6742e", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "014d94f43a5bac92a0c6291f2fe5101a7154a11595217b2671a69fc7ae7c0dea", "class_name": "RelatedNodeInfo"}, {"node_id": "997170d1-de96-48cf-872a-a344552bf671", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "470cd2488de42eceb3dd897d5f45b36dac1c1f1da610f441a726a013ee6040ed", "class_name": "RelatedNodeInfo"}, {"node_id": "e1ad7bd8-097a-4a7a-b6e4-e2376ae31287", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "431dbfab9eb6f5aaba57a41fd237fc01bd9f7ae7588d24fe15ea02094dfc28fa", "class_name": "RelatedNodeInfo"}, {"node_id": "a3a3f326-5eda-4989-a0db-fa043196b4b1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d9967c12e563e2416a9962158e73451ef6013b8c7ead6614366fd2665138798d", "class_name": "RelatedNodeInfo"}, {"node_id": "0c9ac0ae-2d00-411b-a304-afe28d16351c", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "954e56a0815d29ccdff0717b7023779ec37c759038e953dd7b6bbdd1d3b9a319", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The maximum input sequence length is limited to 128 for Zvuk, and to 64 for Amazon-M2 and Beauty. For text-based content embeddings, we employ the E5 encoder [ 24], while the Zvuk dataset includes precomputed audio embeddings2. In practice, content-based embeddings often exhibit higher di- mensionality than the model\u2019s internal representations. To recon- cile this mismatch, we first apply component-wise standardization, followed by Principal Component Analysis (PCA) to reduce the embeddings to the target dimension. To increase the statistical significance of the results, we run each experiment five times with different random seeds and calculate ag- gregated metrics. All code necessary to reproduce our experiments is available at our GitHub repository3. 4.2 Results 4.2.1 Main results. Table 2 summarizes the results of the experi- ments on all datasets. The Content-based KNN method serves as a 2https://www.kaggle.com/datasets/alexxl/zvuk-dataset 3https://github.com/ArtemF42/let-it-gocontent-based baseline that recommends items most similar to the average content embedding of the user\u2019s sequence. SASRec refers to the standard version of the model, which cannot handle cold items. SASRec with content initialization is a baseline variant where item embeddings are initialized from content and then fully fine- tuned during training. SASRec with trainable delta is our proposed approach from Section 3 with a maximum norm constraint of the delta vector \ud835\udeffmax=0.5corresponding to minimum cosine similarity of0.87.", "mimetype": "text/plain", "start_char_idx": 20516, "end_char_idx": 22041, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "70a88b27-013f-479f-b346-c5064d447678": {"__data__": {"id_": "70a88b27-013f-479f-b346-c5064d447678", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0c8d4ec34b9da587f0a636d365250ca9f6aea0e2db0f31a78f1ac36bbcb254cb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b", "node_type": "1", "metadata": {}, "hash": "cc3178ad4bab2991355904352cd363f499567236506ae00ac05893528e5399e2", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "0be360c5-d140-4c86-9e9e-a91262c29e37", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7b4b71b1c8d5e2cb24e0b694cae1b4b7166313a12fe6a81a8c42d9c0cc777746", "class_name": "RelatedNodeInfo"}, {"node_id": "c6276074-770d-4609-983f-48d70e22f1a2", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9028f5416df8df0078ef77844fdca8d8b8e11ebd89bb49ec252bfe60cce2eabb", "class_name": "RelatedNodeInfo"}, {"node_id": "8496b7a0-8a46-41d8-9b48-77e0ff368d7d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2d51d26604f39e90a05097c4f0c47ad107a4d59e9ee650277dcf71c59275c067", "class_name": "RelatedNodeInfo"}, {"node_id": "bd6ba406-0e33-4804-ac5b-d803b83b7056", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f7c70db9b2f0b831f223f30750ed2b672cc18dfc1f9f6130f6bdef3b9594a13e", "class_name": "RelatedNodeInfo"}, {"node_id": "5aa8a48e-ae16-45bd-a590-70eac1aff32a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "acfb3999afa2549aec543739aa9ac348473777819a6ea6fd9ba1891c7f12db07", "class_name": "RelatedNodeInfo"}, {"node_id": "a0058833-5ffc-4def-a6a3-10f5b4b8e3d9", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "4a4d3853c4712dcf702571ab9a4bca5b686d735932c3375262b0c55132e08e1e", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SASRec with trainable delta is our proposed approach from Section 3 with a maximum norm constraint of the delta vector \ud835\udeffmax=0.5corresponding to minimum cosine similarity of0.87. SASRec with content initialization outperforms the content-based baseline on the Zvuk dataset and performs slightly worse on the other datasets in the cold-item settings. As expected, the content- based baseline performs significantly worse on warm items. Impor- tantly, incorporating cold items into SASRec does not degrade its performance on warm items. Content initialization even improves warm-item metrics compared to the original model on Amazon-M2 and Beauty datasets. Our proposed version with a trainable delta leads to substan- tial improvements in cold-item metrics across all three datasets, outperforming the content-based baseline. Warm-item and overall performance also show slight improvements, demonstrating the robustness of our method. 4.2.2 Norm of the delta vector. The norm of the trainable delta vector is the main hyperparameter in our approach. Figure 3 shows how NDCG@10 for cold and all items changes with different values of\ud835\udeffmaxon the Amazon-M2 dataset. When \ud835\udeffmaxis too small, the model does not have enough flexibility to adjust item representa- tions, and the total quality drops significantly. When the value is too large, the embeddings move too far from their original initializa- tion, which leads to worse performance on cold items. We find that values in the range of 0.3 to 0.6 provide a good trade-off, giving the model enough capacity to learn while still keeping the embeddings close to their initialization.", "mimetype": "text/plain", "start_char_idx": 21864, "end_char_idx": 23490, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b": {"__data__": {"id_": "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "70a88b27-013f-479f-b346-c5064d447678", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "65e91ff86d44c7f7535d80f42c25b5abfe601773737cc89867d10e3a25c447de", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "73b29e23-6efb-440b-858d-7846dd96e398", "node_type": "1", "metadata": {}, "hash": "6d9f36b55bcc73aaa56eb2c11fa08c22bff9bc998c40446ec64e1d2aad2ea878", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "b1646404-4baa-4590-8141-d7b263da37c3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d5e5f6c880a1fcf536178a06a10263d297d7a18704d301771e2113ecfb502084", "class_name": "RelatedNodeInfo"}, {"node_id": "d87ab588-a219-4943-b295-6d08dd265695", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "19f7f04824cb6d6f68253269c5bab701d467a743cc88dc92126a3db4f05bfe62", "class_name": "RelatedNodeInfo"}, {"node_id": "d63182ae-cbbc-48bc-bee4-84141e90a007", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f152eee4a53ecdca4ef5134ec695a1ba10d45d7339a434c52c30ccdd55fc93dd", "class_name": "RelatedNodeInfo"}, {"node_id": "b69109bd-c8b2-4edd-b897-8e87f4471990", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b8dd67d84645e00478ab4d6e728d6f5b94cd86e01f0edebd011d0dc4a3a4240f", "class_name": "RelatedNodeInfo"}, {"node_id": "887cb2e6-de01-4bb8-bc57-4d41ac5b0ba0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "6c314e3e049e6f093d3b13f72d07c397f037e037d15ca9abf6119eebc033364b", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We find that values in the range of 0.3 to 0.6 provide a good trade-off, giving the model enough capacity to learn while still keeping the embeddings close to their initialization. 4.2.3 Cold items in input sequences. While the results in Table 2 are focused on cold items in the ground truth, Figure 4 shows how performance metrics change with the proportion of cold items inLet It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization RecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Figure 3: Mean total (top) and cold (bottom) NDCG@10 for SASRec with trainable delta evaluated against \ud835\udeffmaxon the Amazon-M2 dataset. SASRec with content initialization is provided for comparison. Low \ud835\udeffmax values yield high cold-item metrics but degrade the model\u2019s overall quality. user input sequences on the Amazon-M2 dataset. Using content- based initialization significantly improves recommendation quality when cold items are presented in the sequence. Implementing a trainable delta leads to a further, though smaller, improvement in this setting. Figure 4: Mean NDCG@10 for SASRec, SASRec with content initialization, and SASRec with trainable delta, evaluated across different proportions of warm items in test input se- quences on Amazon-M2 dataset. 4.2.4 Low-frequency items. We further analyze how recommen- dation quality metrics for ground-truth items vary with their fre- quency in the training set, as shown in Figure 5.", "mimetype": "text/plain", "start_char_idx": 23310, "end_char_idx": 24792, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "73b29e23-6efb-440b-858d-7846dd96e398": {"__data__": {"id_": "73b29e23-6efb-440b-858d-7846dd96e398", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "af6af039f529c9140d09609654c06352cc4e9b1c7a9d98dc9b0bd7918720dd8a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d82c7612-c14c-464f-8df9-eb86619797d9", "node_type": "1", "metadata": {}, "hash": "b36aaa028526f8585d292eca8219d1b6fcff8acbb36a3a118c1531fe0cf93c8d", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "3e470344-905e-404c-be6f-00abe4d2b2b6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "84d68506e8b949eb377bc80d0b9d43233365ba3f488b57292d269119efd3098e", "class_name": "RelatedNodeInfo"}, {"node_id": "e465497f-d5ce-4507-97c9-54f6f97de1aa", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "70b733d0b86b4ca6f8c17cf0a342fa5a459e26c5b0625b7e5c1e6b77d32a1c2a", "class_name": "RelatedNodeInfo"}, {"node_id": "55ce4f5c-a49c-4a26-a4bc-8c8b6b707819", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "64de707c031178f2ba346b314235e570c01d887002c83203ea0e0242702b28fd", "class_name": "RelatedNodeInfo"}, {"node_id": "f1478900-5b0a-4bd4-9d85-abc424f26e07", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "45d14afcc2361e1156ab57b8e55a73aa34cdac10af228e4e25403f4bb03c0133", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.2.4 Low-frequency items. We further analyze how recommen- dation quality metrics for ground-truth items vary with their fre- quency in the training set, as shown in Figure 5. Our trainable delta approach demonstrates improvements for rare items, with perfor- mance gradually converging to SASRec levels as item frequency increases. 5 Conclusion In this work, we proposed a simple yet effective method for ad- dressing the cold start problem in sequential recommendations by adding a small trainable delta with a bounded norm to frozen Figure 5: Mean NDCG@10 (top) and NDCG@10 relative to SASRec (bottom) for SASRec, SASRec with content initial- ization, and SASRec with trainable delta, evaluated against the frequency of ground-truth items in the training set on Amazon-M2 dataset. content-based embeddings. We evaluated our approach on datasets with text-based and audio-based embeddings, confirming its appli- cability across different modalities of item content. Our key findings demonstrate that the performance on cold items in the ground truth shows significant improvement, while the metrics on warm items remain stable without degradation. Although the approach achieves superior quality metrics, it in- troduces additional training cost due to maintaining a second em- bedding vector for each item. This memory overhead may limit scalability for extremely large item sets. Future work could address this issue by reducing the embedding size or extending our study to additional modalities and recommendation scenarios.", "mimetype": "text/plain", "start_char_idx": 24616, "end_char_idx": 26146, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d82c7612-c14c-464f-8df9-eb86619797d9": {"__data__": {"id_": "d82c7612-c14c-464f-8df9-eb86619797d9", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73b29e23-6efb-440b-858d-7846dd96e398", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3d336a2a0c7f290f7f7025c1c842744586786e7f64e766fa1da6be6953a5b0b4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "627ef3fc-ccd5-4dc6-b333-7648af9b7bc1", "node_type": "1", "metadata": {}, "hash": "384cbe052477ce1367573a9143e9e2174e077c851dcc686adea504bc2e495c04", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "b42e1405-b66a-479b-a50d-5bea7c67af17", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8dbbe87db27ee1d29611ce04cad6cc302ffc46f708ae29567718fd7e3c801472", "class_name": "RelatedNodeInfo"}, {"node_id": "a1ea30e4-5351-450b-b44e-73c76ffd7ebe", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "bc18898801ae76045bc342b5b7473fde8ec37bfdfd1cdce42c13154c203f0538", "class_name": "RelatedNodeInfo"}, {"node_id": "4187a558-80a6-4b38-816b-4cac854fa588", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fc780f9a42cc7ccc39a65e288e51e25eb181afe389d8e725b449ce5f0cfec001", "class_name": "RelatedNodeInfo"}, {"node_id": "7023420d-97a2-4e64-a5bf-9f8439a64480", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d1d6c885b6e29dc43365616d2e59b5b14501f1b55711665e6dc7f751231e59a8", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This memory overhead may limit scalability for extremely large item sets. Future work could address this issue by reducing the embedding size or extending our study to additional modalities and recommendation scenarios. References [1]Artun Boz, Wouter Zorgdrager, Zoe Kotti, Jesse Harte, Panos Louridas, Vassilios Karakoidas, Dietmar Jannach, and Marios Fragkoulis. 2025. Improving sequential recommendations with llms. ACM Transactions on Recommender Systems (2025). doi:10.1145/3711667 [2]Shaked Brody and Shoval Lagziel. 2024. SimRec: Mitigating the cold- start problem in sequential recommendation by integrating item similarity. (2024). https://www.amazon.science/publications/simrec-mitigating-the-cold- start-problem-in-sequential-recommendation-by-integrating-item-similarity [3]Hao Chen, Zefan Wang, Feiran Huang, Xiao Huang, Yue Xu, Yishi Lin, Peng He, and Zhoujun Li. 2022. Generative adversarial framework for cold-start item recommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . 2565\u20132571. doi:10.1145/ 3477495.3531897 [4]Danil Gusak, Anna Volodkevich, Anton Klenitskiy, Alexey Vasilev, and Evgeny Frolov. 2025.", "mimetype": "text/plain", "start_char_idx": 25927, "end_char_idx": 27130, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "627ef3fc-ccd5-4dc6-b333-7648af9b7bc1": {"__data__": {"id_": "627ef3fc-ccd5-4dc6-b333-7648af9b7bc1", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d82c7612-c14c-464f-8df9-eb86619797d9", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9bfd7d9049c207c519041096ef30c2dfaee5b8d3b57e9660d962126e421d2343", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b4ea218f-14e7-45ab-97c2-840461bf59e8", "node_type": "1", "metadata": {}, "hash": "62b2f4e4e63458276f4add85cb30eaba6eec842245ee1efdec756da543fa64cb", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "17a841ee-8d41-49e6-83d7-7805e0dd04f0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "1bb42d9b96fff4e6b765d873be5d0887a5cb92be6f13227ca3f70d1aba4b983f", "class_name": "RelatedNodeInfo"}, {"node_id": "0d7eef55-7570-4adf-93e0-3d06c2e67332", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e41569588369ca5c5d732eedc48f024b6580f331c2813911bd30248112a2aa70", "class_name": "RelatedNodeInfo"}, {"node_id": "2f943d51-eb6d-4848-8089-c0a0e28601fa", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7a16eafbc71ece1f7138a2f0d7d17ac8b0c73182a3b498502f25f509fdf0e253", "class_name": "RelatedNodeInfo"}, {"node_id": "9acf4a38-5d34-4bca-a295-89c9a9090a4a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "bc60e066744338ea384d14479de5f298ebc52a75d20bb1c90aaaf8283440b2a5", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2025. Time to Split: Exploring Data Splitting Strategies for Offline Evalu- ation of Sequential Recommenders. In Proceedings of the 19th ACM Conference on Recommender Systems . doi:10.1145/3705328.3748164 [5]Jesse Harte, Wouter Zorgdrager, Panos Louridas, Asterios Katsifodimos, Diet- mar Jannach, and Marios Fragkoulis. 2023. Leveraging large language models for sequential recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems . 1096\u20131102. doi:10.1145/3604915.3610639 [6]Bal\u00e1zs Hidasi and \u00c1d\u00e1m Tibor Czapp. 2023. Widespread flaws in offline eval- uation of recommender systems. In Proceedings of the 17th acm conference on recommender systems . 848\u2013855. doi:10.1145/3604915.3608839 [7]Feiran Huang, Zefan Wang, Xiao Huang, Yufeng Qian, Zhetao Li, and Hao Chen. 2023. Aligning distillation for cold-start item recommendation. In ProceedingsRecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1147\u20131157.", "mimetype": "text/plain", "start_char_idx": 27125, "end_char_idx": 28230, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b4ea218f-14e7-45ab-97c2-840461bf59e8": {"__data__": {"id_": "b4ea218f-14e7-45ab-97c2-840461bf59e8", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "627ef3fc-ccd5-4dc6-b333-7648af9b7bc1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e5b26d8c4ad886ff3599f2f92f0376f9525fd43af5cf246212305240e1062fcb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1acd86c1-984e-4c83-ac55-164400eade2b", "node_type": "1", "metadata": {}, "hash": "6f90d221ed2363280b5983c163f7784a8a3bf7e17cc4786ce5f4cff346fb0415", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "11773835-8293-4686-9553-d6da84a99592", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "57fa85f703379fe6a2afcba4715e4c115cf383d3d93f315e26bbd58ce78718c6", "class_name": "RelatedNodeInfo"}, {"node_id": "30797ee6-2932-4473-80c3-2e8d1208e985", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b96e8ad274f55e96ea7cf2c06b6ee1130d43f2cfdd088f2f3fefd9383f189e6d", "class_name": "RelatedNodeInfo"}, {"node_id": "0b57821d-7219-42b0-83c2-ff0325a4c990", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9dc7ccdf7fc2ca07252549b08334a56f1fb1635de05d90f78ef4c1e3813a7cf4", "class_name": "RelatedNodeInfo"}, {"node_id": "4ca57500-07b5-4caf-9a39-3f64fa046102", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "97779e0670c47028e7ae63177feeeb8351c707636c98f39a9579e3c9b6742aab", "class_name": "RelatedNodeInfo"}, {"node_id": "c73260f9-0170-4dce-acbb-736406103253", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "60c096c2e8a778ca934b69e60f88784b833cd1a9e1c4f589440eb4f87c70b5cc", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1147\u20131157. doi:10.1145/3539618.3591732 [8]Yitong Ji, Aixin Sun, Jie Zhang, and Chenliang Li. 2023. A critical study on data leakage in recommender system offline evaluation. ACM Transactions on Information Systems 41, 3 (2023), 1\u201327. doi:10.1145/3569930 [9]Wei Jin, Haitao Mao, Zheng Li, Haoming Jiang, Chen Luo, Hongzhi Wen, Haoyu Han, Hanqing Lu, Zhengyang Wang, Ruirui Li, et al .2023. Amazon-m2: A multilingual multi-locale shopping session dataset for recommendation and text generation. Advances in Neural Information Processing Systems 36 (2023), 8006\u2013 8026. https://dl.acm.org/doi/10.5555/3666122.3666473 [10] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom- mendation. In 2018 IEEE international conference on data mining (ICDM) . IEEE, 197\u2013206. doi:10.1109/ICDM.2018.00035 [11] Anton Klenitskiy and Alexey Vasilev. 2023. Turning dross into gold loss: is bert4rec really better than sasrec?. In Proceedings of the 17th ACM Conference on Recommender Systems . 1120\u20131125.", "mimetype": "text/plain", "start_char_idx": 28220, "end_char_idx": 29224, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1acd86c1-984e-4c83-ac55-164400eade2b": {"__data__": {"id_": "1acd86c1-984e-4c83-ac55-164400eade2b", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b4ea218f-14e7-45ab-97c2-840461bf59e8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7dbe599cce9ff6f03ce602f4563b215d270848f16159b476e43ef3c1d263b666", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "32b0ab75-2189-4d14-9ca8-12078565de81", "node_type": "1", "metadata": {}, "hash": "6402c14b3ed305e093bddeaa3fc8e0a55bf41e53e2be2f9b677bbe3966695d41", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "b666278d-7080-4b1b-9cd7-012832fb4da6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "49d9f1a26b52ea2c884a91f5057d1cacae0a289dea60f3bc6f1c8bd5067526da", "class_name": "RelatedNodeInfo"}, {"node_id": "d400e284-1968-4a56-b582-1a7ea915454b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "78e3ff07d9fb61e0257066b69047cc6306cda998f9302402d76c86966b235e6c", "class_name": "RelatedNodeInfo"}, {"node_id": "99e6e0f4-ae35-4739-b72a-d33e07a14980", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "872b01a30a4cab9f42e950ac49f0bf9500eb827d308f62a36b1d889706dcc281", "class_name": "RelatedNodeInfo"}, {"node_id": "5531d320-981a-45f3-8f77-66230ff82fa8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "bd6de047ea2373a4bc548daf53faf5b5765669b60bf24ca721335d02aa560fc8", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Turning dross into gold loss: is bert4rec really better than sasrec?. In Proceedings of the 17th ACM Conference on Recommender Systems . 1120\u20131125. doi:10.1145/3604915.3610644 [12] Anton Klenitskiy, Anna Volodkevich, Anton Pembek, and Alexey Vasilev. 2024. Does it look sequential? an analysis of datasets for evaluation of sequential recommendations. In Proceedings of the 18th ACM Conference on Recommender Systems . 1067\u20131072. doi:10.1145/3640457.3688195 [13] Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and Julian McAuley. 2023. Text is all you need: Learning language representations for se- quential recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 1258\u20131267. doi:10.1145/3580305.3599519 [14] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes. In Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval . 43\u201352. doi:10.1145/2766462.2767755 [15] Walid Shalaby, Sejoon Oh, Amir Afsharinejad, Srijan Kumar, and Xiquan Cui. 2022.", "mimetype": "text/plain", "start_char_idx": 29071, "end_char_idx": 30231, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "32b0ab75-2189-4d14-9ca8-12078565de81": {"__data__": {"id_": "32b0ab75-2189-4d14-9ca8-12078565de81", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1acd86c1-984e-4c83-ac55-164400eade2b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "147f1ddce2154caed525cfd03a72f442abef5b49c4438ceeab06cb71cecbeb4f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "node_type": "1", "metadata": {}, "hash": "ab750787865a6832a18a92c140297bab9e8814dd0328d6cef058aa3e506f1a7f", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "3e836fb6-91d6-42df-b944-3da794785511", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0c96dfee9fd7b0879a76b6fea0ba1a283a4736349854d329b0c0f5421739a7f2", "class_name": "RelatedNodeInfo"}, {"node_id": "8dad0787-2ae6-4bef-9005-66adcdc84994", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "4793ad76330006c08f5b6ac8f4c806903980b47f064f4d18032ce140060fd257", "class_name": "RelatedNodeInfo"}, {"node_id": "8e804274-1d30-47bb-b4a5-8b0a89e03a62", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "06f2e614c62e3b05f0ede470493c551d01e1d279d078dc0b44baafa9f448cf5f", "class_name": "RelatedNodeInfo"}, {"node_id": "a771935f-a85c-494c-97d3-a661f287022e", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2ddf3151faf9f9d19c8e183c56bad576bf39bfad0302558bd6ffdc2c960778bf", "class_name": "RelatedNodeInfo"}, {"node_id": "6156d81a-4ba3-4105-8b9f-518ef11f9afa", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9961abe15aa59be598a479ae35c0dcead208a986034c9bb439e21c1dff3ee175", "class_name": "RelatedNodeInfo"}, {"node_id": "297b007f-5406-4c7f-8487-a28c962f0327", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9d026e2813c6307e7120b44f8db53735f6deb538a5e5026c6e0a4b15ab1aacd5", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2022. M2TRec: Metadata-aware Multi-task Transformer for Large-scale and Cold-start free Session-based Recommendations. In Proceedings of the 16th ACM Conference on Recommender Systems . 573\u2013578. doi:10.1145/3523227.3551477 [16] Valeriy Shevchenko, Nikita Belousov, Alexey Vasilev, Vladimir Zholobov, Artyom Sosedka, Natalia Semenova, Anna Volodkevich, Andrey Savchenko, and Alexey Zaytsev. 2024. From Variability to Stability: Advancing RecSys Benchmarking Practices. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Dis- covery and Data Mining (Barcelona, Spain) (KDD \u201924) . Association for Computing Machinery, New York, NY, USA, 5701\u20135712. doi:10.1145/3637528.3671655 [17] Aixin Sun. 2023. Take a fresh look at recommender systems from an evaluation standpoint. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 2629\u20132638. doi:10.1145/ 3539618.3591931 [18] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional en- coder representations from transformer. In Proceedings of the 28th ACM in- ternational conference on information and knowledge management .", "mimetype": "text/plain", "start_char_idx": 30226, "end_char_idx": 31447, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "141c92b1-0f36-4ebd-a1eb-169ede39eb38": {"__data__": {"id_": "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "32b0ab75-2189-4d14-9ca8-12078565de81", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b6428a7b8fb31512cdd87c0218f5cd5a464aa641a181f7efc957337e2f9d54be", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6366440f-4e3c-497d-972e-42a02ac199a7", "node_type": "1", "metadata": {}, "hash": "15794286f01356bc8cff85b3bc9668ea1f9a0b5eb6f888fe58224943832c5611", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "8a744631-c44b-46a3-aac3-3eccf8b259f6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e97877e8e5b390b529a8ab06385532b9de1dc5d0128bf30ce80b52a25e30c257", "class_name": "RelatedNodeInfo"}, {"node_id": "0195271e-8992-41c3-a61b-4c63fbd03001", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f8f244fe8811316782bac254dfae84fee951481a6f5337e4f1e0c717285fbb37", "class_name": "RelatedNodeInfo"}, {"node_id": "ea125a9d-c4e2-45af-a637-1a75ee96d2ca", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "c552b457987d45b12d5e42d80e7d0be20086b565c44400932481c5a423216a3a", "class_name": "RelatedNodeInfo"}, {"node_id": "33696f3a-b4ce-48c1-ae8e-080dfce4e3cf", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "08283398a9be9dcdb013d07b0fd067f38b0d493d0672a1e7d00b764c1277958b", "class_name": "RelatedNodeInfo"}, {"node_id": "3e635e3b-99e8-4feb-b52b-b18aba01f8b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "45c97fba212dac8cc7e5d90a61a219feb0fee0dcdb1e107e42fedcc86e6fdd65", "class_name": "RelatedNodeInfo"}, {"node_id": "9154054b-d97a-4a29-8150-47cc4cf374ab", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2a9a1a9129e95cf47e7cbf3f79ece724cfcdf960bffaae6912f5bb0182021089", "class_name": "RelatedNodeInfo"}, {"node_id": "dd2a5a00-5308-443c-867b-b9546f0db6e4", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "aa4d5d06745a0b654658ae5a6a8f8dda42078584b0b91f24077c8c4f8252e3f3", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2019. BERT4Rec: Sequential recommendation with bidirectional en- coder representations from transformer. In Proceedings of the 28th ACM in- ternational conference on information and knowledge management . 1441\u20131450. doi:10.1145/3357384.3357895 [19] Zhu Sun, Di Yu, Hui Fang, Jie Yang, Xinghua Qu, Jie Zhang, and Cong Geng. 2020. Are we evaluating rigorously? benchmarking recommendation for reproducible evaluation and fair comparison. In Proceedings of the 14th ACM Conference on Recommender Systems . 23\u201332. doi:10.1145/3383313.3412489 [20] Yan-Martin Tamm and Anna Aljanaki. 2024. Comparative Analysis of Pretrained Audio Representations in Music Recommender Systems. In Proceedings of the 18th ACM Conference on Recommender Systems . 934\u2013938. doi:10.1145/3640457.3688172 [21] Aaron Van den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep content-based music recommendation. Advances in neural information processing systems 26 (2013). https://dl.acm.org/doi/10.5555/2999792.2999907 [22] Alexey Vasilev, Anna Volodkevich, Denis Kulandin, Tatiana Bysheva, and Anton Klenitskiy. 2024. RePlay: a Recommendation Framework for Experimentation and Production Use. In Proceedings of the 18th ACM Conference on Recommender Systems .", "mimetype": "text/plain", "start_char_idx": 31243, "end_char_idx": 32480, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6366440f-4e3c-497d-972e-42a02ac199a7": {"__data__": {"id_": "6366440f-4e3c-497d-972e-42a02ac199a7", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0d88ab7b7128b26976e596d77c23f1d96fa0d13016eb0c22b8ef7d72cdcf22d6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "251a9d11-5ba7-4233-bf7a-46e9b4bd0325", "node_type": "1", "metadata": {}, "hash": "888018883188a3a13208b29d7d91b8a84af7e536f22144e0f428638fdc9e39be", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "7f8e0652-c27c-4561-8ab8-b898f10adaf4", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "54a2bf7e74e710c06198d975cbb9fa13f953ef8e613b1f1cd239368d71efaf97", "class_name": "RelatedNodeInfo"}, {"node_id": "1c2e12c4-c6be-422f-b12c-46b753d6a1b0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "edbefc1349062fe3dcd15be9591c3af85965fab94deccd6e6d07bd9a556c22f9", "class_name": "RelatedNodeInfo"}, {"node_id": "5b0449d7-0e10-45af-87da-d7fe1a5218cf", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "28026f500cd484ac6d52cd06526de0e4e51f5b2233162ba28f597863c373b757", "class_name": "RelatedNodeInfo"}, {"node_id": "4b4da0ab-e078-4eaa-bcf5-fe5eeb4fbf83", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "15c5135700844b80080ee26a96b499b3177b2d060e7ee734ca9af76301255f8b", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2024. RePlay: a Recommendation Framework for Experimentation and Production Use. In Proceedings of the 18th ACM Conference on Recommender Systems . 1191\u20131194. doi:10.1145/3640457.3691701 [23] Maksims Volkovs, Guangwei Yu, and Tomi Poutanen. 2017. Dropoutnet: Ad- dressing cold start in recommender systems. Advances in neural information processing systems 30 (2017). https://dl.acm.org/doi/10.5555/3295222.3295249 [24] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. 2022. Text Embeddings by Weakly-Supervised Contrastive Pre-training. arXiv preprint  (2022). doi:10.48550/ arXiv.2212.03533 [25] Shiyu Wang, Hao Ding, Yupeng Gu, Sergul Aydore, Kousha Kalantari, and Branislav Kveton. 2024. Language-Model Prior Overcomes Cold-Start Items. arXiv preprint  (2024). doi:10.48550/arXiv.2411.09065 [26] Yinwei Wei, Xiang Wang, Qi Li, Liqiang Nie, Yan Li, Xuanping Li, and Tat-Seng Chua. 2021. Contrastive learning for cold-start recommendation.", "mimetype": "text/plain", "start_char_idx": 32333, "end_char_idx": 33334, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "251a9d11-5ba7-4233-bf7a-46e9b4bd0325": {"__data__": {"id_": "251a9d11-5ba7-4233-bf7a-46e9b4bd0325", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6366440f-4e3c-497d-972e-42a02ac199a7", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "00d2af1f45513c9313913cc14403d34eb0cde4285eb1ae1be7728ab1f92a01f7", "class_name": "RelatedNodeInfo"}, "5": [{"node_id": "480ca554-3a44-4f15-8e9a-ce28ddce9817", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "878ceae5e14f1cc76825885b9b6e75316b2e699aadebd3fd4246070d2a9ec466", "class_name": "RelatedNodeInfo"}, {"node_id": "1cf8f0db-ab6f-47cd-9406-0dd2f3071d2d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "66ed3bb8fcecd2c1cf5684668dee875122ec210309e43bad86719ab50de8b5d6", "class_name": "RelatedNodeInfo"}]}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2021. Contrastive learning for cold-start recommendation. In Proceedings of the 29th ACM international conference on multimedia . 5382\u20135390. doi:10.1145/ 3474085.3475665 [27] Yongchun Zhu, Ruobing Xie, Fuzhen Zhuang, Kaikai Ge, Ying Sun, Xu Zhang, Leyu Lin, and Juan Cao. 2021. Learning to warm up cold item embeddings for cold- start recommendation with meta scaling and shifting networks. In Proceedingsof the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1167\u20131176. doi:10.1145/3404835.", "mimetype": "text/plain", "start_char_idx": 33277, "end_char_idx": 33815, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e98eac31-9c3c-4ebe-8f13-59e55f710d10": {"__data__": {"id_": "e98eac31-9c3c-4ebe-8f13-59e55f710d10", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "db249a26-87b5-4afb-a1b8-a2e030b78e56", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "da1b67262e56212dc7898cf18384a8e39d2a44aab093b09755c2d194db34b6a4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "TITLE: Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization\n\nAUTHORS: Anton Pembek, Artem Fatkulin, Anton Klenitskiy, Alexey Vasilev\n\nABSTRACT: Many sequential recommender systems suffer from the cold start problem, where\nitems with few or no interactions cannot be effectively used by the model due\nto the absence of a trained embedding.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 400, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fdb2e7f0-24e9-407c-8cf9-52243751ad4e": {"__data__": {"id_": "fdb2e7f0-24e9-407c-8cf9-52243751ad4e", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e98eac31-9c3c-4ebe-8f13-59e55f710d10", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f34842178f284bdd920033e777bcda703f4cd37a34082567e3150b5c077befc6", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "db249a26-87b5-4afb-a1b8-a2e030b78e56", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "da1b67262e56212dc7898cf18384a8e39d2a44aab093b09755c2d194db34b6a4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Content-based approaches, which leverage\nitem metadata, are commonly used in such scenarios. One possible way is to use\nembeddings derived from content features such as textual descriptions as\ninitialization for the model embeddings. However, directly using frozen content\nembeddings often results in suboptimal performance, as they may not fully adapt\nto the recommendation task.", "mimetype": "text/plain", "start_char_idx": 401, "end_char_idx": 781, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2db9fece-00a1-4a6f-aaae-6a4933998147": {"__data__": {"id_": "2db9fece-00a1-4a6f-aaae-6a4933998147", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fdb2e7f0-24e9-407c-8cf9-52243751ad4e", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9dc6a5ef52b10ef673ab42ce5e97a94791a1135fa84ca885eb1b79fe2094c4a4", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "db249a26-87b5-4afb-a1b8-a2e030b78e56", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "da1b67262e56212dc7898cf18384a8e39d2a44aab093b09755c2d194db34b6a4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, directly using frozen content\nembeddings often results in suboptimal performance, as they may not fully adapt\nto the recommendation task. On the other hand, fine-tuning these embeddings can\ndegrade performance for cold-start items, as item representations may drift far\nfrom their original structure after training. We propose a novel approach to\naddress this limitation.", "mimetype": "text/plain", "start_char_idx": 635, "end_char_idx": 1015, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "66256c0e-8c94-488e-bf00-1da903703df0": {"__data__": {"id_": "66256c0e-8c94-488e-bf00-1da903703df0", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "cc630bfb-bac1-40b2-87e0-7d7500de63c5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e23394951f43da04bad39e40cc42828cdbbc3e7c08b69f108b9bdd6089cfb972", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "On the other hand, fine-tuning these embeddings can\ndegrade performance for cold-start items, as item representations may drift far\nfrom their original structure after training. We propose a novel approach to\naddress this limitation. Instead of entirely freezing the content embeddings or\nfine-tuning them extensively,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 318, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e90dcff2-5517-43c2-a6a1-4ba1d21a4656": {"__data__": {"id_": "e90dcff2-5517-43c2-a6a1-4ba1d21a4656", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "66256c0e-8c94-488e-bf00-1da903703df0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d7efc71e85a5778ebe99274f15d1e05edd6d5ead0060bd2c46b8293d29c1f7fd", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "cc630bfb-bac1-40b2-87e0-7d7500de63c5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e23394951f43da04bad39e40cc42828cdbbc3e7c08b69f108b9bdd6089cfb972", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We propose a novel approach to\naddress this limitation. Instead of entirely freezing the content embeddings or\nfine-tuning them extensively, we introduce a small trainable delta to frozen\nembeddings that enables the model to adapt item representa\n\nKEY DEFINITIONS: way: to use embeddings derived from content features such as textual descrip- tions as initialization for the model embeddings | This: the author\u2019s version of the work | interactions: the model cannot learn effective representations for these items,", "mimetype": "text/plain", "start_char_idx": 178, "end_char_idx": 692, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5693045b-afdf-4a0e-9505-33be4be69a3c": {"__data__": {"id_": "5693045b-afdf-4a0e-9505-33be4be69a3c", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e90dcff2-5517-43c2-a6a1-4ba1d21a4656", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7a4150933be90ff626d64b09d5a374adcb73b4cf32a9c4610679454308bd19b8", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "cc630bfb-bac1-40b2-87e0-7d7500de63c5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e23394951f43da04bad39e40cc42828cdbbc3e7c08b69f108b9bdd6089cfb972", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "leading to poor recommendation quality | issue: to leverage content- based features, such as textual descriptions, to construct embed- dings for cold items | solution: to substitute content embeddings for cold items into a trained model | component: frozen content embeddings with a fixed norm | ponent: a small trainable delta vector with a bounded norm | work: as follows: \u2022We investigate the impact of content-based embedding ini- tialization on the cold start problem in transformer-based sequential recommendation | embeddings: a common strategy for", "mimetype": "text/plain", "start_char_idx": 693, "end_char_idx": 1247, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "44085962-76ba-48da-90ee-697d9e7fc54a": {"__data__": {"id_": "44085962-76ba-48da-90ee-697d9e7fc54a", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5693045b-afdf-4a0e-9505-33be4be69a3c", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "53962d918b9957069a37b7c12bc31a8f625a5d35910391741bbd54421ce251fb", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "cc630bfb-bac1-40b2-87e0-7d7500de63c5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e23394951f43da04bad39e40cc42828cdbbc3e7c08b69f108b9bdd6089cfb972", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "| ponent: a small trainable delta vector with a bounded norm | work: as follows: \u2022We investigate the impact of content-based embedding ini- tialization on the cold start problem in transformer-based sequential recommendation | embeddings: a common strategy for addressing the item cold start problem | objective: to predict the next item the user will interact with\n\nFULL TEXT: Let It Go?", "mimetype": "text/plain", "start_char_idx": 987, "end_char_idx": 1375, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2673e9dd-96d1-42f5-903c-bf289afc91a0": {"__data__": {"id_": "2673e9dd-96d1-42f5-903c-bf289afc91a0", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "be03fd97b06563bae1fcd3d306b00940631e397d5610ee902bcbe9780c56fb3f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization Anton Pembek apembek@bk.ru Sber AI Lab, Lomonosov Moscow State University (MSU) Moscow, Russian FederationArtem Fatkulin artem42fatkulin@gmail.com Sber AI Lab, HSE University Moscow, Russian Federation Anton Klenitskiy antklen@gmail.com Sber AI Lab Moscow, Russian FederationAlexey Vasilev alexxl.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 399, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "36f1afb1-b558-4531-9cdc-616558dcfaee": {"__data__": {"id_": "36f1afb1-b558-4531-9cdc-616558dcfaee", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2673e9dd-96d1-42f5-903c-bf289afc91a0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a8545f7587481306e9b7875dcf76a5c981492d1982935aa4dabe94b797f26069", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "be03fd97b06563bae1fcd3d306b00940631e397d5610ee902bcbe9780c56fb3f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "com Sber AI Lab, HSE University Moscow, Russian Federation Anton Klenitskiy antklen@gmail.com Sber AI Lab Moscow, Russian FederationAlexey Vasilev alexxl.vasilev@yandex.ru Sber AI Lab, HSE University Moscow, Russian Federation Figure 1: Illustration of the proposed approach.", "mimetype": "text/plain", "start_char_idx": 245, "end_char_idx": 520, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "65eb96c0-affd-4497-9c15-0272053042e2": {"__data__": {"id_": "65eb96c0-affd-4497-9c15-0272053042e2", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "36f1afb1-b558-4531-9cdc-616558dcfaee", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7d0ff482cd40868ad8e6e23b26d466ca66e6df463c0bf4ef715c4bf09ad2b5b2", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "be03fd97b06563bae1fcd3d306b00940631e397d5610ee902bcbe9780c56fb3f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "com Sber AI Lab Moscow, Russian FederationAlexey Vasilev alexxl.vasilev@yandex.ru Sber AI Lab, HSE University Moscow, Russian Federation Figure 1: Illustration of the proposed approach. Abstract Many sequential recommender systems suffer from the cold start problem, where items with few or no interactions cannot be effec- tively used by the model due to the absence of a trained embed- ding.", "mimetype": "text/plain", "start_char_idx": 335, "end_char_idx": 728, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a1ca29c1-9e8d-484b-9415-dc3107357580": {"__data__": {"id_": "a1ca29c1-9e8d-484b-9415-dc3107357580", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "65eb96c0-affd-4497-9c15-0272053042e2", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a0c5362b364f623992cfbf4d6d56328b46fbd38bea3c9816f16a913bb9446e01", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "be03fd97b06563bae1fcd3d306b00940631e397d5610ee902bcbe9780c56fb3f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Abstract Many sequential recommender systems suffer from the cold start problem, where items with few or no interactions cannot be effec- tively used by the model due to the absence of a trained embed- ding. Content-based approaches, which leverage item metadata, are commonly used in such scenarios. One possible way is to use embeddings derived from content features such as textual descrip- tions as initialization for the model embeddings.", "mimetype": "text/plain", "start_char_idx": 521, "end_char_idx": 964, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e4dc984c-e3f2-4923-8645-5fcb9ab3e78e": {"__data__": {"id_": "e4dc984c-e3f2-4923-8645-5fcb9ab3e78e", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a1ca29c1-9e8d-484b-9415-dc3107357580", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e0f789e5bf63f30e28fdbf773c82c0604ac57b968ba27cfa9206c5e2b8022b80", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "be03fd97b06563bae1fcd3d306b00940631e397d5610ee902bcbe9780c56fb3f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Content-based approaches, which leverage item metadata, are commonly used in such scenarios. One possible way is to use embeddings derived from content features such as textual descrip- tions as initialization for the model embeddings. However, directly using frozen content embeddings often results in suboptimal per- formance, as they may not fully adapt to the recommendation task.", "mimetype": "text/plain", "start_char_idx": 729, "end_char_idx": 1113, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "017ffcb0-64fd-4717-bfb4-dd0029d24a77": {"__data__": {"id_": "017ffcb0-64fd-4717-bfb4-dd0029d24a77", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e4dc984c-e3f2-4923-8645-5fcb9ab3e78e", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "ca0c9799c503ef3a576738f3e98d032f3f7fabf9cb4442700e8ea372104afb5b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "be03fd97b06563bae1fcd3d306b00940631e397d5610ee902bcbe9780c56fb3f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, directly using frozen content embeddings often results in suboptimal per- formance, as they may not fully adapt to the recommendation task. On the other hand, fine-tuning these embeddings can degrade per- formance for cold-start items, as item representations may drift far from their original structure after training. We propose a novel approach to address this limitation.", "mimetype": "text/plain", "start_char_idx": 965, "end_char_idx": 1349, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a0c428d4-9bdb-4837-84c4-0e4d1cc8c134": {"__data__": {"id_": "a0c428d4-9bdb-4837-84c4-0e4d1cc8c134", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "017ffcb0-64fd-4717-bfb4-dd0029d24a77", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "5eb2fc09204437e3243291e8f0c784262d796f5b89fb084d9fe27f62b19ab29b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f2b5105-17d5-46b8-b73c-9b7672e026b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "be03fd97b06563bae1fcd3d306b00940631e397d5610ee902bcbe9780c56fb3f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "On the other hand, fine-tuning these embeddings can degrade per- formance for cold-start items, as item representations may drift far from their original structure after training. We propose a novel approach to address this limitation. Instead of entirely freezing the content embeddings or fine-tuning them extensively, we introduce a small trainable delta to frozen embed- dings that enables the model to adapt item representations without letting them go too far from their original semantic structure.", "mimetype": "text/plain", "start_char_idx": 1114, "end_char_idx": 1619, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d938c1e9-40cf-4541-8f86-471f4f006481": {"__data__": {"id_": "d938c1e9-40cf-4541-8f86-471f4f006481", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "88e12252-5fec-46c2-a2ae-6fc241f89a76", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3c45b330891265bd1c9e1909b6d484581f392cc3811ecc7652b838e79a27e597", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Instead of entirely freezing the content embeddings or fine-tuning them extensively, we introduce a small trainable delta to frozen embed- dings that enables the model to adapt item representations without letting them go too far from their original semantic structure. This approach demonstrates consistent improvements across multiple datasets and modalities, including e-commerce datasets with textual descriptions and a music dataset with audio-based representation. RecSys \u201925, Prague, Czech Republic \u00a92025 Copyright held by the owner/author(s).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 550, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5da3506c-fac9-4eb3-8288-0998c9026a57": {"__data__": {"id_": "5da3506c-fac9-4eb3-8288-0998c9026a57", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d938c1e9-40cf-4541-8f86-471f4f006481", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f14a5bdd381426bad4c2bf89470a62a80e0dc30f7a5ec6292b590c0249adb74a", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "88e12252-5fec-46c2-a2ae-6fc241f89a76", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3c45b330891265bd1c9e1909b6d484581f392cc3811ecc7652b838e79a27e597", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "RecSys \u201925, Prague, Czech Republic \u00a92025 Copyright held by the owner/author(s). Publication rights licensed to ACM. This is the author\u2019s version of the work. It is posted here for your personal use. Not for redistribution.", "mimetype": "text/plain", "start_char_idx": 471, "end_char_idx": 693, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1a93036f-9a6b-49b8-8e4e-85375e507a10": {"__data__": {"id_": "1a93036f-9a6b-49b8-8e4e-85375e507a10", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5da3506c-fac9-4eb3-8288-0998c9026a57", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cf350e0c353f824820a4a3c35582a8ad22a95a8643f3fc364061cab41840aa56", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "88e12252-5fec-46c2-a2ae-6fc241f89a76", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3c45b330891265bd1c9e1909b6d484581f392cc3811ecc7652b838e79a27e597", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Publication rights licensed to ACM. This is the author\u2019s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in Proceedings of the Nineteenth ACM Conference on Recommender Systems (RecSys \u201925), September 22\u201326, 2025, Prague, Czech Republic , https://doi.org/10.1145/3705328.3748038.CCS Concepts \u2022Information systems \u2192Recommender systems .", "mimetype": "text/plain", "start_char_idx": 551, "end_char_idx": 970, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f19243eb-b1ce-4903-b5a3-284412d9e872": {"__data__": {"id_": "f19243eb-b1ce-4903-b5a3-284412d9e872", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1a93036f-9a6b-49b8-8e4e-85375e507a10", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d72155e07806e9b90f69aa4bb498e949e5ca532777e36531e4221023644b327b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "88e12252-5fec-46c2-a2ae-6fc241f89a76", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3c45b330891265bd1c9e1909b6d484581f392cc3811ecc7652b838e79a27e597", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Keywords Recommender Systems, Sequential Recommendations, Cold-start ACM Reference Format: Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev. 2025. Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recom- mendations with Content-Based Initialization.", "mimetype": "text/plain", "start_char_idx": 971, "end_char_idx": 1251, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e7cfb727-258a-4e21-a9c5-0e0ae4195c18": {"__data__": {"id_": "e7cfb727-258a-4e21-a9c5-0e0ae4195c18", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f19243eb-b1ce-4903-b5a3-284412d9e872", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b0487fd24c9a076fac8e18d91c1b5eb693862f2ec51089b1c4326152fd205843", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "88e12252-5fec-46c2-a2ae-6fc241f89a76", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3c45b330891265bd1c9e1909b6d484581f392cc3811ecc7652b838e79a27e597", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2025. Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recom- mendations with Content-Based Initialization. In Proceedings of the Nine- teenth ACM Conference on Recommender Systems (RecSys \u201925), September 22\u201326, 2025, Prague, Czech Republic. ACM, New York, NY, USA, 6 pages.", "mimetype": "text/plain", "start_char_idx": 1130, "end_char_idx": 1418, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "18d5406c-5efd-4928-845a-25db3d586722": {"__data__": {"id_": "18d5406c-5efd-4928-845a-25db3d586722", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0a542dabfdd965760e0127e10fa41fb6b4063da88447a1e3fea916c0308a56f9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "ACM, New York, NY, USA, 6 pages. https://doi.org/10.1145/3705328.3748038 1 Introduction The cold start problem remains a significant challenge for recom- mender systems in general and sequential recommender systems in particular. These systems aim to predict a user\u2019s next interac- tion based on their history, but struggle when encountering cold items with few or no interactions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 381, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "257f60ef-b0ad-4fbc-b605-6d181656a11a": {"__data__": {"id_": "257f60ef-b0ad-4fbc-b605-6d181656a11a", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "18d5406c-5efd-4928-845a-25db3d586722", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b11ba17f02f2292eba8caebcbce0f361c1a343555f9b0a73f44d726ea18eed87", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0a542dabfdd965760e0127e10fa41fb6b4063da88447a1e3fea916c0308a56f9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These systems aim to predict a user\u2019s next interac- tion based on their history, but struggle when encountering cold items with few or no interactions. This lack of interactions means the model cannot learn effective representations for these items, leading to poor recommendation quality. A common strategy to address this issue is to leverage content- based features, such as textual descriptions, to construct embed- dings for cold items.", "mimetype": "text/plain", "start_char_idx": 230, "end_char_idx": 671, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f4e57e09-98a3-45cf-9ebf-1c9897d4370b": {"__data__": {"id_": "f4e57e09-98a3-45cf-9ebf-1c9897d4370b", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "257f60ef-b0ad-4fbc-b605-6d181656a11a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "c5f787edb48a1e092ccda6b81b121e3d3737123d0a5a3fcb5dacf285cb356b7e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0a542dabfdd965760e0127e10fa41fb6b4063da88447a1e3fea916c0308a56f9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A common strategy to address this issue is to leverage content- based features, such as textual descriptions, to construct embed- dings for cold items. However, this approach introduces a distri- bution gap: the embeddings of warm items, learned during model training, may differ significantly from content-based embeddings used for cold items. To bridge this gap, various techniques have been explored, including learning transformations from cold embeddingsv1 [cs.IR] 25 Jul 2025RecSys \u201925,", "mimetype": "text/plain", "start_char_idx": 520, "end_char_idx": 1012, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "55086b99-4947-4d9e-abb2-c96ba69ff0dd": {"__data__": {"id_": "55086b99-4947-4d9e-abb2-c96ba69ff0dd", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f4e57e09-98a3-45cf-9ebf-1c9897d4370b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "c25f1588b35d7b6176847d8febb6ba8596142925ac5270864fb90f5f63e2f671", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0a542dabfdd965760e0127e10fa41fb6b4063da88447a1e3fea916c0308a56f9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To bridge this gap, various techniques have been explored, including learning transformations from cold embeddingsv1 [cs.IR] 25 Jul 2025RecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev to the warm item embedding space [ 21,23,27], employing con- trastive learning [ 26], adversarial training [ 3],", "mimetype": "text/plain", "start_char_idx": 865, "end_char_idx": 1238, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ebf6015f-27fd-481d-aa92-de46f7f861e3": {"__data__": {"id_": "ebf6015f-27fd-481d-aa92-de46f7f861e3", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "55086b99-4947-4d9e-abb2-c96ba69ff0dd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "32acf87fb3a2ea01265c8216462d625fc322f3799d5faad711d84b5cf3f7f282", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0a542dabfdd965760e0127e10fa41fb6b4063da88447a1e3fea916c0308a56f9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev to the warm item embedding space [ 21,23,27], employing con- trastive learning [ 26], adversarial training [ 3], and distillation [ 7] to encourage similarity between cold and warm item representations.", "mimetype": "text/plain", "start_char_idx": 1073, "end_char_idx": 1328, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "267f4c36-c2e6-42f9-8915-8ea6c18fed83": {"__data__": {"id_": "267f4c36-c2e6-42f9-8915-8ea6c18fed83", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ebf6015f-27fd-481d-aa92-de46f7f861e3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "5e5ab5a987127a36b1b61a30d9db274b07eea9f16c9a0daea84dac8349b9b3fb", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0a542dabfdd965760e0127e10fa41fb6b4063da88447a1e3fea916c0308a56f9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "23,27], employing con- trastive learning [ 26], adversarial training [ 3], and distillation [ 7] to encourage similarity between cold and warm item representations. Recent works [ 1,5] demonstrated that using text embeddings as initialization for transformer-based sequential recommendation models like SASRec [ 10] and BERT4Rec [ 18] improves overall rec- ommendation quality.", "mimetype": "text/plain", "start_char_idx": 1164, "end_char_idx": 1541, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "93c2b70a-135f-496e-b14e-45caa053bf73": {"__data__": {"id_": "93c2b70a-135f-496e-b14e-45caa053bf73", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "bb7534db-e25f-428a-8778-6cb5b6f5ad95", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "182a79fe6e1d1ccefc83937560c25883e0d17d9acabae970e400e7d733cef54d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Recent works [ 1,5] demonstrated that using text embeddings as initialization for transformer-based sequential recommendation models like SASRec [ 10] and BERT4Rec [ 18] improves overall rec- ommendation quality. In our work, we investigate how content- based initialization, not limited to text but also including audio- based features, affects the cold start problem in sequential rec- ommendation.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 400, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "67e94527-9263-4837-b131-a4799f7e51e9": {"__data__": {"id_": "67e94527-9263-4837-b131-a4799f7e51e9", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "93c2b70a-135f-496e-b14e-45caa053bf73", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0f6809cad0cde45bce850bf264cf5ec0ef362b9a8ec9d39f5bde4ec8075485e1", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "bb7534db-e25f-428a-8778-6cb5b6f5ad95", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "182a79fe6e1d1ccefc83937560c25883e0d17d9acabae970e400e7d733cef54d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In our work, we investigate how content- based initialization, not limited to text but also including audio- based features, affects the cold start problem in sequential rec- ommendation. A straightforward solution is to substitute content embeddings for cold items into a trained model. However, allowing full fine-tuning of these embeddings during training can hurt per- formance on cold items, as the embeddings may drift significantly from their initial content-based representation.", "mimetype": "text/plain", "start_char_idx": 213, "end_char_idx": 700, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "62923145-ce3a-40a8-b0c4-c499785f29a6": {"__data__": {"id_": "62923145-ce3a-40a8-b0c4-c499785f29a6", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67e94527-9263-4837-b131-a4799f7e51e9", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "86ed56cacbf29ddefeca2dddd26d291df167d2eebc0769fd4134de20fec7801c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "bb7534db-e25f-428a-8778-6cb5b6f5ad95", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "182a79fe6e1d1ccefc83937560c25883e0d17d9acabae970e400e7d733cef54d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, allowing full fine-tuning of these embeddings during training can hurt per- formance on cold items, as the embeddings may drift significantly from their initial content-based representation. On the other hand, fully freezing content embeddings limits the model\u2019s flexibility and hurts overall performance, as it cannot fully adapt to the interaction data. To address these limitations, we propose an approach where item embeddings consist of two components. The first component is frozen content embeddings with a fixed norm.", "mimetype": "text/plain", "start_char_idx": 501, "end_char_idx": 1035, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "00cd7f5b-7518-4ade-81a2-63ab6f97aabc": {"__data__": {"id_": "00cd7f5b-7518-4ade-81a2-63ab6f97aabc", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "62923145-ce3a-40a8-b0c4-c499785f29a6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "ba6c7e4c0a01a5a846b05685f0665c677fc598ca9ea3cb44f462cfa94ebb114c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "bb7534db-e25f-428a-8778-6cb5b6f5ad95", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "182a79fe6e1d1ccefc83937560c25883e0d17d9acabae970e400e7d733cef54d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To address these limitations, we propose an approach where item embeddings consist of two components. The first component is frozen content embeddings with a fixed norm. The second com- ponent is a small trainable delta vector with a bounded norm. This setup allows the model to adapt item representations to the interac- tion data without letting them go far from their original semantic structure derived from content.", "mimetype": "text/plain", "start_char_idx": 866, "end_char_idx": 1286, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8038baa3-f888-4c86-9e5d-fb963c4ce5fd": {"__data__": {"id_": "8038baa3-f888-4c86-9e5d-fb963c4ce5fd", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "00cd7f5b-7518-4ade-81a2-63ab6f97aabc", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "c1a7f67a675ec23774eaaafd81ca9bc45a3f0efeccde7c14376c5a854cb80a15", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "bb7534db-e25f-428a-8778-6cb5b6f5ad95", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "182a79fe6e1d1ccefc83937560c25883e0d17d9acabae970e400e7d733cef54d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The second com- ponent is a small trainable delta vector with a bounded norm. This setup allows the model to adapt item representations to the interac- tion data without letting them go far from their original semantic structure derived from content. As a result, it improves recommen- dation quality on new items without sacrificing performance on those seen during training.", "mimetype": "text/plain", "start_char_idx": 1036, "end_char_idx": 1412, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "61c8cea0-fafd-48a7-874d-f597795d15a8": {"__data__": {"id_": "61c8cea0-fafd-48a7-874d-f597795d15a8", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8038baa3-f888-4c86-9e5d-fb963c4ce5fd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "39561cc1e96e90d208a390cce7e3c7ab73e38d442eb198f038daeb6557b19058", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "bb7534db-e25f-428a-8778-6cb5b6f5ad95", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "182a79fe6e1d1ccefc83937560c25883e0d17d9acabae970e400e7d733cef54d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "As a result, it improves recommen- dation quality on new items without sacrificing performance on those seen during training. The main contributions of our work are as follows: \u2022We investigate the impact of content-based embedding ini- tialization on the cold start problem in transformer-based sequential recommendation. \u2022We propose a method that learns a small trainable delta with bounded norm on top of frozen content embeddings.", "mimetype": "text/plain", "start_char_idx": 1287, "end_char_idx": 1720, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d5781ced-bcdf-46e5-8e63-877991d14207": {"__data__": {"id_": "d5781ced-bcdf-46e5-8e63-877991d14207", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "27a59c5ab4b6fccb1f670fb18b2f2d58a2b596690bad8c622cd94e7ddf6e7391", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\u2022We propose a method that learns a small trainable delta with bounded norm on top of frozen content embeddings. \u2022We demonstrate that this approach consistently improves performance on cold items across different data modalities, including textual item descriptions and audio representations of songs. 2 Related Work Using content-based representations to derive model embeddings is a common strategy for addressing the item cold start problem. Different approaches have been proposed to align cold item em- beddings with the warm embedding space.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 546, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8af3a283-7382-4582-b416-6d0cef2edfa6": {"__data__": {"id_": "8af3a283-7382-4582-b416-6d0cef2edfa6", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d5781ced-bcdf-46e5-8e63-877991d14207", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f31ac9efce8a11cd661fe95d564199e7dffb03837840ffe529ae806b97a78ba9", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "27a59c5ab4b6fccb1f670fb18b2f2d58a2b596690bad8c622cd94e7ddf6e7391", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2 Related Work Using content-based representations to derive model embeddings is a common strategy for addressing the item cold start problem. Different approaches have been proposed to align cold item em- beddings with the warm embedding space. The work [ 21] predicts latent factors directly from a song\u2019s audio content.", "mimetype": "text/plain", "start_char_idx": 301, "end_char_idx": 623, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "51918c55-025f-4906-bfb0-b0bfe491171c": {"__data__": {"id_": "51918c55-025f-4906-bfb0-b0bfe491171c", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8af3a283-7382-4582-b416-6d0cef2edfa6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "af3396c87ecbef865995780da59f9d6acca3abd50f2a13a3f552ff4c9fc9217e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "27a59c5ab4b6fccb1f670fb18b2f2d58a2b596690bad8c622cd94e7ddf6e7391", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Different approaches have been proposed to align cold item em- beddings with the warm embedding space. The work [ 21] predicts latent factors directly from a song\u2019s audio content. DropoutNet [ 23] takes both latent preference factors and content features as input and applies input dropout to the latent factors during training, forcing the model to rely on content when preference information is missing.", "mimetype": "text/plain", "start_char_idx": 444, "end_char_idx": 849, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "870c0c78-3dc0-438e-a7c3-01243e73e58a": {"__data__": {"id_": "870c0c78-3dc0-438e-a7c3-01243e73e58a", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "51918c55-025f-4906-bfb0-b0bfe491171c", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9a65f83ee7729c45b763576f3c1ea5d836e8fd51851e8f7c55a1ebba3a41b30c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "27a59c5ab4b6fccb1f670fb18b2f2d58a2b596690bad8c622cd94e7ddf6e7391", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "DropoutNet [ 23] takes both latent preference factors and content features as input and applies input dropout to the latent factors during training, forcing the model to rely on content when preference information is missing. The paper [ 27] uses meta networks to generate item- specific scaling and shifting functions that transform cold item embeddings into the warm feature space. CLCRec [ 26] applies con- trastive learning to maximize the mutual information between item content representations and collaborative embeddings.", "mimetype": "text/plain", "start_char_idx": 624, "end_char_idx": 1153, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d8d747b8-d81a-419d-8083-7f8523d53feb": {"__data__": {"id_": "d8d747b8-d81a-419d-8083-7f8523d53feb", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "870c0c78-3dc0-438e-a7c3-01243e73e58a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3f35109a7c6ef6a3911023feec680d8ede1395f8fdf50d458abaaa356cd3ba6c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "27a59c5ab4b6fccb1f670fb18b2f2d58a2b596690bad8c622cd94e7ddf6e7391", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "CLCRec [ 26] applies con- trastive learning to maximize the mutual information between item content representations and collaborative embeddings. GAR [ 3] em- ploys adversarial training between a generator and a recommender to ensure that generated cold item embeddings have a similar distri- bution to warm ones.", "mimetype": "text/plain", "start_char_idx": 1008, "end_char_idx": 1321, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a8f1e88e-ff95-496f-81d6-17e468412c91": {"__data__": {"id_": "a8f1e88e-ff95-496f-81d6-17e468412c91", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d8d747b8-d81a-419d-8083-7f8523d53feb", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "01eb4db1289b82aebbce2640b6a9fc945fba513b9084ef646ff8dc649090736b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "27a59c5ab4b6fccb1f670fb18b2f2d58a2b596690bad8c622cd94e7ddf6e7391", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "GAR [ 3] em- ploys adversarial training between a generator and a recommender to ensure that generated cold item embeddings have a similar distri- bution to warm ones. ALDI [ 7] introduces a distillation framework where warm items act as \"teachers\" and cold items as \"students,\" aligning the students\u2019 content-based predictions with the teachers\u2019behavior-based predictions. These works mainly focus on collabo- rative filtering models rather than sequential recommendations.", "mimetype": "text/plain", "start_char_idx": 1154, "end_char_idx": 1628, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2b0058fc-1a45-474e-9544-ec4e9faae58c": {"__data__": {"id_": "2b0058fc-1a45-474e-9544-ec4e9faae58c", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a8f1e88e-ff95-496f-81d6-17e468412c91", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "660345f2eb69f9736b9620342ca1b721f04b20d76f854085f0ec4031bb49a45f", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6df56ab1-fcff-4ae7-901a-9a5f555b123d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "27a59c5ab4b6fccb1f670fb18b2f2d58a2b596690bad8c622cd94e7ddf6e7391", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These works mainly focus on collabo- rative filtering models rather than sequential recommendations. For sequential recommendations, M2TRec [ 15] introduces an item-ID-free framework that learns item representations directly from metadata and uses multi-task learning.", "mimetype": "text/plain", "start_char_idx": 1528, "end_char_idx": 1796, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "96bdd5d3-a773-482d-a30d-06d7d77395aa": {"__data__": {"id_": "96bdd5d3-a773-482d-a30d-06d7d77395aa", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0b48d73f-7b7d-48ee-b07c-c7803a538edd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "70ff16738ffbbd01dd90d5a35e8594cc952353abfa683af4723e228df28f2daa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These works mainly focus on collabo- rative filtering models rather than sequential recommendations. For sequential recommendations, M2TRec [ 15] introduces an item-ID-free framework that learns item representations directly from metadata and uses multi-task learning. Recformer [ 13] models items and user preferences using language representations derived solely from item textual attributes. This approach, however, in- creases computational complexity compared to ID-based methods due to much longer input sequences.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 520, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ef94c2bc-3eb7-4146-85bc-5713adff1302": {"__data__": {"id_": "ef94c2bc-3eb7-4146-85bc-5713adff1302", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "96bdd5d3-a773-482d-a30d-06d7d77395aa", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "02ca7df05dbcc6c428e2fc8f881f9f2f9db81a6bd698644e40af4d7bb7213509", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0b48d73f-7b7d-48ee-b07c-c7803a538edd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "70ff16738ffbbd01dd90d5a35e8594cc952353abfa683af4723e228df28f2daa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Recformer [ 13] models items and user preferences using language representations derived solely from item textual attributes. This approach, however, in- creases computational complexity compared to ID-based methods due to much longer input sequences. In contrast to these works, we focus on leveraging content embeddings within classic ID-based models like SASRec. SimRec [ 2] and the work [ 25] incorporate item similarities derived from textual embeddings into the training process of such models using customized loss functions.", "mimetype": "text/plain", "start_char_idx": 269, "end_char_idx": 801, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c05bca4c-5716-479f-9d85-6b9593fd13d8": {"__data__": {"id_": "c05bca4c-5716-479f-9d85-6b9593fd13d8", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef94c2bc-3eb7-4146-85bc-5713adff1302", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d86af8e6ce1f5faf07f3c5cec10461c9f641984d3759cec799f4cf4421fb82c3", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0b48d73f-7b7d-48ee-b07c-c7803a538edd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "70ff16738ffbbd01dd90d5a35e8594cc952353abfa683af4723e228df28f2daa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SimRec [ 2] and the work [ 25] incorporate item similarities derived from textual embeddings into the training process of such models using customized loss functions. Unlike our approach, they consider tail items - those with very few in- teractions but not completely new - as cold. The works [ 1,5] use textual embeddings to initialize the transformer embedding layer and show that this approach improves recommendation metrics. However, they do not specifically address the cold start problem.", "mimetype": "text/plain", "start_char_idx": 635, "end_char_idx": 1131, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d3739567-9d85-4d3e-b562-9b18a0fe7718": {"__data__": {"id_": "d3739567-9d85-4d3e-b562-9b18a0fe7718", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c05bca4c-5716-479f-9d85-6b9593fd13d8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "ebec9844273c29158cc58ad39cd18c573cfe030e9b38e87c9cffdc34c79be059", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0b48d73f-7b7d-48ee-b07c-c7803a538edd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "70ff16738ffbbd01dd90d5a35e8594cc952353abfa683af4723e228df28f2daa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The works [ 1,5] use textual embeddings to initialize the transformer embedding layer and show that this approach improves recommendation metrics. However, they do not specifically address the cold start problem. The paper [ 20] explores the usage of frozen pretrained audio repre- sentations for music recommendations without any fine-tuning. 3 Approach 3.1 Task formulation LetUbe the set of users and Ibe the set of items.", "mimetype": "text/plain", "start_char_idx": 919, "end_char_idx": 1344, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "81b11a8d-9cd6-4b83-9dfd-d06fb630e5f3": {"__data__": {"id_": "81b11a8d-9cd6-4b83-9dfd-d06fb630e5f3", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d3739567-9d85-4d3e-b562-9b18a0fe7718", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "132d6970ade9590cadee98bd5339da2e134c0d53587626457248733b0c0daa2d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "0b48d73f-7b7d-48ee-b07c-c7803a538edd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "70ff16738ffbbd01dd90d5a35e8594cc952353abfa683af4723e228df28f2daa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3 Approach 3.1 Task formulation LetUbe the set of users and Ibe the set of items. In the sequential recommendation setting, we are given an ordered history of user interactions with items. The objective is to predict the next item the user will interact with.", "mimetype": "text/plain", "start_char_idx": 1263, "end_char_idx": 1522, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "47a07172-514d-4d6d-8d70-98c529ca03e7": {"__data__": {"id_": "47a07172-514d-4d6d-8d70-98c529ca03e7", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7bae6336d1987ef51f49a27907b1e437c612369799e9f7b3b455b6736d26c6b1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In the sequential recommendation setting, we are given an ordered history of user interactions with items. The objective is to predict the next item the user will interact with. State-of-the-art sequential recommender systems (e.g., SASRec and BERT4Rec) typically define a learnable embedding function \ud835\udc38:I\u2192R\ud835\udc5a, which maps each item \ud835\udc56\u2208Ito a vector representation e\ud835\udc56\u2208R\ud835\udc5a.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 367, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "49f949a8-0735-49af-870e-1ffde8de81c9": {"__data__": {"id_": "49f949a8-0735-49af-870e-1ffde8de81c9", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "47a07172-514d-4d6d-8d70-98c529ca03e7", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a83f4daec7f6c2ec04aa1243892fa4ac23407e7e633d58cdf6c98b82d3b36d34", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7bae6336d1987ef51f49a27907b1e437c612369799e9f7b3b455b6736d26c6b1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A transformer-based architecture aggregates a sequence of user interactions into a user representation h\ud835\udc62\u2208R\ud835\udc5a.", "mimetype": "text/plain", "start_char_idx": 368, "end_char_idx": 477, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "eedc9a90-b5d5-4912-9092-9d2490f79c24": {"__data__": {"id_": "eedc9a90-b5d5-4912-9092-9d2490f79c24", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49f949a8-0735-49af-870e-1ffde8de81c9", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a00bdb373f810b6c0b87550968f34a9312c9d6cc66e1a1985550e45a2af0dfb4", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7bae6336d1987ef51f49a27907b1e437c612369799e9f7b3b455b6736d26c6b1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A transformer-based architecture aggregates a sequence of user interactions into a user representation h\ud835\udc62\u2208R\ud835\udc5a. This representation is then used in a Maximum Inner Product Search (MIPS) to compute relevance scores for all items: \ud835\udc5f(\ud835\udc62,\ud835\udc56)=h\ud835\udc62\u00b7e\ud835\udc56(1) While demonstrating superior overall performance, such models fail to handle new items due to the absence of trained embeddings for them \u2014 a problem called item cold start.", "mimetype": "text/plain", "start_char_idx": 368, "end_char_idx": 783, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7ab2825a-5f7c-4550-afe8-901081e154f6": {"__data__": {"id_": "7ab2825a-5f7c-4550-afe8-901081e154f6", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eedc9a90-b5d5-4912-9092-9d2490f79c24", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "45b27161a44c9c16ff3bc8e4d0717baed81fb3dd9320fc94fe39a8b61da82dcb", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7bae6336d1987ef51f49a27907b1e437c612369799e9f7b3b455b6736d26c6b1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "At the same time, enabling the model to make use of cold items can increase recom- mendation diversity, improve overall performance by leveraging interactions with newly introduced content, and extend the model\u2019s deployment lifetime by reducing the need for frequent retraining. Addressing this limitation is therefore crucial for building robust and efficient recommender systems. 3.2 Content-based initialization In many domains, items are accompanied by additional information, such as textual descriptions for goods or sound-based embeddings for music tracks.", "mimetype": "text/plain", "start_char_idx": 784, "end_char_idx": 1347, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "62c5299b-1bf0-4bf1-8c51-116c95825420": {"__data__": {"id_": "62c5299b-1bf0-4bf1-8c51-116c95825420", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7ab2825a-5f7c-4550-afe8-901081e154f6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f60a1a0e28e6aa2624538a25745a41dcc55afcfeae19b167bb5a31f08fc12c7d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7bae6336d1987ef51f49a27907b1e437c612369799e9f7b3b455b6736d26c6b1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Addressing this limitation is therefore crucial for building robust and efficient recommender systems. 3.2 Content-based initialization In many domains, items are accompanied by additional information, such as textual descriptions for goods or sound-based embeddings for music tracks. In the absence of trained embeddings for new items, it is reasonable to utilize this content information to gener- ate initial representations.", "mimetype": "text/plain", "start_char_idx": 1063, "end_char_idx": 1491, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "164847cd-f3fe-4ff4-a218-4c3272542352": {"__data__": {"id_": "164847cd-f3fe-4ff4-a218-4c3272542352", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "eabe9e88a8098b712d8494defdf592fbe801549145734a040b04500c1f8fe038", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In the absence of trained embeddings for new items, it is reasonable to utilize this content information to gener- ate initial representations. For cold items, these representations can be used as-is during inference, while for warm items, they can be fine-tuned along with other parts of the model during training. Prior works have shown [ 1,5] that initializing the model with text-based embeddings can significantly improve recommendation quality.Let It Go?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 460, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7171672f-3d76-4671-b19a-0d002c808b11": {"__data__": {"id_": "7171672f-3d76-4671-b19a-0d002c808b11", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "164847cd-f3fe-4ff4-a218-4c3272542352", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "6ecbddfac184f530ef487d689a20d6dda7e19156b160906c84d5997772fe9749", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "eabe9e88a8098b712d8494defdf592fbe801549145734a040b04500c1f8fe038", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Prior works have shown [ 1,5] that initializing the model with text-based embeddings can significantly improve recommendation quality.Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization RecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Nevertheless, the effectiveness of content-based initialization de- pends critically on both the quality of the source information and the capabilities of the encoder model.", "mimetype": "text/plain", "start_char_idx": 316, "end_char_idx": 794, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "07364ea6-e560-49e5-8f36-3d64a72d9f38": {"__data__": {"id_": "07364ea6-e560-49e5-8f36-3d64a72d9f38", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7171672f-3d76-4671-b19a-0d002c808b11", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "64a09a0aad6ba54aa74a453b28c713eda635fb4408a9140cd5afcdc9021bc5e5", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "eabe9e88a8098b712d8494defdf592fbe801549145734a040b04500c1f8fe038", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, as previously shown in [ 20], different audio encoding techniques demonstrate various performance when used to generate music track represen- tations. Furthermore, the direct use of content-based embeddings comes with a major drawback: freezing them during training leads to degraded model performance, while allowing them to be updated makes the approach less suitable for the item cold start scenario.", "mimetype": "text/plain", "start_char_idx": 795, "end_char_idx": 1211, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "36cbc85e-6884-415e-8239-c4ad7ac472e1": {"__data__": {"id_": "36cbc85e-6884-415e-8239-c4ad7ac472e1", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07364ea6-e560-49e5-8f36-3d64a72d9f38", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "597994176b73dabbb2fe9ebecf6e9ccdf290380fa2803e749763ac4f71d3306c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "eabe9e88a8098b712d8494defdf592fbe801549145734a040b04500c1f8fe038", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Furthermore, the direct use of content-based embeddings comes with a major drawback: freezing them during training leads to degraded model performance, while allowing them to be updated makes the approach less suitable for the item cold start scenario. That is, once training is complete, the content-based embeddings of cold items remain outside the learned representation space, re- sulting in poor generalization to unseen items.", "mimetype": "text/plain", "start_char_idx": 959, "end_char_idx": 1391, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "04c2eed4-7b4c-46e4-a197-0a22bf5357eb": {"__data__": {"id_": "04c2eed4-7b4c-46e4-a197-0a22bf5357eb", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "36cbc85e-6884-415e-8239-c4ad7ac472e1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "63309ba7ca7e8fafcddf5b12e8d279a4ef2a0691bb5c2a5b567985b2983a029b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "eabe9e88a8098b712d8494defdf592fbe801549145734a040b04500c1f8fe038", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "That is, once training is complete, the content-based embeddings of cold items remain outside the learned representation space, re- sulting in poor generalization to unseen items. 3.3 Representation adjustment To overcome this limitation, we propose freezing content-based item embeddings, fixing their norm, and training only a small delta layer. This allows the model to adjust item representations slightly while keeping them close to the original embeddings. di ei ci\u03b8 \u03b3 Figure 2: Geometric representation of the proposed approach.", "mimetype": "text/plain", "start_char_idx": 1212, "end_char_idx": 1747, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "71aa0155-3650-424b-80d3-d39b8c47f0f5": {"__data__": {"id_": "71aa0155-3650-424b-80d3-d39b8c47f0f5", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2855e277-9266-4da9-a41b-62970f13924a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8bdb1d78714f66ef76ff3ffa7aa204566a0b14bcd9316c73cae4ede09ad93ff0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This allows the model to adjust item representations slightly while keeping them close to the original embeddings. di ei ci\u03b8 \u03b3 Figure 2: Geometric representation of the proposed approach. c\ud835\udc56is a frozen content-based item embedding, d\ud835\udc56is the corre- sponding trainable correction vector and e\ud835\udc56is the final item representation. Formally,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 334, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e66d8f48-4744-4c7c-af37-f336f2106dc0": {"__data__": {"id_": "e66d8f48-4744-4c7c-af37-f336f2106dc0", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "71aa0155-3650-424b-80d3-d39b8c47f0f5", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2fe70c984e2d68ca5fac9c50a61d0f3fee7e0dbe74915a9dc190dbf9eacdcf01", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2855e277-9266-4da9-a41b-62970f13924a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8bdb1d78714f66ef76ff3ffa7aa204566a0b14bcd9316c73cae4ede09ad93ff0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "c\ud835\udc56is a frozen content-based item embedding, d\ud835\udc56is the corre- sponding trainable correction vector and e\ud835\udc56is the final item representation. Formally, given a content-based embedding c\ud835\udc56\u2208R\ud835\udc5aof an item \ud835\udc56\u2208Iwith unit norm\u2225c\ud835\udc56\u2225=1,", "mimetype": "text/plain", "start_char_idx": 188, "end_char_idx": 407, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "271872ae-f2e5-43c7-9ede-e4a01d149ada": {"__data__": {"id_": "271872ae-f2e5-43c7-9ede-e4a01d149ada", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e66d8f48-4744-4c7c-af37-f336f2106dc0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d6069d2b3bee92f31f900be64f8f78089a8f37519c939a9c412e5aaab31fba7a", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2855e277-9266-4da9-a41b-62970f13924a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8bdb1d78714f66ef76ff3ffa7aa204566a0b14bcd9316c73cae4ede09ad93ff0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Formally, given a content-based embedding c\ud835\udc56\u2208R\ud835\udc5aof an item \ud835\udc56\u2208Iwith unit norm\u2225c\ud835\udc56\u2225=1, and a trainable delta vector d\ud835\udc56\u2208R\ud835\udc5a with\u2225d\ud835\udc56\u2225=\ud835\udeff\ud835\udc56, where 0\u2264\ud835\udeff\ud835\udc56<1,", "mimetype": "text/plain", "start_char_idx": 325, "end_char_idx": 469, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3d234c0b-4bc1-4565-8944-328cf3c2c90e": {"__data__": {"id_": "3d234c0b-4bc1-4565-8944-328cf3c2c90e", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "271872ae-f2e5-43c7-9ede-e4a01d149ada", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a7695702a51dcaf44547957d5ad937d95448b12de0e0cb24d142861ae1b17fe6", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2855e277-9266-4da9-a41b-62970f13924a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8bdb1d78714f66ef76ff3ffa7aa204566a0b14bcd9316c73cae4ede09ad93ff0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "and a trainable delta vector d\ud835\udc56\u2208R\ud835\udc5a with\u2225d\ud835\udc56\u2225=\ud835\udeff\ud835\udc56, where 0\u2264\ud835\udeff\ud835\udc56<1, we consider the cosine similarity between the original embedding and its adjusted form e\ud835\udc56=c\ud835\udc56+d\ud835\udc56: sim(c\ud835\udc56,", "mimetype": "text/plain", "start_char_idx": 408, "end_char_idx": 574, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "67614e3e-03e1-4acb-adaf-edb0c6b8f21b": {"__data__": {"id_": "67614e3e-03e1-4acb-adaf-edb0c6b8f21b", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3d234c0b-4bc1-4565-8944-328cf3c2c90e", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "bac9b358bd997f4bc5fdfa8469d46c9ba0ab1c0aa277ba4d4f4a981afe4941c2", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2855e277-9266-4da9-a41b-62970f13924a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8bdb1d78714f66ef76ff3ffa7aa204566a0b14bcd9316c73cae4ede09ad93ff0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "where 0\u2264\ud835\udeff\ud835\udc56<1, we consider the cosine similarity between the original embedding and its adjusted form e\ud835\udc56=c\ud835\udc56+d\ud835\udc56: sim(c\ud835\udc56,e\ud835\udc56)=cos\ud835\udefe=\u221a\ufe03 1\u2212sin2\ud835\udefe (2) where\ud835\udefedenotes the angle between c\ud835\udc56ande\ud835\udc56. Although the minimum cosine similarity can be obtained by straightforward differentiation,", "mimetype": "text/plain", "start_char_idx": 456, "end_char_idx": 729, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "217fb68d-c222-405e-9cc5-530acc1d60cb": {"__data__": {"id_": "217fb68d-c222-405e-9cc5-530acc1d60cb", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67614e3e-03e1-4acb-adaf-edb0c6b8f21b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f93705b4d4131ffabbb10171576dbdc7eb3bf10b63422bd2d68ae4ffcf1412ae", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "2855e277-9266-4da9-a41b-62970f13924a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8bdb1d78714f66ef76ff3ffa7aa204566a0b14bcd9316c73cae4ede09ad93ff0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Although the minimum cosine similarity can be obtained by straightforward differentiation, here we present a more elegant and intuitive derivation using the law of sines: \u2225d\ud835\udc56\u2225 sin\ud835\udefe=\u2225c\ud835\udc56\u2225 sin\ud835\udf03=\u21d2 sin\ud835\udefe=\ud835\udeff\ud835\udc56sin\ud835\udf03 (3) where\ud835\udf03is the interior angle of the triangle opposite the side repre- sented by vector c\ud835\udc56(see Figure 2).", "mimetype": "text/plain", "start_char_idx": 639, "end_char_idx": 951, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4b6e2f0c-cd70-401d-9c38-e4dd4a510006": {"__data__": {"id_": "4b6e2f0c-cd70-401d-9c38-e4dd4a510006", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8401cdeb-6662-48aa-beae-b4bb5f06a885", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a4eabc3b1d8f7a3cd2161e90d0b9cc8e5554df1bd0f7f85b785d34398c25e8f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Applying this substitution to Equation 2 gives an explicit rela- tionship between cosine similarity and the norm of the correction vector: sim(c\ud835\udc56,e\ud835\udc56)=\u221a\ufe03 1\u2212\ud835\udeff2 \ud835\udc56sin2\ud835\udf03 (4) The minimum cosine similarity occurs when \ud835\udf03=\ud835\udf0b/2and is equal: min \ud835\udf03sim(c\ud835\udc56,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 242, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "03872e73-1622-4624-9157-0cf489f0e13d": {"__data__": {"id_": "03872e73-1622-4624-9157-0cf489f0e13d", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4b6e2f0c-cd70-401d-9c38-e4dd4a510006", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "182e6447cec68b2b3157f167c876a96b8b5869d4fbd66aee4f5d71592c27f647", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8401cdeb-6662-48aa-beae-b4bb5f06a885", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a4eabc3b1d8f7a3cd2161e90d0b9cc8e5554df1bd0f7f85b785d34398c25e8f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "e\ud835\udc56)=\u221a\ufe03 1\u2212\ud835\udeff2 \ud835\udc56(5)Geometrically, if we visualize the endpoint of e\ud835\udc56tracing a sphere of radius\ud835\udeff\ud835\udc56around the endpoint of c\ud835\udc56, the case where the vector d\ud835\udc56 is orthogonal to e\ud835\udc56corresponds to this minimum (see Figure 2).", "mimetype": "text/plain", "start_char_idx": 242, "end_char_idx": 453, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cd528d2d-349b-4636-951e-7c63480b6a20": {"__data__": {"id_": "cd528d2d-349b-4636-951e-7c63480b6a20", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "03872e73-1622-4624-9157-0cf489f0e13d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "5e5414423b0e95f87d85f0fc3e135f82a559d6f65907985c481d1a287a1cf4b6", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8401cdeb-6662-48aa-beae-b4bb5f06a885", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a4eabc3b1d8f7a3cd2161e90d0b9cc8e5554df1bd0f7f85b785d34398c25e8f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "the case where the vector d\ud835\udc56 is orthogonal to e\ud835\udc56corresponds to this minimum (see Figure 2). Thus, by varying the norm \ud835\udeff\ud835\udc56, we can control how close the item representation is to the original content-based embedding. We apply the following strategy to constrain the correction vectors during training: we introduce a hyperparameter \ud835\udeffmaxand clip the norm of each vector if it exceeds this threshold.", "mimetype": "text/plain", "start_char_idx": 362, "end_char_idx": 758, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a44a846e-1368-4dcf-b24e-cb249e06d290": {"__data__": {"id_": "a44a846e-1368-4dcf-b24e-cb249e06d290", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cd528d2d-349b-4636-951e-7c63480b6a20", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "ed63c946c35bec0fe5292ffacca6469a7b5ef2f06f1566450360fb6fc594ad31", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8401cdeb-6662-48aa-beae-b4bb5f06a885", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a4eabc3b1d8f7a3cd2161e90d0b9cc8e5554df1bd0f7f85b785d34398c25e8f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We apply the following strategy to constrain the correction vectors during training: we introduce a hyperparameter \ud835\udeffmaxand clip the norm of each vector if it exceeds this threshold. In the item cold start scenario, maintaining proximity to content- based embeddings enables direct use of these representations for cold items. Additionally, the proposed technique also serves as a form of regularization.", "mimetype": "text/plain", "start_char_idx": 577, "end_char_idx": 980, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fef7d2f7-47b0-4201-b0cd-bc66f8b983d4": {"__data__": {"id_": "fef7d2f7-47b0-4201-b0cd-bc66f8b983d4", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a44a846e-1368-4dcf-b24e-cb249e06d290", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3c608367ba3d444a0c58914a2859368f349395dda7a9e86a497427852146b45b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8401cdeb-6662-48aa-beae-b4bb5f06a885", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a4eabc3b1d8f7a3cd2161e90d0b9cc8e5554df1bd0f7f85b785d34398c25e8f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In the item cold start scenario, maintaining proximity to content- based embeddings enables direct use of these representations for cold items. Additionally, the proposed technique also serves as a form of regularization. Since sequential recommenders rely on MIPS, where the embedding norm directly influences item scores, it is important to manage the variation in norms across items, which we found to be substantial.", "mimetype": "text/plain", "start_char_idx": 759, "end_char_idx": 1179, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f21d4276-a6c9-48b9-8169-ea1da2252944": {"__data__": {"id_": "f21d4276-a6c9-48b9-8169-ea1da2252944", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fef7d2f7-47b0-4201-b0cd-bc66f8b983d4", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8d050b970df53d88be0217c7329d0af5cd8503c1ebb55983d4e510006a1b5d9c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "8401cdeb-6662-48aa-beae-b4bb5f06a885", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "a4eabc3b1d8f7a3cd2161e90d0b9cc8e5554df1bd0f7f85b785d34398c25e8f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since sequential recommenders rely on MIPS, where the embedding norm directly influences item scores, it is important to manage the variation in norms across items, which we found to be substantial. 4 Experiments 4.1 Experimental settings Table 1: Statistics of the datasets after preprocessing, includ- ing average sequence length and the percentage of cold items in the ground truth (GT).", "mimetype": "text/plain", "start_char_idx": 981, "end_char_idx": 1371, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "10beae5b-b1a9-488e-a38e-d20cf0f57c3a": {"__data__": {"id_": "10beae5b-b1a9-488e-a38e-d20cf0f57c3a", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "14effdc0-fe79-40b8-ae47-1d97a86b2018", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "1555fb3485e63369c352170c1a78d9a1972547e9d5cf674e4d25256875b186b5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4 Experiments 4.1 Experimental settings Table 1: Statistics of the datasets after preprocessing, includ- ing average sequence length and the percentage of cold items in the ground truth (GT). Dataset # Users # Items # Interact.Avg.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 231, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0f0324ce-b500-483f-8127-4ab86cd0b517": {"__data__": {"id_": "0f0324ce-b500-483f-8127-4ab86cd0b517", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10beae5b-b1a9-488e-a38e-d20cf0f57c3a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "dc292c8e0106015b2b97f5490e260aafa017b557e40532e3416b70f7321d72d7", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "14effdc0-fe79-40b8-ae47-1d97a86b2018", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "1555fb3485e63369c352170c1a78d9a1972547e9d5cf674e4d25256875b186b5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Dataset # Users # Items # Interact.Avg. Cold items length in GT Amazon-M2 FR [9] 129,983 44,049 566,806 4.3 7% Beauty [14] 21,029 11,733 149,147 7.1 25% Zvuk [16] 9,076 131,085 3,236,653 356.6 13% 4.1.1 Datasets.", "mimetype": "text/plain", "start_char_idx": 192, "end_char_idx": 404, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b0412f56-acb4-40b4-bb73-3eac0d4655fd": {"__data__": {"id_": "b0412f56-acb4-40b4-bb73-3eac0d4655fd", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0f0324ce-b500-483f-8127-4ab86cd0b517", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0ceee1c8852c7c1ce4b337c3ba22664d5d85036ac3b1e8ed9d21848dc1215b4e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "14effdc0-fe79-40b8-ae47-1d97a86b2018", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "1555fb3485e63369c352170c1a78d9a1972547e9d5cf674e4d25256875b186b5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We evaluate our approach on three datasets from different domains. Amazon-M2 [ 9] is a dataset from the KDD Cup 2023 competition1. It comprises customer shopping sessions from six locales and includes textual item descriptions. Beauty, one of the most widely used datasets in sequential recommendation with inherent sequential patterns [ 12], contains customer reviews and is also rich in textual information.", "mimetype": "text/plain", "start_char_idx": 405, "end_char_idx": 814, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0d008531-2a6c-4491-96b9-f8230675d5b3": {"__data__": {"id_": "0d008531-2a6c-4491-96b9-f8230675d5b3", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b0412f56-acb4-40b4-bb73-3eac0d4655fd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "34ca9058b91c3c440cdddf3caef0a413e40429077a60dddb19c134721c6757bc", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "14effdc0-fe79-40b8-ae47-1d97a86b2018", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "1555fb3485e63369c352170c1a78d9a1972547e9d5cf674e4d25256875b186b5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It comprises customer shopping sessions from six locales and includes textual item descriptions. Beauty, one of the most widely used datasets in sequential recommendation with inherent sequential patterns [ 12], contains customer reviews and is also rich in textual information. To verify that our method general- izes across modalities, we additionally examine Zvuk [ 16], a dataset with strong sequential structure [ 12] from the music streaming service containing audio-based item representations.", "mimetype": "text/plain", "start_char_idx": 536, "end_char_idx": 1036, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d33b4179-66f9-4811-91c5-b2a7efd792ab": {"__data__": {"id_": "d33b4179-66f9-4811-91c5-b2a7efd792ab", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0d008531-2a6c-4491-96b9-f8230675d5b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2e1fa76b59f3ea30d48c3ac0ef4b3772ffffa10c1e8afd1802f08dacbf9a6f04", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "14effdc0-fe79-40b8-ae47-1d97a86b2018", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "1555fb3485e63369c352170c1a78d9a1972547e9d5cf674e4d25256875b186b5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To verify that our method general- izes across modalities, we additionally examine Zvuk [ 16], a dataset with strong sequential structure [ 12] from the music streaming service containing audio-based item representations. For Amazon-M2, we use the original data provided by the au- thors, restricting our evaluation to the France locale (specifically, Task 2, Phase 1).", "mimetype": "text/plain", "start_char_idx": 815, "end_char_idx": 1184, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9d1a25ea-00c8-4605-9954-1c1323e22e4b": {"__data__": {"id_": "9d1a25ea-00c8-4605-9954-1c1323e22e4b", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d33b4179-66f9-4811-91c5-b2a7efd792ab", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f92cb8f3849db9ae098c72e9aaab161879da628033cce6318de9d36c95dd3535", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "14effdc0-fe79-40b8-ae47-1d97a86b2018", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "1555fb3485e63369c352170c1a78d9a1972547e9d5cf674e4d25256875b186b5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For Amazon-M2, we use the original data provided by the au- thors, restricting our evaluation to the France locale (specifically, Task 2, Phase 1). Following [ 6,12], we remove consecutive dupli- cated items from the user sequence for all datasets.", "mimetype": "text/plain", "start_char_idx": 1037, "end_char_idx": 1285, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c0a2b1ba-261c-4c16-b2ec-c27f47dd37d8": {"__data__": {"id_": "c0a2b1ba-261c-4c16-b2ec-c27f47dd37d8", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9322dd63-adad-4546-91dc-b82fb1ea8fef", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d8666d1ca684ce64d01b3b7d84146221fa392c41b3c46f6815df71d0f248f8d5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Following [ 6,12], we remove consecutive dupli- cated items from the user sequence for all datasets. For the Zvuk dataset, we consider interactions longer than 60 seconds as positive and retain only those, while for Beauty, we filter out reviews with a rating lower than 4. Additionally, for Zvuk, we randomly sample 10,000 users to obtain a representative yet computationally efficient subset.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 394, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fc34b30e-072c-4512-8b77-e266c67ffeb4": {"__data__": {"id_": "fc34b30e-072c-4512-8b77-e266c67ffeb4", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c0a2b1ba-261c-4c16-b2ec-c27f47dd37d8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7208968769f07154716299643195c116805312be26f21b7908c7b4da92622486", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9322dd63-adad-4546-91dc-b82fb1ea8fef", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d8666d1ca684ce64d01b3b7d84146221fa392c41b3c46f6815df71d0f248f8d5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Additionally, for Zvuk, we randomly sample 10,000 users to obtain a representative yet computationally efficient subset. Finally, we apply \ud835\udc5b-core filtering [ 19] with\ud835\udc5b=3to the train/validation data for Zvuk and Beauty. The final statistics of the datasets after preprocessing are summarized in Table 1. 4.1.2 Evaluation.", "mimetype": "text/plain", "start_char_idx": 274, "end_char_idx": 594, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1f3039bb-27da-4e34-b4e7-3b14bd2483e1": {"__data__": {"id_": "1f3039bb-27da-4e34-b4e7-3b14bd2483e1", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fc34b30e-072c-4512-8b77-e266c67ffeb4", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b76a4ce5c48222fbd350fa0fdbd8d152a4dd077ddd9cea6854081ceb07201cb1", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9322dd63-adad-4546-91dc-b82fb1ea8fef", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d8666d1ca684ce64d01b3b7d84146221fa392c41b3c46f6815df71d0f248f8d5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The final statistics of the datasets after preprocessing are summarized in Table 1. 4.1.2 Evaluation. For Amazon-M2, we use the original train-test split configuration with a 2-week training period followed by a 1-week test period. For Beauty and Zvuk, we use a global temporal split to prevent data leakage [ 8,17] with the temporal boundary set at 90% of the interactions.", "mimetype": "text/plain", "start_char_idx": 493, "end_char_idx": 867, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4a409ce0-60b0-46a7-aac9-e0069a1d1a45": {"__data__": {"id_": "4a409ce0-60b0-46a7-aac9-e0069a1d1a45", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1f3039bb-27da-4e34-b4e7-3b14bd2483e1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fa83af922478610f7a3f047c2ba3f875dff7da935f7098e26592b12bb1bc91fc", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9322dd63-adad-4546-91dc-b82fb1ea8fef", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d8666d1ca684ce64d01b3b7d84146221fa392c41b3c46f6815df71d0f248f8d5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For Beauty and Zvuk, we use a global temporal split to prevent data leakage [ 8,17] with the temporal boundary set at 90% of the interactions. The validation set consists of sequences from 10% of randomly sampled users for all datasets.", "mimetype": "text/plain", "start_char_idx": 725, "end_char_idx": 961, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7ba4d891-959f-449e-8179-f1521d58278b": {"__data__": {"id_": "7ba4d891-959f-449e-8179-f1521d58278b", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4a409ce0-60b0-46a7-aac9-e0069a1d1a45", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "4876779517db8ffb93ce76002a5cca93decbca7b7108858fc9315efcf60db82e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9322dd63-adad-4546-91dc-b82fb1ea8fef", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d8666d1ca684ce64d01b3b7d84146221fa392c41b3c46f6815df71d0f248f8d5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The validation set consists of sequences from 10% of randomly sampled users for all datasets. The last inter- action is used as the ground truth for validation and test sets, while 1https://kddcup23.github.ioRecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev Table 2: Performance on cold, warm, and all ground -truth items.", "mimetype": "text/plain", "start_char_idx": 868, "end_char_idx": 1265, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "464a52ee-13cc-4b31-a684-7d9d56b077f4": {"__data__": {"id_": "464a52ee-13cc-4b31-a684-7d9d56b077f4", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7ba4d891-959f-449e-8179-f1521d58278b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "4c296686d883703cf07d6ed42164179b88a558925876413fd13237469a3d9e0d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9322dd63-adad-4546-91dc-b82fb1ea8fef", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d8666d1ca684ce64d01b3b7d84146221fa392c41b3c46f6815df71d0f248f8d5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Bold numbers mark the best model; the second best is underlined . Abbreviations: c.i. \u2013 content initialization, t.d.", "mimetype": "text/plain", "start_char_idx": 1266, "end_char_idx": 1382, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f268ff23-4ef0-40d4-8930-334329d426ff": {"__data__": {"id_": "f268ff23-4ef0-40d4-8930-334329d426ff", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "76a288f9-53f4-4e84-8d97-b368d41bd698", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fecc2d7f7bae84392dde2ed06f90ae3f4ea884408d835ed41dfc00d26adbcfda", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Bold numbers mark the best model; the second best is underlined . Abbreviations: c.i. \u2013 content initialization, t.d. \u2013 trainable delta, GT \u2013 ground truth. Metric ModelAmazon-M2 Beauty Zvuk Cold GT Warm GT Total Cold GT Warm GT Total Cold GT Warm GT Total HR@10Content-based KNN 0.454 \u00b10.000 0.383\u00b10.000 0.388\u00b10.000 0.043\u00b10.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 323, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5cf8fd08-0342-48d7-be27-4435c1996190": {"__data__": {"id_": "5cf8fd08-0342-48d7-be27-4435c1996190", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f268ff23-4ef0-40d4-8930-334329d426ff", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9fc3cf5bc52772ff7ca38c287a4cf4efc526ddbd63e03e2d58b7b0ab2913cecb", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "76a288f9-53f4-4e84-8d97-b368d41bd698", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fecc2d7f7bae84392dde2ed06f90ae3f4ea884408d835ed41dfc00d26adbcfda", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "454 \u00b10.000 0.383\u00b10.000 0.388\u00b10.000 0.043\u00b10.000 0.044\u00b10.000 0.044\u00b10.000 0.009\u00b10.000 0.000\u00b10.000 0.001\u00b10.000 SASRec 0.000 \u00b10.000 0.610\u00b10.003 0.567\u00b10.002 0.000\u00b10.", "mimetype": "text/plain", "start_char_idx": 280, "end_char_idx": 439, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "50efc748-fd69-4dc4-b5e9-67712fc6c1a1": {"__data__": {"id_": "50efc748-fd69-4dc4-b5e9-67712fc6c1a1", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5cf8fd08-0342-48d7-be27-4435c1996190", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "68ac68210d2c52ab37af93d8dc19aba9cee40431127a12f1747d4be933f1bb9d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "76a288f9-53f4-4e84-8d97-b368d41bd698", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fecc2d7f7bae84392dde2ed06f90ae3f4ea884408d835ed41dfc00d26adbcfda", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "000 0.000\u00b10.000 0.001\u00b10.000 SASRec 0.000 \u00b10.000 0.610\u00b10.003 0.567\u00b10.002 0.000\u00b10.000 0.072\u00b10.001 0.054\u00b10.001 0.000\u00b10.000 0.094\u00b10.003 0.082\u00b10.003 SASRec with c.i.", "mimetype": "text/plain", "start_char_idx": 359, "end_char_idx": 519, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3065ba83-65ce-469a-9bc9-569c22f7502b": {"__data__": {"id_": "3065ba83-65ce-469a-9bc9-569c22f7502b", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "50efc748-fd69-4dc4-b5e9-67712fc6c1a1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "c3e5749741fdad34ca3532b840e358bcef184d65c97a5f6bf418f6c30c946906", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "76a288f9-53f4-4e84-8d97-b368d41bd698", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fecc2d7f7bae84392dde2ed06f90ae3f4ea884408d835ed41dfc00d26adbcfda", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "000 0.072\u00b10.001 0.054\u00b10.001 0.000\u00b10.000 0.094\u00b10.003 0.082\u00b10.003 SASRec with c.i. 0.435 \u00b10.015 0.620\u00b10.002 0.607\u00b10.001 0.032\u00b10.004 0.088\u00b10.002 0.074\u00b10.002 0.023\u00b10.003 0.088\u00b10.002 0.080\u00b10.002 SASRec with t.d.", "mimetype": "text/plain", "start_char_idx": 439, "end_char_idx": 645, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3cb07a26-fdd1-4774-b0f8-29aa21e8fb76": {"__data__": {"id_": "3cb07a26-fdd1-4774-b0f8-29aa21e8fb76", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a513b767-e451-410c-b79a-380601bc5888", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9ca3fba71bd2a59a702b158eb82f6cf7e3b844f68c71ea9a1ef1ea16679defa5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(ours) 0.509\u00b10.005 0.617\u00b10.002 0.609\u00b10.002 0.038\u00b10.008 0.092\u00b10.002 0.078\u00b10.003 0.034\u00b10.002 0.094\u00b10.002 0.087\u00b10.002 NDCG@10Content-based KNN 0.312 \u00b10.000 0.232\u00b10.000 0.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 167, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2d95dc7b-2b64-4bb0-b581-6f0bb18ae0bd": {"__data__": {"id_": "2d95dc7b-2b64-4bb0-b581-6f0bb18ae0bd", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3cb07a26-fdd1-4774-b0f8-29aa21e8fb76", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fb2522fda9bfaf4f92dd8b4d34f75d9bc68f026bcd2b5b14c7aa2bcc2b5dbb11", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a513b767-e451-410c-b79a-380601bc5888", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9ca3fba71bd2a59a702b158eb82f6cf7e3b844f68c71ea9a1ef1ea16679defa5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "034\u00b10.002 0.094\u00b10.002 0.087\u00b10.002 NDCG@10Content-based KNN 0.312 \u00b10.000 0.232\u00b10.000 0.238\u00b10.000 0.022\u00b10.000 0.024\u00b10.000 0.024\u00b10.000 0.006\u00b10.000 0.000\u00b10.000 0.001\u00b10.", "mimetype": "text/plain", "start_char_idx": 81, "end_char_idx": 245, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3e23d28c-240e-4d79-8cd6-4781172dfa54": {"__data__": {"id_": "3e23d28c-240e-4d79-8cd6-4781172dfa54", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2d95dc7b-2b64-4bb0-b581-6f0bb18ae0bd", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e193b64ec32adf2bea1c3ed747c20128c42fb71df5b55e2a1d80d3f71f484239", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a513b767-e451-410c-b79a-380601bc5888", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9ca3fba71bd2a59a702b158eb82f6cf7e3b844f68c71ea9a1ef1ea16679defa5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "000 0.022\u00b10.000 0.024\u00b10.000 0.024\u00b10.000 0.006\u00b10.000 0.000\u00b10.000 0.001\u00b10.000 SASRec 0.000 \u00b10.000 0.438\u00b10.002 0.407\u00b10.002 0.000\u00b10.000 0.043\u00b10.001 0.033\u00b10.001 0.", "mimetype": "text/plain", "start_char_idx": 173, "end_char_idx": 331, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7c440d64-bcd6-4811-9a1f-f70a29f65c0d": {"__data__": {"id_": "7c440d64-bcd6-4811-9a1f-f70a29f65c0d", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3e23d28c-240e-4d79-8cd6-4781172dfa54", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3a87d4002838e358cec2a202470f1809ff843126190f20912d7f0d17eb9b1f25", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a513b767-e451-410c-b79a-380601bc5888", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9ca3fba71bd2a59a702b158eb82f6cf7e3b844f68c71ea9a1ef1ea16679defa5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "000 \u00b10.000 0.438\u00b10.002 0.407\u00b10.002 0.000\u00b10.000 0.043\u00b10.001 0.033\u00b10.001 0.000\u00b10.000 0.063\u00b10.001 0.055\u00b10.001 SASRec with c.i.", "mimetype": "text/plain", "start_char_idx": 258, "end_char_idx": 381, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "35d04f89-ee46-445b-8cc5-daf903360930": {"__data__": {"id_": "35d04f89-ee46-445b-8cc5-daf903360930", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c440d64-bcd6-4811-9a1f-f70a29f65c0d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "695c10eaf6b8ecee3547507eeb51be1ba39b1709f2ee7b7aa85b45c4c357f640", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "a513b767-e451-410c-b79a-380601bc5888", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9ca3fba71bd2a59a702b158eb82f6cf7e3b844f68c71ea9a1ef1ea16679defa5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "000 0.043\u00b10.001 0.033\u00b10.001 0.000\u00b10.000 0.063\u00b10.001 0.055\u00b10.001 SASRec with c.i. 0.297 \u00b10.010 0.448\u00b10.001 0.438\u00b10.000 0.018\u00b10.002 0.053\u00b10.001 0.044\u00b10.001 0.014\u00b10.002 0.058\u00b10.002 0.052\u00b10.001 SASRec with t.d.", "mimetype": "text/plain", "start_char_idx": 301, "end_char_idx": 507, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1cff163b-f8d9-49bf-8ec0-0c03e7994dd1": {"__data__": {"id_": "1cff163b-f8d9-49bf-8ec0-0c03e7994dd1", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9eaef3ff-f04f-444b-bb7f-84ada902b046", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cbfbb5c20011f3c74a4b3573d4f57738733679de7abeac24c76cbe88ad8dff4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(ours) 0.359\u00b10.000 0.446\u00b10.002 0.440\u00b10.002 0.022\u00b10.004 0.054\u00b10.001 0.046\u00b10.002 0.021\u00b10.002 0.060\u00b10.002 0.055\u00b10.002 the previous part of the sequence is used as input to the model.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 179, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "15199290-499d-482f-be5d-8846ec3f1177": {"__data__": {"id_": "15199290-499d-482f-be5d-8846ec3f1177", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1cff163b-f8d9-49bf-8ec0-0c03e7994dd1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "115298f3d4e01a0fefcf7efe928d2a606c42351f239f58747fd2ec69c8066e3b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9eaef3ff-f04f-444b-bb7f-84ada902b046", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cbfbb5c20011f3c74a4b3573d4f57738733679de7abeac24c76cbe88ad8dff4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This setup is appropriate for next-item prediction according to [4]. To evaluate the quality of the recommendation, we use Nor- malized Discounted Cumulative Gain (NDCG@10) and Hit Rate (HR@10) from the Replay library [ 22]. We distinguish between warm items, which are present in the training set, and cold items appearing only in the test set.", "mimetype": "text/plain", "start_char_idx": 180, "end_char_idx": 525, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "84a1c9a3-0caa-42e1-961d-1d0e470a190c": {"__data__": {"id_": "84a1c9a3-0caa-42e1-961d-1d0e470a190c", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "15199290-499d-482f-be5d-8846ec3f1177", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3cf578e50be6320ba77ead862663375efcf9a3ff4f859a15c187c83aafcc62db", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9eaef3ff-f04f-444b-bb7f-84ada902b046", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cbfbb5c20011f3c74a4b3573d4f57738733679de7abeac24c76cbe88ad8dff4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We distinguish between warm items, which are present in the training set, and cold items appearing only in the test set. To evaluate the impact on the cold- start problem, we measure the performance separately for users with warm ground-truth items and users with cold ground-truth items. Table 1 shows the proportion of such users. 4.1.3 Implementation Details. We perform the experiments with the SASRec model [ 10].", "mimetype": "text/plain", "start_char_idx": 405, "end_char_idx": 823, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7d225255-9701-49d2-ba99-d2880e6fe9af": {"__data__": {"id_": "7d225255-9701-49d2-ba99-d2880e6fe9af", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "84a1c9a3-0caa-42e1-961d-1d0e470a190c", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cdb3c98e9b028e40ae47975c0e0eb872f6fc2c49d00c896142d9b67e703a315e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9eaef3ff-f04f-444b-bb7f-84ada902b046", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cbfbb5c20011f3c74a4b3573d4f57738733679de7abeac24c76cbe88ad8dff4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Table 1 shows the proportion of such users. 4.1.3 Implementation Details. We perform the experiments with the SASRec model [ 10]. All models are trained using full cross- entropy loss following [ 11], with a batch size of 128. We employ the Adam optimizer with a learning rate of 1e-3. SASRec is configured with two transformer blocks, a single attention head, and a dropout rate of 0.3.", "mimetype": "text/plain", "start_char_idx": 694, "end_char_idx": 1081, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bcca71aa-7fe8-4348-bb1e-dfcb91db8b11": {"__data__": {"id_": "bcca71aa-7fe8-4348-bb1e-dfcb91db8b11", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7d225255-9701-49d2-ba99-d2880e6fe9af", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "dcf4c78597690fefed349dd7856bf3168f17c05b30c2af7767b3a5457b4263ed", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "9eaef3ff-f04f-444b-bb7f-84ada902b046", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "cbfbb5c20011f3c74a4b3573d4f57738733679de7abeac24c76cbe88ad8dff4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We employ the Adam optimizer with a learning rate of 1e-3. SASRec is configured with two transformer blocks, a single attention head, and a dropout rate of 0.3. The embedding dimension is set to 128 for Beauty and Zvuk, and to 64 for Amazon-M2. The maximum input sequence length is limited to 128 for Zvuk, and to 64 for Amazon-M2 and Beauty.", "mimetype": "text/plain", "start_char_idx": 921, "end_char_idx": 1263, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "73a668b8-64b4-41bc-b4a8-add81af6742e": {"__data__": {"id_": "73a668b8-64b4-41bc-b4a8-add81af6742e", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0c8d4ec34b9da587f0a636d365250ca9f6aea0e2db0f31a78f1ac36bbcb254cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The maximum input sequence length is limited to 128 for Zvuk, and to 64 for Amazon-M2 and Beauty. For text-based content embeddings, we employ the E5 encoder [ 24], while the Zvuk dataset includes precomputed audio embeddings2. In practice, content-based embeddings often exhibit higher di- mensionality than the model\u2019s internal representations.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 346, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "997170d1-de96-48cf-872a-a344552bf671": {"__data__": {"id_": "997170d1-de96-48cf-872a-a344552bf671", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73a668b8-64b4-41bc-b4a8-add81af6742e", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "014d94f43a5bac92a0c6291f2fe5101a7154a11595217b2671a69fc7ae7c0dea", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0c8d4ec34b9da587f0a636d365250ca9f6aea0e2db0f31a78f1ac36bbcb254cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In practice, content-based embeddings often exhibit higher di- mensionality than the model\u2019s internal representations. To recon- cile this mismatch, we first apply component-wise standardization, followed by Principal Component Analysis (PCA) to reduce the embeddings to the target dimension. To increase the statistical significance of the results, we run each experiment five times with different random seeds and calculate ag- gregated metrics. All code necessary to reproduce our experiments is available at our GitHub repository3.", "mimetype": "text/plain", "start_char_idx": 228, "end_char_idx": 763, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e1ad7bd8-097a-4a7a-b6e4-e2376ae31287": {"__data__": {"id_": "e1ad7bd8-097a-4a7a-b6e4-e2376ae31287", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "997170d1-de96-48cf-872a-a344552bf671", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "470cd2488de42eceb3dd897d5f45b36dac1c1f1da610f441a726a013ee6040ed", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0c8d4ec34b9da587f0a636d365250ca9f6aea0e2db0f31a78f1ac36bbcb254cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To increase the statistical significance of the results, we run each experiment five times with different random seeds and calculate ag- gregated metrics. All code necessary to reproduce our experiments is available at our GitHub repository3. 4.2 Results 4.2.1 Main results. Table 2 summarizes the results of the experi- ments on all datasets.", "mimetype": "text/plain", "start_char_idx": 521, "end_char_idx": 864, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a3a3f326-5eda-4989-a0db-fa043196b4b1": {"__data__": {"id_": "a3a3f326-5eda-4989-a0db-fa043196b4b1", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e1ad7bd8-097a-4a7a-b6e4-e2376ae31287", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "431dbfab9eb6f5aaba57a41fd237fc01bd9f7ae7588d24fe15ea02094dfc28fa", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0c8d4ec34b9da587f0a636d365250ca9f6aea0e2db0f31a78f1ac36bbcb254cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "All code necessary to reproduce our experiments is available at our GitHub repository3. 4.2 Results 4.2.1 Main results. Table 2 summarizes the results of the experi- ments on all datasets. The Content-based KNN method serves as a 2https://www.kaggle.com/datasets/alexxl/zvuk-dataset 3https://github.com/ArtemF42/let-it-gocontent-based baseline that recommends items most similar to the average content embedding of the user\u2019s sequence.", "mimetype": "text/plain", "start_char_idx": 676, "end_char_idx": 1111, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0c9ac0ae-2d00-411b-a304-afe28d16351c": {"__data__": {"id_": "0c9ac0ae-2d00-411b-a304-afe28d16351c", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a3a3f326-5eda-4989-a0db-fa043196b4b1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d9967c12e563e2416a9962158e73451ef6013b8c7ead6614366fd2665138798d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0c8d4ec34b9da587f0a636d365250ca9f6aea0e2db0f31a78f1ac36bbcb254cb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SASRec refers to the standard version of the model, which cannot handle cold items. SASRec with content initialization is a baseline variant where item embeddings are initialized from content and then fully fine- tuned during training. SASRec with trainable delta is our proposed approach from Section 3 with a maximum norm constraint of the delta vector \ud835\udeffmax=0.5corresponding to minimum cosine similarity of0.87.", "mimetype": "text/plain", "start_char_idx": 1112, "end_char_idx": 1525, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0be360c5-d140-4c86-9e9e-a91262c29e37": {"__data__": {"id_": "0be360c5-d140-4c86-9e9e-a91262c29e37", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "70a88b27-013f-479f-b346-c5064d447678", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "65e91ff86d44c7f7535d80f42c25b5abfe601773737cc89867d10e3a25c447de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SASRec with trainable delta is our proposed approach from Section 3 with a maximum norm constraint of the delta vector \ud835\udeffmax=0.5corresponding to minimum cosine similarity of0.87. SASRec with content initialization outperforms the content-based baseline on the Zvuk dataset and performs slightly worse on the other datasets in the cold-item settings. As expected, the content- based baseline performs significantly worse on warm items.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 433, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c6276074-770d-4609-983f-48d70e22f1a2": {"__data__": {"id_": "c6276074-770d-4609-983f-48d70e22f1a2", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0be360c5-d140-4c86-9e9e-a91262c29e37", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7b4b71b1c8d5e2cb24e0b694cae1b4b7166313a12fe6a81a8c42d9c0cc777746", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "70a88b27-013f-479f-b346-c5064d447678", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "65e91ff86d44c7f7535d80f42c25b5abfe601773737cc89867d10e3a25c447de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SASRec with content initialization outperforms the content-based baseline on the Zvuk dataset and performs slightly worse on the other datasets in the cold-item settings. As expected, the content- based baseline performs significantly worse on warm items. Impor- tantly, incorporating cold items into SASRec does not degrade its performance on warm items. Content initialization even improves warm-item metrics compared to the original model on Amazon-M2 and Beauty datasets.", "mimetype": "text/plain", "start_char_idx": 178, "end_char_idx": 653, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8496b7a0-8a46-41d8-9b48-77e0ff368d7d": {"__data__": {"id_": "8496b7a0-8a46-41d8-9b48-77e0ff368d7d", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c6276074-770d-4609-983f-48d70e22f1a2", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9028f5416df8df0078ef77844fdca8d8b8e11ebd89bb49ec252bfe60cce2eabb", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "70a88b27-013f-479f-b346-c5064d447678", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "65e91ff86d44c7f7535d80f42c25b5abfe601773737cc89867d10e3a25c447de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Impor- tantly, incorporating cold items into SASRec does not degrade its performance on warm items. Content initialization even improves warm-item metrics compared to the original model on Amazon-M2 and Beauty datasets. Our proposed version with a trainable delta leads to substan- tial improvements in cold-item metrics across all three datasets, outperforming the content-based baseline. Warm-item and overall performance also show slight improvements, demonstrating the robustness of our method.", "mimetype": "text/plain", "start_char_idx": 434, "end_char_idx": 932, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bd6ba406-0e33-4804-ac5b-d803b83b7056": {"__data__": {"id_": "bd6ba406-0e33-4804-ac5b-d803b83b7056", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8496b7a0-8a46-41d8-9b48-77e0ff368d7d", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2d51d26604f39e90a05097c4f0c47ad107a4d59e9ee650277dcf71c59275c067", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "70a88b27-013f-479f-b346-c5064d447678", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "65e91ff86d44c7f7535d80f42c25b5abfe601773737cc89867d10e3a25c447de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Warm-item and overall performance also show slight improvements, demonstrating the robustness of our method. 4.2.2 Norm of the delta vector. The norm of the trainable delta vector is the main hyperparameter in our approach. Figure 3 shows how NDCG@10 for cold and all items changes with different values of\ud835\udeffmaxon the Amazon-M2 dataset.", "mimetype": "text/plain", "start_char_idx": 824, "end_char_idx": 1159, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5aa8a48e-ae16-45bd-a590-70eac1aff32a": {"__data__": {"id_": "5aa8a48e-ae16-45bd-a590-70eac1aff32a", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bd6ba406-0e33-4804-ac5b-d803b83b7056", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f7c70db9b2f0b831f223f30750ed2b672cc18dfc1f9f6130f6bdef3b9594a13e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "70a88b27-013f-479f-b346-c5064d447678", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "65e91ff86d44c7f7535d80f42c25b5abfe601773737cc89867d10e3a25c447de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The norm of the trainable delta vector is the main hyperparameter in our approach. Figure 3 shows how NDCG@10 for cold and all items changes with different values of\ud835\udeffmaxon the Amazon-M2 dataset. When \ud835\udeffmaxis too small, the model does not have enough flexibility to adjust item representa- tions, and the total quality drops significantly.", "mimetype": "text/plain", "start_char_idx": 965, "end_char_idx": 1302, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a0058833-5ffc-4def-a6a3-10f5b4b8e3d9": {"__data__": {"id_": "a0058833-5ffc-4def-a6a3-10f5b4b8e3d9", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5aa8a48e-ae16-45bd-a590-70eac1aff32a", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "acfb3999afa2549aec543739aa9ac348473777819a6ea6fd9ba1891c7f12db07", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "70a88b27-013f-479f-b346-c5064d447678", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "65e91ff86d44c7f7535d80f42c25b5abfe601773737cc89867d10e3a25c447de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "When \ud835\udeffmaxis too small, the model does not have enough flexibility to adjust item representa- tions, and the total quality drops significantly. When the value is too large, the embeddings move too far from their original initializa- tion, which leads to worse performance on cold items. We find that values in the range of 0.3 to 0.6 provide a good trade-off, giving the model enough capacity to learn while still keeping the embeddings close to their initialization.", "mimetype": "text/plain", "start_char_idx": 1160, "end_char_idx": 1626, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b1646404-4baa-4590-8141-d7b263da37c3": {"__data__": {"id_": "b1646404-4baa-4590-8141-d7b263da37c3", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "af6af039f529c9140d09609654c06352cc4e9b1c7a9d98dc9b0bd7918720dd8a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We find that values in the range of 0.3 to 0.6 provide a good trade-off, giving the model enough capacity to learn while still keeping the embeddings close to their initialization. 4.2.3 Cold items in input sequences. While the results in Table 2 are focused on cold items in the ground truth, Figure 4 shows how performance metrics change with the proportion of cold items inLet It Go?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 386, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d87ab588-a219-4943-b295-6d08dd265695": {"__data__": {"id_": "d87ab588-a219-4943-b295-6d08dd265695", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1646404-4baa-4590-8141-d7b263da37c3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "d5e5f6c880a1fcf536178a06a10263d297d7a18704d301771e2113ecfb502084", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "af6af039f529c9140d09609654c06352cc4e9b1c7a9d98dc9b0bd7918720dd8a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.2.3 Cold items in input sequences. While the results in Table 2 are focused on cold items in the ground truth, Figure 4 shows how performance metrics change with the proportion of cold items inLet It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization RecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Figure 3: Mean total (top) and cold (bottom) NDCG@10 for SASRec with trainable delta evaluated against \ud835\udeffmaxon the Amazon-M2 dataset.", "mimetype": "text/plain", "start_char_idx": 181, "end_char_idx": 679, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d63182ae-cbbc-48bc-bee4-84141e90a007": {"__data__": {"id_": "d63182ae-cbbc-48bc-bee4-84141e90a007", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d87ab588-a219-4943-b295-6d08dd265695", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "19f7f04824cb6d6f68253269c5bab701d467a743cc88dc92126a3db4f05bfe62", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "af6af039f529c9140d09609654c06352cc4e9b1c7a9d98dc9b0bd7918720dd8a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SASRec with content initialization is provided for comparison. Low \ud835\udeffmax values yield high cold-item metrics but degrade the model\u2019s overall quality. user input sequences on the Amazon-M2 dataset. Using content- based initialization significantly improves recommendation quality when cold items are presented in the sequence. Implementing a trainable delta leads to a further, though smaller, improvement in this setting.", "mimetype": "text/plain", "start_char_idx": 680, "end_char_idx": 1100, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b69109bd-c8b2-4edd-b897-8e87f4471990": {"__data__": {"id_": "b69109bd-c8b2-4edd-b897-8e87f4471990", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d63182ae-cbbc-48bc-bee4-84141e90a007", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f152eee4a53ecdca4ef5134ec695a1ba10d45d7339a434c52c30ccdd55fc93dd", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "af6af039f529c9140d09609654c06352cc4e9b1c7a9d98dc9b0bd7918720dd8a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "user input sequences on the Amazon-M2 dataset. Using content- based initialization significantly improves recommendation quality when cold items are presented in the sequence. Implementing a trainable delta leads to a further, though smaller, improvement in this setting. Figure 4: Mean NDCG@10 for SASRec, SASRec with content initialization, and SASRec with trainable delta, evaluated across different proportions of warm items in test input se- quences on Amazon-M2 dataset.", "mimetype": "text/plain", "start_char_idx": 829, "end_char_idx": 1305, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "887cb2e6-de01-4bb8-bc57-4d41ac5b0ba0": {"__data__": {"id_": "887cb2e6-de01-4bb8-bc57-4d41ac5b0ba0", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b69109bd-c8b2-4edd-b897-8e87f4471990", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b8dd67d84645e00478ab4d6e728d6f5b94cd86e01f0edebd011d0dc4a3a4240f", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "af6af039f529c9140d09609654c06352cc4e9b1c7a9d98dc9b0bd7918720dd8a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Figure 4: Mean NDCG@10 for SASRec, SASRec with content initialization, and SASRec with trainable delta, evaluated across different proportions of warm items in test input se- quences on Amazon-M2 dataset. 4.2.4 Low-frequency items. We further analyze how recommen- dation quality metrics for ground-truth items vary with their fre- quency in the training set, as shown in Figure 5.", "mimetype": "text/plain", "start_char_idx": 1101, "end_char_idx": 1482, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3e470344-905e-404c-be6f-00abe4d2b2b6": {"__data__": {"id_": "3e470344-905e-404c-be6f-00abe4d2b2b6", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "73b29e23-6efb-440b-858d-7846dd96e398", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3d336a2a0c7f290f7f7025c1c842744586786e7f64e766fa1da6be6953a5b0b4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.2.4 Low-frequency items. We further analyze how recommen- dation quality metrics for ground-truth items vary with their fre- quency in the training set, as shown in Figure 5. Our trainable delta approach demonstrates improvements for rare items, with perfor- mance gradually converging to SASRec levels as item frequency increases.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 333, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e465497f-d5ce-4507-97c9-54f6f97de1aa": {"__data__": {"id_": "e465497f-d5ce-4507-97c9-54f6f97de1aa", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3e470344-905e-404c-be6f-00abe4d2b2b6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "84d68506e8b949eb377bc80d0b9d43233365ba3f488b57292d269119efd3098e", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "73b29e23-6efb-440b-858d-7846dd96e398", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3d336a2a0c7f290f7f7025c1c842744586786e7f64e766fa1da6be6953a5b0b4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Our trainable delta approach demonstrates improvements for rare items, with perfor- mance gradually converging to SASRec levels as item frequency increases. 5 Conclusion In this work, we proposed a simple yet effective method for ad- dressing the cold start problem in sequential recommendations by adding a small trainable delta with a bounded norm to frozen Figure 5: Mean NDCG@10 (top) and NDCG@10 relative to SASRec (bottom) for SASRec, SASRec with content initial- ization, and SASRec with trainable delta, evaluated against the frequency of ground-truth items in the training set on Amazon-M2 dataset.", "mimetype": "text/plain", "start_char_idx": 177, "end_char_idx": 784, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "55ce4f5c-a49c-4a26-a4bc-8c8b6b707819": {"__data__": {"id_": "55ce4f5c-a49c-4a26-a4bc-8c8b6b707819", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e465497f-d5ce-4507-97c9-54f6f97de1aa", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "70b733d0b86b4ca6f8c17cf0a342fa5a459e26c5b0625b7e5c1e6b77d32a1c2a", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "73b29e23-6efb-440b-858d-7846dd96e398", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3d336a2a0c7f290f7f7025c1c842744586786e7f64e766fa1da6be6953a5b0b4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "content-based embeddings. We evaluated our approach on datasets with text-based and audio-based embeddings, confirming its appli- cability across different modalities of item content. Our key findings demonstrate that the performance on cold items in the ground truth shows significant improvement, while the metrics on warm items remain stable without degradation. Although the approach achieves superior quality metrics, it in- troduces additional training cost due to maintaining a second em- bedding vector for each item.", "mimetype": "text/plain", "start_char_idx": 785, "end_char_idx": 1310, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f1478900-5b0a-4bd4-9d85-abc424f26e07": {"__data__": {"id_": "f1478900-5b0a-4bd4-9d85-abc424f26e07", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "55ce4f5c-a49c-4a26-a4bc-8c8b6b707819", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "64de707c031178f2ba346b314235e570c01d887002c83203ea0e0242702b28fd", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "73b29e23-6efb-440b-858d-7846dd96e398", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "3d336a2a0c7f290f7f7025c1c842744586786e7f64e766fa1da6be6953a5b0b4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Although the approach achieves superior quality metrics, it in- troduces additional training cost due to maintaining a second em- bedding vector for each item. This memory overhead may limit scalability for extremely large item sets. Future work could address this issue by reducing the embedding size or extending our study to additional modalities and recommendation scenarios.", "mimetype": "text/plain", "start_char_idx": 1151, "end_char_idx": 1530, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b42e1405-b66a-479b-a50d-5bea7c67af17": {"__data__": {"id_": "b42e1405-b66a-479b-a50d-5bea7c67af17", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "d82c7612-c14c-464f-8df9-eb86619797d9", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9bfd7d9049c207c519041096ef30c2dfaee5b8d3b57e9660d962126e421d2343", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This memory overhead may limit scalability for extremely large item sets. Future work could address this issue by reducing the embedding size or extending our study to additional modalities and recommendation scenarios. References [1]Artun Boz, Wouter Zorgdrager, Zoe Kotti, Jesse Harte, Panos Louridas, Vassilios Karakoidas, Dietmar Jannach, and Marios Fragkoulis. 2025.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 371, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a1ea30e4-5351-450b-b44e-73c76ffd7ebe": {"__data__": {"id_": "a1ea30e4-5351-450b-b44e-73c76ffd7ebe", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b42e1405-b66a-479b-a50d-5bea7c67af17", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "8dbbe87db27ee1d29611ce04cad6cc302ffc46f708ae29567718fd7e3c801472", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "d82c7612-c14c-464f-8df9-eb86619797d9", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9bfd7d9049c207c519041096ef30c2dfaee5b8d3b57e9660d962126e421d2343", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2025. Improving sequential recommendations with llms. ACM Transactions on Recommender Systems (2025). doi:10.1145/3711667 [2]Shaked Brody and Shoval Lagziel. 2024. SimRec: Mitigating the cold- start problem in sequential recommendation by integrating item similarity. (2024).", "mimetype": "text/plain", "start_char_idx": 366, "end_char_idx": 641, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4187a558-80a6-4b38-816b-4cac854fa588": {"__data__": {"id_": "4187a558-80a6-4b38-816b-4cac854fa588", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a1ea30e4-5351-450b-b44e-73c76ffd7ebe", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "bc18898801ae76045bc342b5b7473fde8ec37bfdfd1cdce42c13154c203f0538", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "d82c7612-c14c-464f-8df9-eb86619797d9", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9bfd7d9049c207c519041096ef30c2dfaee5b8d3b57e9660d962126e421d2343", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2024. SimRec: Mitigating the cold- start problem in sequential recommendation by integrating item similarity. (2024). https://www.amazon.science/publications/simrec-mitigating-the-cold- start-problem-in-sequential-recommendation-by-integrating-item-similarity [3]Hao Chen, Zefan Wang, Feiran Huang, Xiao Huang, Yue Xu, Yishi Lin, Peng He, and Zhoujun Li.", "mimetype": "text/plain", "start_char_idx": 524, "end_char_idx": 878, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7023420d-97a2-4e64-a5bf-9f8439a64480": {"__data__": {"id_": "7023420d-97a2-4e64-a5bf-9f8439a64480", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4187a558-80a6-4b38-816b-4cac854fa588", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fc780f9a42cc7ccc39a65e288e51e25eb181afe389d8e725b449ce5f0cfec001", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "d82c7612-c14c-464f-8df9-eb86619797d9", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9bfd7d9049c207c519041096ef30c2dfaee5b8d3b57e9660d962126e421d2343", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2022. Generative adversarial framework for cold-start item recommendation. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval . 2565\u20132571. doi:10.1145/ 3477495.3531897 [4]Danil Gusak, Anna Volodkevich, Anton Klenitskiy, Alexey Vasilev, and Evgeny Frolov. 2025.", "mimetype": "text/plain", "start_char_idx": 879, "end_char_idx": 1203, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "17a841ee-8d41-49e6-83d7-7805e0dd04f0": {"__data__": {"id_": "17a841ee-8d41-49e6-83d7-7805e0dd04f0", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "627ef3fc-ccd5-4dc6-b333-7648af9b7bc1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e5b26d8c4ad886ff3599f2f92f0376f9525fd43af5cf246212305240e1062fcb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2025. Time to Split: Exploring Data Splitting Strategies for Offline Evalu- ation of Sequential Recommenders. In Proceedings of the 19th ACM Conference on Recommender Systems . doi:10.1145/3705328.3748164 [5]Jesse Harte, Wouter Zorgdrager, Panos Louridas, Asterios Katsifodimos, Diet- mar Jannach, and Marios Fragkoulis.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 320, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0d7eef55-7570-4adf-93e0-3d06c2e67332": {"__data__": {"id_": "0d7eef55-7570-4adf-93e0-3d06c2e67332", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "17a841ee-8d41-49e6-83d7-7805e0dd04f0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "1bb42d9b96fff4e6b765d873be5d0887a5cb92be6f13227ca3f70d1aba4b983f", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "627ef3fc-ccd5-4dc6-b333-7648af9b7bc1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e5b26d8c4ad886ff3599f2f92f0376f9525fd43af5cf246212305240e1062fcb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Leveraging large language models for sequential recommendation. In Proceedings of the 17th ACM Conference on Recommender Systems . 1096\u20131102. doi:10.1145/3604915.3610639 [6]Bal\u00e1zs Hidasi and \u00c1d\u00e1m Tibor Czapp. 2023. Widespread flaws in offline eval- uation of recommender systems.", "mimetype": "text/plain", "start_char_idx": 321, "end_char_idx": 606, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2f943d51-eb6d-4848-8089-c0a0e28601fa": {"__data__": {"id_": "2f943d51-eb6d-4848-8089-c0a0e28601fa", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0d7eef55-7570-4adf-93e0-3d06c2e67332", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e41569588369ca5c5d732eedc48f024b6580f331c2813911bd30248112a2aa70", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "627ef3fc-ccd5-4dc6-b333-7648af9b7bc1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e5b26d8c4ad886ff3599f2f92f0376f9525fd43af5cf246212305240e1062fcb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Widespread flaws in offline eval- uation of recommender systems. In Proceedings of the 17th acm conference on recommender systems . 848\u2013855. doi:10.1145/3604915.3608839 [7]Feiran Huang, Zefan Wang, Xiao Huang, Yufeng Qian, Zhetao Li, and Hao Chen. 2023. Aligning distillation for cold-start item recommendation.", "mimetype": "text/plain", "start_char_idx": 536, "end_char_idx": 853, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9acf4a38-5d34-4bca-a295-89c9a9090a4a": {"__data__": {"id_": "9acf4a38-5d34-4bca-a295-89c9a9090a4a", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2f943d51-eb6d-4848-8089-c0a0e28601fa", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7a16eafbc71ece1f7138a2f0d7d17ac8b0c73182a3b498502f25f509fdf0e253", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "627ef3fc-ccd5-4dc6-b333-7648af9b7bc1", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e5b26d8c4ad886ff3599f2f92f0376f9525fd43af5cf246212305240e1062fcb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Aligning distillation for cold-start item recommendation. In ProceedingsRecSys \u201925, September 22\u201326, 2025, Prague, Czech Republic Anton Pembek, Artem Fatkulin, Anton Klenitskiy, and Alexey Vasilev of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1147\u20131157.", "mimetype": "text/plain", "start_char_idx": 790, "end_char_idx": 1105, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "11773835-8293-4686-9553-d6da84a99592": {"__data__": {"id_": "11773835-8293-4686-9553-d6da84a99592", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b4ea218f-14e7-45ab-97c2-840461bf59e8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7dbe599cce9ff6f03ce602f4563b215d270848f16159b476e43ef3c1d263b666", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1147\u20131157. doi:10.1145/3539618.3591732 [8]Yitong Ji, Aixin Sun, Jie Zhang, and Chenliang Li. 2023. A critical study on data leakage in recommender system offline evaluation. ACM Transactions on Information Systems 41, 3 (2023), 1\u201327.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 233, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "30797ee6-2932-4473-80c3-2e8d1208e985": {"__data__": {"id_": "30797ee6-2932-4473-80c3-2e8d1208e985", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "11773835-8293-4686-9553-d6da84a99592", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "57fa85f703379fe6a2afcba4715e4c115cf383d3d93f315e26bbd58ce78718c6", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b4ea218f-14e7-45ab-97c2-840461bf59e8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7dbe599cce9ff6f03ce602f4563b215d270848f16159b476e43ef3c1d263b666", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. A critical study on data leakage in recommender system offline evaluation. ACM Transactions on Information Systems 41, 3 (2023), 1\u201327. doi:10.1145/3569930 [9]Wei Jin, Haitao Mao, Zheng Li, Haoming Jiang, Chen Luo, Hongzhi Wen, Haoyu Han, Hanqing Lu, Zhengyang Wang, Ruirui Li, et al .2023.", "mimetype": "text/plain", "start_char_idx": 93, "end_char_idx": 388, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0b57821d-7219-42b0-83c2-ff0325a4c990": {"__data__": {"id_": "0b57821d-7219-42b0-83c2-ff0325a4c990", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "30797ee6-2932-4473-80c3-2e8d1208e985", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b96e8ad274f55e96ea7cf2c06b6ee1130d43f2cfdd088f2f3fefd9383f189e6d", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b4ea218f-14e7-45ab-97c2-840461bf59e8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7dbe599cce9ff6f03ce602f4563b215d270848f16159b476e43ef3c1d263b666", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Amazon-m2: A multilingual multi-locale shopping session dataset for recommendation and text generation. Advances in Neural Information Processing Systems 36 (2023), 8006\u2013 8026. https://dl.acm.org/doi/10.5555/3666122.3666473 [10] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom- mendation.", "mimetype": "text/plain", "start_char_idx": 389, "end_char_idx": 703, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4ca57500-07b5-4caf-9a39-3f64fa046102": {"__data__": {"id_": "4ca57500-07b5-4caf-9a39-3f64fa046102", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b57821d-7219-42b0-83c2-ff0325a4c990", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9dc7ccdf7fc2ca07252549b08334a56f1fb1635de05d90f78ef4c1e3813a7cf4", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b4ea218f-14e7-45ab-97c2-840461bf59e8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7dbe599cce9ff6f03ce602f4563b215d270848f16159b476e43ef3c1d263b666", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2018. Self-attentive sequential recom- mendation. In 2018 IEEE international conference on data mining (ICDM) . IEEE, 197\u2013206. doi:10.1109/ICDM.2018.00035 [11] Anton Klenitskiy and Alexey Vasilev. 2023. Turning dross into gold loss: is bert4rec really better than sasrec?.", "mimetype": "text/plain", "start_char_idx": 654, "end_char_idx": 926, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c73260f9-0170-4dce-acbb-736406103253": {"__data__": {"id_": "c73260f9-0170-4dce-acbb-736406103253", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ca57500-07b5-4caf-9a39-3f64fa046102", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "97779e0670c47028e7ae63177feeeb8351c707636c98f39a9579e3c9b6742aab", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "b4ea218f-14e7-45ab-97c2-840461bf59e8", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "7dbe599cce9ff6f03ce602f4563b215d270848f16159b476e43ef3c1d263b666", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Turning dross into gold loss: is bert4rec really better than sasrec?. In Proceedings of the 17th ACM Conference on Recommender Systems . 1120\u20131125.", "mimetype": "text/plain", "start_char_idx": 851, "end_char_idx": 1004, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b666278d-7080-4b1b-9cd7-012832fb4da6": {"__data__": {"id_": "b666278d-7080-4b1b-9cd7-012832fb4da6", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "1acd86c1-984e-4c83-ac55-164400eade2b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "147f1ddce2154caed525cfd03a72f442abef5b49c4438ceeab06cb71cecbeb4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Turning dross into gold loss: is bert4rec really better than sasrec?. In Proceedings of the 17th ACM Conference on Recommender Systems . 1120\u20131125. doi:10.1145/3604915.3610644 [12] Anton Klenitskiy, Anna Volodkevich, Anton Pembek, and Alexey Vasilev. 2024. Does it look sequential?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 287, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d400e284-1968-4a56-b582-1a7ea915454b": {"__data__": {"id_": "d400e284-1968-4a56-b582-1a7ea915454b", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b666278d-7080-4b1b-9cd7-012832fb4da6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "49d9f1a26b52ea2c884a91f5057d1cacae0a289dea60f3bc6f1c8bd5067526da", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "1acd86c1-984e-4c83-ac55-164400eade2b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "147f1ddce2154caed525cfd03a72f442abef5b49c4438ceeab06cb71cecbeb4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2024. Does it look sequential? an analysis of datasets for evaluation of sequential recommendations. In Proceedings of the 18th ACM Conference on Recommender Systems . 1067\u20131072. doi:10.1145/3640457.3688195 [13] Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and Julian McAuley. 2023.", "mimetype": "text/plain", "start_char_idx": 257, "end_char_idx": 562, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "99e6e0f4-ae35-4739-b72a-d33e07a14980": {"__data__": {"id_": "99e6e0f4-ae35-4739-b72a-d33e07a14980", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d400e284-1968-4a56-b582-1a7ea915454b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "78e3ff07d9fb61e0257066b69047cc6306cda998f9302402d76c86966b235e6c", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "1acd86c1-984e-4c83-ac55-164400eade2b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "147f1ddce2154caed525cfd03a72f442abef5b49c4438ceeab06cb71cecbeb4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Text is all you need: Learning language representations for se- quential recommendation. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining . 1258\u20131267. doi:10.1145/3580305.3599519 [14] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes.", "mimetype": "text/plain", "start_char_idx": 557, "end_char_idx": 922, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5531d320-981a-45f3-8f77-66230ff82fa8": {"__data__": {"id_": "5531d320-981a-45f3-8f77-66230ff82fa8", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "99e6e0f4-ae35-4739-b72a-d33e07a14980", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "872b01a30a4cab9f42e950ac49f0bf9500eb827d308f62a36b1d889706dcc281", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "1acd86c1-984e-4c83-ac55-164400eade2b", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "147f1ddce2154caed525cfd03a72f442abef5b49c4438ceeab06cb71cecbeb4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2015. Image-based recommendations on styles and substitutes. In Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval . 43\u201352. doi:10.1145/2766462.2767755 [15] Walid Shalaby, Sejoon Oh, Amir Afsharinejad, Srijan Kumar, and Xiquan Cui. 2022.", "mimetype": "text/plain", "start_char_idx": 862, "end_char_idx": 1160, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3e836fb6-91d6-42df-b944-3da794785511": {"__data__": {"id_": "3e836fb6-91d6-42df-b944-3da794785511", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "32b0ab75-2189-4d14-9ca8-12078565de81", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b6428a7b8fb31512cdd87c0218f5cd5a464aa641a181f7efc957337e2f9d54be", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2022. M2TRec: Metadata-aware Multi-task Transformer for Large-scale and Cold-start free Session-based Recommendations. In Proceedings of the 16th ACM Conference on Recommender Systems . 573\u2013578.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 194, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8dad0787-2ae6-4bef-9005-66adcdc84994": {"__data__": {"id_": "8dad0787-2ae6-4bef-9005-66adcdc84994", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3e836fb6-91d6-42df-b944-3da794785511", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0c96dfee9fd7b0879a76b6fea0ba1a283a4736349854d329b0c0f5421739a7f2", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "32b0ab75-2189-4d14-9ca8-12078565de81", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b6428a7b8fb31512cdd87c0218f5cd5a464aa641a181f7efc957337e2f9d54be", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2022. M2TRec: Metadata-aware Multi-task Transformer for Large-scale and Cold-start free Session-based Recommendations. In Proceedings of the 16th ACM Conference on Recommender Systems . 573\u2013578. doi:10.1145/3523227.3551477 [16] Valeriy Shevchenko, Nikita Belousov, Alexey Vasilev, Vladimir Zholobov, Artyom Sosedka, Natalia Semenova, Anna Volodkevich, Andrey Savchenko, and Alexey Zaytsev.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 389, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8e804274-1d30-47bb-b4a5-8b0a89e03a62": {"__data__": {"id_": "8e804274-1d30-47bb-b4a5-8b0a89e03a62", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8dad0787-2ae6-4bef-9005-66adcdc84994", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "4793ad76330006c08f5b6ac8f4c806903980b47f064f4d18032ce140060fd257", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "32b0ab75-2189-4d14-9ca8-12078565de81", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b6428a7b8fb31512cdd87c0218f5cd5a464aa641a181f7efc957337e2f9d54be", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2024. From Variability to Stability: Advancing RecSys Benchmarking Practices. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Dis- covery and Data Mining (Barcelona, Spain) (KDD \u201924) . Association for Computing Machinery, New York, NY, USA, 5701\u20135712. doi:10.1145/3637528.3671655 [17] Aixin Sun. 2023.", "mimetype": "text/plain", "start_char_idx": 390, "end_char_idx": 705, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a771935f-a85c-494c-97d3-a661f287022e": {"__data__": {"id_": "a771935f-a85c-494c-97d3-a661f287022e", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8e804274-1d30-47bb-b4a5-8b0a89e03a62", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "06f2e614c62e3b05f0ede470493c551d01e1d279d078dc0b44baafa9f448cf5f", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "32b0ab75-2189-4d14-9ca8-12078565de81", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b6428a7b8fb31512cdd87c0218f5cd5a464aa641a181f7efc957337e2f9d54be", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Association for Computing Machinery, New York, NY, USA, 5701\u20135712. doi:10.1145/3637528.3671655 [17] Aixin Sun. 2023. Take a fresh look at recommender systems from an evaluation standpoint. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 2629\u20132638.", "mimetype": "text/plain", "start_char_idx": 589, "end_char_idx": 905, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6156d81a-4ba3-4105-8b9f-518ef11f9afa": {"__data__": {"id_": "6156d81a-4ba3-4105-8b9f-518ef11f9afa", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a771935f-a85c-494c-97d3-a661f287022e", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2ddf3151faf9f9d19c8e183c56bad576bf39bfad0302558bd6ffdc2c960778bf", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "32b0ab75-2189-4d14-9ca8-12078565de81", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b6428a7b8fb31512cdd87c0218f5cd5a464aa641a181f7efc957337e2f9d54be", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023. Take a fresh look at recommender systems from an evaluation standpoint. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval . 2629\u20132638. doi:10.1145/ 3539618.3591931 [18] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019.", "mimetype": "text/plain", "start_char_idx": 700, "end_char_idx": 1022, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "297b007f-5406-4c7f-8487-a28c962f0327": {"__data__": {"id_": "297b007f-5406-4c7f-8487-a28c962f0327", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6156d81a-4ba3-4105-8b9f-518ef11f9afa", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "9961abe15aa59be598a479ae35c0dcead208a986034c9bb439e21c1dff3ee175", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "32b0ab75-2189-4d14-9ca8-12078565de81", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "b6428a7b8fb31512cdd87c0218f5cd5a464aa641a181f7efc957337e2f9d54be", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "doi:10.1145/ 3539618.3591931 [18] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional en- coder representations from transformer. In Proceedings of the 28th ACM in- ternational conference on information and knowledge management .", "mimetype": "text/plain", "start_char_idx": 906, "end_char_idx": 1221, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8a744631-c44b-46a3-aac3-3eccf8b259f6": {"__data__": {"id_": "8a744631-c44b-46a3-aac3-3eccf8b259f6", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0d88ab7b7128b26976e596d77c23f1d96fa0d13016eb0c22b8ef7d72cdcf22d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2019. BERT4Rec: Sequential recommendation with bidirectional en- coder representations from transformer. In Proceedings of the 28th ACM in- ternational conference on information and knowledge management . 1441\u20131450. doi:10.1145/3357384.3357895 [19] Zhu Sun, Di Yu, Hui Fang, Jie Yang, Xinghua Qu, Jie Zhang, and Cong Geng. 2020.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 328, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0195271e-8992-41c3-a61b-4c63fbd03001": {"__data__": {"id_": "0195271e-8992-41c3-a61b-4c63fbd03001", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8a744631-c44b-46a3-aac3-3eccf8b259f6", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "e97877e8e5b390b529a8ab06385532b9de1dc5d0128bf30ce80b52a25e30c257", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0d88ab7b7128b26976e596d77c23f1d96fa0d13016eb0c22b8ef7d72cdcf22d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "doi:10.1145/3357384.3357895 [19] Zhu Sun, Di Yu, Hui Fang, Jie Yang, Xinghua Qu, Jie Zhang, and Cong Geng. 2020. Are we evaluating rigorously? benchmarking recommendation for reproducible evaluation and fair comparison. In Proceedings of the 14th ACM Conference on Recommender Systems . 23\u201332.", "mimetype": "text/plain", "start_char_idx": 216, "end_char_idx": 509, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ea125a9d-c4e2-45af-a637-1a75ee96d2ca": {"__data__": {"id_": "ea125a9d-c4e2-45af-a637-1a75ee96d2ca", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0195271e-8992-41c3-a61b-4c63fbd03001", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "f8f244fe8811316782bac254dfae84fee951481a6f5337e4f1e0c717285fbb37", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0d88ab7b7128b26976e596d77c23f1d96fa0d13016eb0c22b8ef7d72cdcf22d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2020. Are we evaluating rigorously? benchmarking recommendation for reproducible evaluation and fair comparison. In Proceedings of the 14th ACM Conference on Recommender Systems . 23\u201332. doi:10.1145/3383313.3412489 [20] Yan-Martin Tamm and Anna Aljanaki. 2024. Comparative Analysis of Pretrained Audio Representations in Music Recommender Systems.", "mimetype": "text/plain", "start_char_idx": 323, "end_char_idx": 670, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "33696f3a-b4ce-48c1-ae8e-080dfce4e3cf": {"__data__": {"id_": "33696f3a-b4ce-48c1-ae8e-080dfce4e3cf", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ea125a9d-c4e2-45af-a637-1a75ee96d2ca", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "c552b457987d45b12d5e42d80e7d0be20086b565c44400932481c5a423216a3a", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0d88ab7b7128b26976e596d77c23f1d96fa0d13016eb0c22b8ef7d72cdcf22d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "doi:10.1145/3383313.3412489 [20] Yan-Martin Tamm and Anna Aljanaki. 2024. Comparative Analysis of Pretrained Audio Representations in Music Recommender Systems. In Proceedings of the 18th ACM Conference on Recommender Systems . 934\u2013938.", "mimetype": "text/plain", "start_char_idx": 510, "end_char_idx": 746, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3e635e3b-99e8-4feb-b52b-b18aba01f8b3": {"__data__": {"id_": "3e635e3b-99e8-4feb-b52b-b18aba01f8b3", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "33696f3a-b4ce-48c1-ae8e-080dfce4e3cf", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "08283398a9be9dcdb013d07b0fd067f38b0d493d0672a1e7d00b764c1277958b", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0d88ab7b7128b26976e596d77c23f1d96fa0d13016eb0c22b8ef7d72cdcf22d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2024. Comparative Analysis of Pretrained Audio Representations in Music Recommender Systems. In Proceedings of the 18th ACM Conference on Recommender Systems . 934\u2013938. doi:10.1145/3640457.3688172 [21] Aaron Van den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep content-based music recommendation. Advances in neural information processing systems 26 (2013).", "mimetype": "text/plain", "start_char_idx": 578, "end_char_idx": 948, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9154054b-d97a-4a29-8150-47cc4cf374ab": {"__data__": {"id_": "9154054b-d97a-4a29-8150-47cc4cf374ab", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3e635e3b-99e8-4feb-b52b-b18aba01f8b3", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "45c97fba212dac8cc7e5d90a61a219feb0fee0dcdb1e107e42fedcc86e6fdd65", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0d88ab7b7128b26976e596d77c23f1d96fa0d13016eb0c22b8ef7d72cdcf22d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2013. Deep content-based music recommendation. Advances in neural information processing systems 26 (2013). https://dl.acm.org/doi/10.5555/2999792.2999907 [22] Alexey Vasilev, Anna Volodkevich, Denis Kulandin, Tatiana Bysheva, and Anton Klenitskiy. 2024. RePlay: a Recommendation Framework for Experimentation and Production Use.", "mimetype": "text/plain", "start_char_idx": 841, "end_char_idx": 1170, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dd2a5a00-5308-443c-867b-b9546f0db6e4": {"__data__": {"id_": "dd2a5a00-5308-443c-867b-b9546f0db6e4", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9154054b-d97a-4a29-8150-47cc4cf374ab", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "2a9a1a9129e95cf47e7cbf3f79ece724cfcdf960bffaae6912f5bb0182021089", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "141c92b1-0f36-4ebd-a1eb-169ede39eb38", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "0d88ab7b7128b26976e596d77c23f1d96fa0d13016eb0c22b8ef7d72cdcf22d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2024. RePlay: a Recommendation Framework for Experimentation and Production Use. In Proceedings of the 18th ACM Conference on Recommender Systems .", "mimetype": "text/plain", "start_char_idx": 1090, "end_char_idx": 1237, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7f8e0652-c27c-4561-8ab8-b898f10adaf4": {"__data__": {"id_": "7f8e0652-c27c-4561-8ab8-b898f10adaf4", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6366440f-4e3c-497d-972e-42a02ac199a7", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "00d2af1f45513c9313913cc14403d34eb0cde4285eb1ae1be7728ab1f92a01f7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2024. RePlay: a Recommendation Framework for Experimentation and Production Use. In Proceedings of the 18th ACM Conference on Recommender Systems . 1191\u20131194. doi:10.1145/3640457.3691701 [23] Maksims Volkovs, Guangwei Yu, and Tomi Poutanen. 2017. Dropoutnet: Ad- dressing cold start in recommender systems.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 306, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1c2e12c4-c6be-422f-b12c-46b753d6a1b0": {"__data__": {"id_": "1c2e12c4-c6be-422f-b12c-46b753d6a1b0", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7f8e0652-c27c-4561-8ab8-b898f10adaf4", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "54a2bf7e74e710c06198d975cbb9fa13f953ef8e613b1f1cd239368d71efaf97", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6366440f-4e3c-497d-972e-42a02ac199a7", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "00d2af1f45513c9313913cc14403d34eb0cde4285eb1ae1be7728ab1f92a01f7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2017. Dropoutnet: Ad- dressing cold start in recommender systems. Advances in neural information processing systems 30 (2017). https://dl.acm.org/doi/10.5555/3295222.3295249 [24] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. 2022.", "mimetype": "text/plain", "start_char_idx": 241, "end_char_idx": 534, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5b0449d7-0e10-45af-87da-d7fe1a5218cf": {"__data__": {"id_": "5b0449d7-0e10-45af-87da-d7fe1a5218cf", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1c2e12c4-c6be-422f-b12c-46b753d6a1b0", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "edbefc1349062fe3dcd15be9591c3af85965fab94deccd6e6d07bd9a556c22f9", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6366440f-4e3c-497d-972e-42a02ac199a7", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "00d2af1f45513c9313913cc14403d34eb0cde4285eb1ae1be7728ab1f92a01f7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2022. Text Embeddings by Weakly-Supervised Contrastive Pre-training. arXiv preprint  (2022). doi:10.48550/ arXiv.2212.03533 [25] Shiyu Wang, Hao Ding, Yupeng Gu, Sergul Aydore, Kousha Kalantari, and Branislav Kveton. 2024. Language-Model Prior Overcomes Cold-Start Items.", "mimetype": "text/plain", "start_char_idx": 529, "end_char_idx": 800, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4b4da0ab-e078-4eaa-bcf5-fe5eeb4fbf83": {"__data__": {"id_": "4b4da0ab-e078-4eaa-bcf5-fe5eeb4fbf83", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5b0449d7-0e10-45af-87da-d7fe1a5218cf", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "28026f500cd484ac6d52cd06526de0e4e51f5b2233162ba28f597863c373b757", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "6366440f-4e3c-497d-972e-42a02ac199a7", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "00d2af1f45513c9313913cc14403d34eb0cde4285eb1ae1be7728ab1f92a01f7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2024. Language-Model Prior Overcomes Cold-Start Items. arXiv preprint  (2024). doi:10.48550/arXiv.2411.09065 [26] Yinwei Wei, Xiang Wang, Qi Li, Liqiang Nie, Yan Li, Xuanping Li, and Tat-Seng Chua. 2021. Contrastive learning for cold-start recommendation.", "mimetype": "text/plain", "start_char_idx": 746, "end_char_idx": 1001, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "480ca554-3a44-4f15-8e9a-ce28ddce9817": {"__data__": {"id_": "480ca554-3a44-4f15-8e9a-ce28ddce9817", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "251a9d11-5ba7-4233-bf7a-46e9b4bd0325", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fb3d92b5d438b1777f4ceb068a810080f8da7c6fde0a1fa141f48389af4bbc41", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2021. Contrastive learning for cold-start recommendation. In Proceedings of the 29th ACM international conference on multimedia . 5382\u20135390. doi:10.1145/ 3474085.3475665 [27] Yongchun Zhu, Ruobing Xie, Fuzhen Zhuang, Kaikai Ge, Ying Sun, Xu Zhang, Leyu Lin, and Juan Cao. 2021.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 277, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1cf8f0db-ab6f-47cd-9406-0dd2f3071d2d": {"__data__": {"id_": "1cf8f0db-ab6f-47cd-9406-0dd2f3071d2d", "embedding": null, "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58", "node_type": "4", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "24b4f2e9adf7d95d5b8f005d5f010c9d630f7974850f0fcb7319bb47c0838109", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "480ca554-3a44-4f15-8e9a-ce28ddce9817", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "878ceae5e14f1cc76825885b9b6e75316b2e699aadebd3fd4246070d2a9ec466", "class_name": "RelatedNodeInfo"}, "4": {"node_id": "251a9d11-5ba7-4233-bf7a-46e9b4bd0325", "node_type": "1", "metadata": {"arxiv_id": "2507.19473v1", "title": "Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization", "authors": ["Anton Pembek", "Artem Fatkulin", "Anton Klenitskiy", "Alexey Vasilev"], "published_date": "2025-07-25", "categories": ["cs.IR"], "pdf_url": "https://arxiv.org/pdf/2507.19473v1.pdf", "browser_url": "https://arxiv.org/abs/2507.19473v1", "source": "arxiv", "definitions_count": 65, "has_definitions": true, "text_length": 31668, "abstract_length": 1000}, "hash": "fb3d92b5d438b1777f4ceb068a810080f8da7c6fde0a1fa141f48389af4bbc41", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2021. Learning to warm up cold item embeddings for cold- start recommendation with meta scaling and shifting networks. In Proceedingsof the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval . 1167\u20131176. doi:10.1145/3404835.", "mimetype": "text/plain", "start_char_idx": 272, "end_char_idx": 538, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"6f440d16-2431-41f4-877c-ad898350deae": {"doc_hash": "0126d6acaf8f7a518cf2ead60ea57f551c02d90ce37b0d397d7c817a0b8240dd", "ref_doc_id": "c4265ab6-05ed-4395-a546-5f1ee91f4f1a"}, "7003b41e-20e0-42ab-843e-a271be0e924f": {"doc_hash": "0126d6acaf8f7a518cf2ead60ea57f551c02d90ce37b0d397d7c817a0b8240dd", "ref_doc_id": "e48f2d73-47ba-4340-8c98-0d6111cb4385"}, "86e55fac-da13-4cc0-952b-b42d884098c6": {"doc_hash": "0126d6acaf8f7a518cf2ead60ea57f551c02d90ce37b0d397d7c817a0b8240dd", "ref_doc_id": "8abedc4c-dac1-4e56-8f97-49c469ebfabc"}, "0c2e4a27-aa8c-45f9-99ab-17147d2a04d8": {"doc_hash": "0126d6acaf8f7a518cf2ead60ea57f551c02d90ce37b0d397d7c817a0b8240dd", "ref_doc_id": "6de2692d-6f77-411b-9d34-4ff57a9f487f"}, "f7f2539c-b3e6-43ce-ac64-3384afb003d4": {"doc_hash": "ad9c95b2bb7e2b04b4508c3eeef35fd3f2e0f3999b4a304fdaa18a364474386b", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "2019d7ef-2e72-43a9-902c-84165d1deba7": {"doc_hash": "27d53e8003fd8011531982961e84ca24e6fdc9cb16d02f8b551ff8c7f879154a", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "e8617c0f-f6e5-4c98-bdf3-27fa71b2618f": {"doc_hash": "1d3c3086dea953f87ab6c82accbfe7343e3d40ef8848616fe24e249adbc439f2", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "9a342988-b3b6-4b39-8946-5338c3a2ed25": {"doc_hash": "3d70c586e6a719207e545fddacc46179eec6a296409def5cb99cf44c08f36d94", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "c417ce99-4fc9-4d11-9ec1-f4164c276b0f": {"doc_hash": "109ace0644510a427a56ebb6afe02e84c3549e453e5166d01ea5126380dd9c21", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "ebee8422-9689-4833-b9b3-0d286c8f8fe1": {"doc_hash": "569f7d93a1b1ed10c075d355906fa336bc08585b7faf1e8d7753f8655477e1df", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "5c4d6d39-20ca-4a8a-b995-5932eb940fb3": {"doc_hash": "089a7e15f8ebf90326892271b58b15215fbdb2a00aa73991ba52b66b17d7c84d", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "7cf1f99a-fee7-4a5d-a06a-8aad46a7244d": {"doc_hash": "b0f64c53674749bf09673fc7f345b64d2a9c3ba64c7671ba051e55378ade08a4", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "8c93bffe-d77e-429f-ad1a-420fec555002": {"doc_hash": "45651069b1befe7a2b4547a56f4506718f39cacb6dfced40e4d80fc7e52480b0", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "b36ee1e1-e379-42a4-8288-aed0bcd8176e": {"doc_hash": "b6b4fbfa4c7d34bc6e597f2164d029244c68016fbe75c2e33153b6470cd0aa19", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "279db839-6723-4de9-ab33-4981b1fd019a": {"doc_hash": "1af8969c1a3f803ae611b2fb84c82005459ccb7046a17ee12a902a0306c1b5c1", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "2c15ca1a-6ff8-4c3b-aa9f-64612f7628fb": {"doc_hash": "a26346e0207378b98b36cbf6798b1233424d0e1d438d9b9e681fd3f0192f9ac2", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "6ee032cc-ad33-4562-a00d-58f3706107c9": {"doc_hash": "f68444f933673b11cb7f356a096bed0f22c424d3a819f55162ff9efdf8fac18c", "ref_doc_id": "f0f40196-a659-466c-a28a-b6b64a25be2a"}, "3655e5af-c111-4716-97dd-083e09278ff0": {"doc_hash": "fa5b60eaa00c82cdb1ee03839bd21a585e91c054feb7f761aed2ca470676fee7", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "5787f5e6-7229-4a94-8af4-b8cce7de27a1": {"doc_hash": "56c3d35f496985c27fe5e61c9353214304ebcb1fe7035bbee3cb4358fbc3d2bd", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "0f4b023d-91fa-42ce-9d83-a43adb2beefb": {"doc_hash": "30440cdf420b76aa485f92603ee0dbbb8168f72b5367d5944e211af59145674d", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "4232ecb5-0f02-4c22-905d-17dfa3dab83c": {"doc_hash": "207a82cb8e210375b1a1c894619d017230eb2aec3665284ad44623a134a69edd", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "132dad29-60f0-4e9f-a1a6-16810e9ac804": {"doc_hash": "9cfda5f3fd76f7d268ab953c8c49b969e092dbb279b0c26a20b6e12cb58547b0", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "bb20f6c6-9134-47fa-bba7-c586c497b183": {"doc_hash": "0180498e3be0023141f76df60c99daae0ec7e37c93002c775f84f97140ac1853", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "6b162950-280a-48c2-b2e9-62de59c18016": {"doc_hash": "3a05c75d6b047cd2cf2656a78a5770f57748516c1f34c0d41520243720038388", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "a6bbdbaa-e091-4351-ac23-e38bbbc671fe": {"doc_hash": "dd3dbf448c71dc4406c1a9673664c4788b2ec10eabe95024ef6c2159d32092c1", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "ff5b4e40-acf6-4130-98f5-b0e1a580c413": {"doc_hash": "bd13ab658ecdb81ee75b5a91049eb577735378458b2f26799e3d7c5352d20f36", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "a3c125e6-af0b-4556-bac8-f4fcc93a3d65": {"doc_hash": "8df112faa9ae99afce5d1bc5da5763b56aa3e9e9c4b0b800c570732414ec794f", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "8aa6d737-eb01-421e-896c-5969cfb6601b": {"doc_hash": "85d35c7681df01be5011b77ebb3aed9df8d0ece589f2e3348cc7a595ca75ef7e", "ref_doc_id": "ce000b18-e86a-4418-8240-8b7779fb0411"}, "a01fa895-5f83-46af-9fc3-bbd26f899a45": {"doc_hash": "d4b2b0be90cea560fc5366830d8c8f3e59bff0bd1c2513d85886ec90f86beae8", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ba7060b2-c1c4-48c8-967f-acb5a5e228f5": {"doc_hash": "38ea6b49c1bc4cc5b37ecf5ddd1443f346af8396c9af8cf5c48163af04390af3", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "3ac06a99-d62a-4b14-8057-5ad071c9a8b2": {"doc_hash": "5b494e927064a8d15ad971603a6ab9cec2ca361819f5d5af8da5fa7b499fdabe", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "0b203616-3a2a-4b73-b264-44ae27413c5a": {"doc_hash": "41787e373179d7800531033b26bff64a7a89bded72b3506316d99c3b7d9d38b9", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "518bbff6-f700-466e-ae5e-151ca9c45c9a": {"doc_hash": "e5e58102d8e28b7e262191de99596748c0a564576d0d354712a97ae43d479c5d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f8949761-d7ef-452b-b6d0-0d1f4c571764": {"doc_hash": "98d994daf535408e3d99104325e3503b320f71b2a86dd2d06592422be072bc09", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "5815e249-b092-433f-be95-f8cbe0b3daab": {"doc_hash": "8b696f514b7a1d29ad8bf9f0d828a9584a96002f79c90366c28812018dea00d9", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "b1166cfc-d3a5-4815-acd0-2407106e63f1": {"doc_hash": "beb2cbd0557b911ff26c6db080858ea162abc3ee5f5d5b6f53f8c1b70c0d0807", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "5077d32d-8eb7-4a7e-b626-3736f5ea976e": {"doc_hash": "c96d5fdb583a0a6829c8b79ec59fc5f3244b3a3b6999ca7e1d7793a93c48e6d4", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f34686f8-a71e-48c8-b854-2e3d3c5f8ea8": {"doc_hash": "07a199dede03ee51c8f457ac0b0d1d0701896839c2e0bf5d17ecbb3db8e37f9f", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "a3c375a8-9dc5-4a67-b9af-514b1f764e59": {"doc_hash": "b416a75a95d5ab7a878a5a8c7be8fe94e99e47be3540518faa1a760f956ba5c0", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "2c71a4ba-fb61-4962-bc10-e322980ec04a": {"doc_hash": "2ad1b86c194950b028bc32b84461bc144370c0ca62e260bd70c3c237e9f2d2bc", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "8005f7a8-6a58-4018-b2d2-c43d4956a5a4": {"doc_hash": "37d20bb39b106ec0e6388a83b451491fa699d92274dcad9f660eecdba602b2cb", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "0718afa5-46ea-4eda-8c4d-a57fd276fa0f": {"doc_hash": "784d4395096f346efa94556ffb1cdac53ce54093ee212796ba6335d64356c0bc", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "5dfdb998-f423-445d-8bfc-a68a110eb2db": {"doc_hash": "07307918ff0274f9f1ad39885c8ed1c467898d130c1371c2971d84e051badeaf", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "b915ffc9-8d12-45df-9dcd-6789cf6d0126": {"doc_hash": "177a810379cfdaafcf26c2600f684a6a8c6792225add313bd88e4224cb1f12dd", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e96a93da-42b0-486f-921a-eaefd380df59": {"doc_hash": "5fb382dd16c9102c4ea40976da91321fd5fa47f3d09cc3cf36e01ccd12662480", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "22b58cc1-4f09-4bcd-ae98-ca507709fa3a": {"doc_hash": "ff49a9bb196c5d1311d2ed81a04c0ce6b4c6d000d6d33ba70e1b951d7ce81333", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "9ab2e3f1-f9ff-4080-915a-0444f695af0d": {"doc_hash": "560835adb11b2aff7cb97e3c4232f18b97fb48c7f3b196d7f4b7ffebf9fedb4f", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d85aba7a-36ad-4cc9-bb2b-570ce9a43fd5": {"doc_hash": "18f3a1f8e8c7ce753494ef62bc38cad38af6f71b21656ff71750140eb0e8572d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c66f7c50-d609-4182-af3b-864ded6b5b70": {"doc_hash": "853232996bd2020c22e2cfb1adf9568f6c90d0794dd3846a0e84db0b2b88bc47", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "eb5d3a53-a45e-4097-845b-a18ce54f9cec": {"doc_hash": "f294da9f278345a925ffb9e9116e04ba0344df9c84d710780b6af4c7c5d502ad", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c3852fdd-7c7c-4592-bf72-0a655646bec5": {"doc_hash": "7f477dae4ea6aca24b23eb488c928606ce2b7d75e653ec7af0bb06644a95a123", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "540c70b6-2abc-4c67-9556-0c10b87b742a": {"doc_hash": "7c29efe98bd8eed0c838f7055c5f6bf5efc8cbecbaf8715307e110c2ecccf296", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "a166db30-c2e0-4ee6-961d-c55174141f73": {"doc_hash": "58e7285059a3b17d10ee60b3daf3a0d0275f2038155bd4536679677e87be4872", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "2ba5b336-cde8-49ef-a2f5-c655bbf4b151": {"doc_hash": "a2a5d57ba34b250693698c7b9e2fff62e3262c0ca3b1ea267a58929db94062cf", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ad3be8a6-aac9-451d-8483-8b16fc4671ff": {"doc_hash": "c573696465a96adcc30831ce133319655835a555c85b0bdefdefe3be3dc5f5a9", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "11edbd09-dceb-4d7a-936d-c5b63e1320cb": {"doc_hash": "c4f2bf40801c732be905b4413f2e306b24e33e769f8b2c770ea70218e37119a6", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "4e3095c8-d7ca-4ee4-bd99-b42bd393be8f": {"doc_hash": "dc2f2b9c372f1d9b1dd4428e764f0e75e04ea2fce032313058b2889fae33d700", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "55f139d1-e089-4158-875f-be649f023996": {"doc_hash": "a63d187fbccb82a5b77faf9ae1991f5d018bd291b44490bbd745b5eb9c7b04ac", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "edf14a7e-432c-4aab-a664-7a0b40a5e13e": {"doc_hash": "80f477774ce4cecbea43218ca827ec15c3d2a96846b036fa5088306fde7ee2cb", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "56dc8265-cdb6-46d9-9ee5-d6c9dc798056": {"doc_hash": "d4231435026602d89e8547d74edaac91fbc146c6dfe2957ac8de672c8265489c", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "72e13c48-1857-4244-900f-9e7a1f7e6763": {"doc_hash": "217757993c6cd45d521fff52ce4bc2e2e0e27d8c4cd56ac1ef3a1868733b5d18", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "204c3fb6-154c-4508-9774-68fd1f274e01": {"doc_hash": "845332175e4a9ebb9ba3e5cd25ec8260f70ace153c6d84caa8bac70fd79c5708", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "65f85521-e243-4b44-842b-bfebfce7cc2a": {"doc_hash": "11ef898cc98f74311e8ec7289de4f166c00ffee9033d664455f4d63c0b18c12a", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f67a7758-7358-4539-828e-a06cc05e491d": {"doc_hash": "88a6d31aada36c458cc53d30aabaeabf08eb6485425eb1fbcc5ee51703e120b2", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d7d3a8d2-696e-44de-9b80-a9a04b798420": {"doc_hash": "2d451399d92c33fab9b1ba921255e5f0887a6a166de20fe6b2c5ab58118bf83d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "72ca9d2d-0c71-4ccb-bfe0-7db20c790544": {"doc_hash": "b00509312f845fd034ad685ece1960194f0b455bf2b33492166e187007d05ed1", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "57b31622-1557-422e-bbd7-e9e6ea16b735": {"doc_hash": "82682353a42c9b1cd18053fcd67eccf7355117921394fda5571fe241deb30e4e", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "1254c435-fbf0-4649-a7d6-f158fc8b1213": {"doc_hash": "9004dfa0055c47bd2ecdd199f71ddc30729ea61d2b65b3f24e73182f56fa69dd", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e75d4856-4cdb-4b2f-b492-784e59799624": {"doc_hash": "71e94518331b10bd16335e1d1de7cc6795f72e7cc7069a9ca321ba7505dc0dee", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "1560e316-0278-4e30-b751-ec24ef3deac7": {"doc_hash": "d7f7c4005ffd0f6aaa374187544e35ab808151f0706f0ab1bf3b47dfec64559c", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "05c7e783-1c8e-46fa-89b0-e577ecc3ba69": {"doc_hash": "3a87e5004e79c88ec51809b128c2da13810f66d0fc9b52487984f418c2771661", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "7e983058-8495-42d0-b7ea-72bbc288957b": {"doc_hash": "88585bcc47a0946cacd4a9d49feb38cb43c2fb0db2bdb517919771afe2421f21", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "b5edf441-b4e6-4d88-b1ab-b6be5e840ff2": {"doc_hash": "a9b5e6a1ce93832eb353d6dcc0ea7dd38730eb5b33272682e4fcdbdaa35429e9", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "5d8327e8-0269-48cc-82ba-d0a56cba74d6": {"doc_hash": "3e955686c68769fd03436f3fe35c51a0023f21acadd380b75bbda229de35f70e", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "b1972c46-76a6-4b05-ac48-9fa83e86489e": {"doc_hash": "46008471cc6d2c6645013c17323fe2a0e854843227ba898b8cdc0764ad8b78f6", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "6d937604-5db8-47cc-a662-2b0aa94f3a68": {"doc_hash": "a97c7ca115db38061667e879b012dcbff60dea9de266cede1194addc0809a0e9", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "fef62cd4-9e15-440e-b235-9327c4f3726d": {"doc_hash": "0106252a0accd07629ddba696a6b0c7ce0a549dc3f34317150fe2d700833fadd", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "cbf9cf49-855f-454b-822f-a0c688c91f33": {"doc_hash": "a2899245e4a5e6120a17f8b565c7db0f9cfc24d0e60429bfa618271ca59897e4", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ef0843ca-0e39-44c4-8f16-d294697f54e7": {"doc_hash": "dbe7a19709bc97ca3444b745a741f985f204914edf14ba82f154ee2c0a1d97f5", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "b2aa2894-fbb5-490f-9cc2-b42016adc155": {"doc_hash": "7cdcef9676e81ce22c12bbc06142e537cd49654f23e5e861fdcb8ac99420bcb4", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d8af5298-de5f-499a-9e8b-9df15181ae20": {"doc_hash": "050f3996c98d29413660fc6096cc5a8b1831ccc8cfa433375d0dfe9d560ac2b6", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ff9fe6e1-300e-4238-b879-c00fae44e746": {"doc_hash": "cf0c8b2aba191692ef12c0f793598c74969633e8bbbcfd7a6f7ed904cdca0093", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e8a717d8-1720-4376-956f-aed5bc62ae9c": {"doc_hash": "2461cfaaba0ba1e584775d3134efa93f9578b3d568090c17479f62e4dba1d450", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "887ef03b-8d4d-463f-a102-2c7f116ace6a": {"doc_hash": "24d168562093b0c7e632e5e969db0321afc9b48d61666e39fef836a235bba04a", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "cc5a5b22-3ae4-45ad-9cc9-f870fd194fe8": {"doc_hash": "f24a1665d6e163188791f06a80f446f5cb9c381118a7640713b7e8f97d99b1e9", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "5b2a83f0-a1cc-48ed-8191-6eb8d509bd8d": {"doc_hash": "72da7a9cb63c4562902c3e6f6d4c258942e33ff592f97800a16e41125e2a691f", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ef6402f4-f7a3-4388-956f-5735811f42b8": {"doc_hash": "1c86bbc3ed616cb02404ebf762e5f0306d70fb2423c17ccdbdd97017ecb45444", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "fef29f8b-d5d5-4f02-9fe9-9e0ac18bddaf": {"doc_hash": "65f6da5ccee4903767835c56af0259becea69cd792ce7e3d03328686a4cb8718", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e896a32e-f3b1-4a3d-9e7e-b44a246a9069": {"doc_hash": "848696887db688d5d1aba866355c3220832ece5bb83373203840fe0543866a85", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "6838372f-1425-4c57-aa9f-c3950828e2c8": {"doc_hash": "c3c6203dc10d5cf3a08c2133e5a7ad2d936b06ec9f90a47265cf16caa3487bde", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e2477c6f-c898-452f-966a-287b2097bd04": {"doc_hash": "285c0daf9e10bf8afa0212fa4bd3b7c177b9ef4134fa1dbf44f739426fdfec1c", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f7afb3af-75f4-40bf-9bf6-97c2be306db0": {"doc_hash": "e7a3f699d53e2a0812e4e50f0bac321aa5e95e53e72f3dc697b72bc934fd37d9", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "81a9dff0-d2c8-4e19-b34a-ea54ec89aff4": {"doc_hash": "5c8f562cb112c7a7c2ac6ff0cdc9fdaa37d1d8424bb1c983928a32c45ef25691", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "1342e88d-46cb-41fb-a360-5c984b7e4b07": {"doc_hash": "f760d83cc0de3944ac0291bf999949f50fac43ad8f7707b8c95bcd44d02cccdf", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "98c4dc26-0fbe-4670-b1b5-d9353b1b19f6": {"doc_hash": "6a831be6164f74e37d36c2bf049daf35a0bd9d8b5698e94720acdeebc6a5fff3", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "58e79da7-7039-4fe9-93c8-9a4d2119cd19": {"doc_hash": "0fe7affb86c9539f968f62c89d0e4570e5c7f8f1ec20afac8b9403cfa1199a5d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d67f47ce-3ca9-4035-95fd-50d76bc5d27a": {"doc_hash": "7bddf6a66d6a0ca8d9c810a13d39940d234c7187e2d661a0438752533d1916d3", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "5aefaae7-5438-4d76-aa50-cea746c00f8c": {"doc_hash": "7602e701bfea976f51cd3a4685779bbddfa9a609bd4344fc351b268f67154ac0", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "bb510eef-d5a7-4b09-9fc6-e91155bceef7": {"doc_hash": "4d1249f988f2a6feabfa6fcdf3a4c340324e06455b06f00c4eecd31e2f9c6703", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e939d74a-1846-4c73-8f6b-9fb5a08e23d5": {"doc_hash": "95e9b65360397e4f04539e3798d0a94aa16b66131bb61a1b44028de67ded15a1", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "a898fed2-472f-49f3-99ac-8fe6cc78117c": {"doc_hash": "c0d0f445b51d2b244d5983ceaa4442a146705099a136cf298d330c0bd9deda81", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "1793f7cf-183e-4a98-8174-074bc48152bf": {"doc_hash": "4302eb7b4f46afa655e984fcc19c14de51640b454acd854a6fe0755e905e083d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f9b28e53-7b26-4e01-8e4a-45beb13cc969": {"doc_hash": "5b1ae4190c5b104e241afb1eef21366fc5464940b2a25c611bfeacff6dde737d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "fe584ebf-1e0d-4439-980f-d6d31f5bfb96": {"doc_hash": "20bec196db9200fdae1edfaedcfd8b83e5cd91ee5a86fcfc409ab99e3d27702b", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "cff87716-9c31-4efa-977a-57da71ea9caf": {"doc_hash": "320b7f11931c142e12229f2b17ede321f04e4372edc0b82bdc3a4d82f564a8ad", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "82aece2a-57f3-40a3-b965-c1a79180d271": {"doc_hash": "61aa04ab490d2a2a75c93ba9c1e888b7779605621de177f27c1f7825b4883eb4", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c0daad12-ed76-45a9-b2ce-079e4927cd52": {"doc_hash": "8d9c5f52f71a3349b98c33fb285627526ff277dc3bf820d455b227d122d92a61", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d88747cc-f81d-4571-94b7-4d32f89e6187": {"doc_hash": "d18b1d06eca8d17779d5f94af75450a50c29fcfbaed01dd148313c6a8198a42c", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d1b99fcd-e0b6-4bc4-b874-e503548a1b2a": {"doc_hash": "b59826016d8059c456e86e1b4e9306c04fdabd279429f7b900ddec5c7a14f548", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "134ca2a5-6721-444f-8735-3fcbd4279912": {"doc_hash": "fc09ae50c94383a73719bf17a81164ef24e4ce58561f5eee6e715b46bd2b8901", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c067d04b-7966-4862-9d67-714264a9ba14": {"doc_hash": "3759bd2df07a1b30ed455b9847c38206d74ff135223a83cfab38be653631b356", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c6fc1767-9a71-474d-a95d-eec42bfdd67d": {"doc_hash": "fd5d0ecc3e2be40cb0c21727b32671cd102ced85b34141c30e20d3d0ab00de2c", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "a74a2647-c490-4d09-abaa-43f16952b578": {"doc_hash": "e2514ceff89c7565236632926d2f41a8b82469f86407d94f7f59f9918347e468", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "61f3dbfa-f6f5-4bfb-bcd4-767a0322452a": {"doc_hash": "dc396d3e9914987108b13dee75e566e3871d24f10cadf4e2a1ec4025e9741be5", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "659aa38f-8022-4a40-9cb2-48e544b37d93": {"doc_hash": "f8918d8a65cf861c781f393cca2f8e6853384ee1579d05ffe2d5395f9d756226", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "17410a37-262c-4bb4-ac80-3131cf1cefbe": {"doc_hash": "7912e3a51174466ad34fca7bc7d971b7e26fc71f9176392c202577529b4d4a9b", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "6fca940a-7f41-4c2d-a5d3-f69b3d1ed098": {"doc_hash": "4ef0f02cf03d44f88ee9604063141eb2887cb67464d86266c02b1b54f4268a1b", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "6fec6105-9b7d-470c-a6ce-36ceea0d2491": {"doc_hash": "6d9ae127194a230d8d54049069940d4b4cb88fc83c156fb1b0b6542904c3a02a", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "91c5d9fe-99e9-4d58-99df-b4bb9029619e": {"doc_hash": "e743f7d7f77f874c4b30600bdbf5f5d9751b98dc53e0aa6b9965529e139ec683", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "4c8596f3-16b6-4ab3-b9da-f34b710cd6e9": {"doc_hash": "a06f2d05afc3b9c1558d2fca7ea553d86c32f8155e1dcbd7ade1616f5c22eff7", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "10d56503-07e6-427f-ab7c-06fe148afc35": {"doc_hash": "ef09b5927e9f81b3b0228a322af71b61429f675e3047dd81292c8da94946a1e1", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "89bb33ac-a79e-44c8-8f66-e0df0fa73c3c": {"doc_hash": "706aa0113a569b4fa7495c07ad9beebc423d13d34dbf3907aa3a75dda02a7292", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "90b2626b-b05b-4bc3-b0ab-93d0759e23be": {"doc_hash": "a2f0ee1970db20ef327385b81af98a9b93e41394aad7b1d568e64baf9dd6eb05", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "07ed3ee9-c6a3-4b5c-98ca-b3d9014df619": {"doc_hash": "bd3c07df5ba12fad1895a14d0d449b4d5e95c01256d809cd8862196118f6df17", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "07b5a9e0-bf5e-4da4-9dcf-ba10e87175fb": {"doc_hash": "74aa8f80fcea66755391b63a3636ea8389703548cc67d220520d718a7f8d43d4", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "8fe56c3d-194d-4903-a3ac-371944c5bf77": {"doc_hash": "da5f903facc4399a3f66f641d6b15a8e64a5ce137505fc94e055be882409a2d2", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "0b09c21d-c881-40b8-b873-b0e20d7730d9": {"doc_hash": "1d93c15f4c4f1302e718b9b1d6553b156a8907a99ad3587a6f8883881cdb1c9d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "9d8d8f57-95d1-49c8-87e8-fe37cca7127e": {"doc_hash": "cfee8399ad9da97766d31f6b1ab225a1b1d4548077dd73e371437f5ef0bb6e1c", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "df241559-7c56-43f4-b0c2-7b44caf4371b": {"doc_hash": "0c782dab096661294adb7c3347c09230746a95d653ac40d99262317150c0c078", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "2179b319-ddfd-43e5-a6b6-67880b53a055": {"doc_hash": "7a6b602ba7a82f570a613564625894241257a81a4e05e5d033df2d59bcd9d8f1", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "0886f1ee-01f2-4054-a49d-a30f2462ed9f": {"doc_hash": "9566d7dddd39049c64f056d8d3bbd5d35e8c7b4555dfa093722f593ae7a1e758", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "2c8822af-79f7-435b-bac6-e77a454e835e": {"doc_hash": "d489bb7b068dce10457d62a3ce1e9e31eb195fe8f4b7510b465bab3e1bf98c21", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "9b243eda-64b3-4ebe-890e-e2cf7da7d4fb": {"doc_hash": "329067631e3a100553e8f64a525be75c8b54a99bde89421e71a60fe04f277927", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "807a94fc-2c07-4fa5-9b7c-f6a16d40b8e1": {"doc_hash": "465919f2cf792df49a306348b9f2c378e2f8207e934e1d7fb5b2172160210304", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "bf2a084c-54e7-4747-8e04-f4827636db70": {"doc_hash": "f670bd161eb1018554eee9fe3d10f1a060133502ff6377ac69d8d3a1a7e5705d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "fe5f80a4-4584-4cb4-a0f6-c5539025c6bd": {"doc_hash": "a06572821769489e26ac1a72360b364aed2ba6f1a943fcde6cbce7df1ca63852", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "b94fe5c1-8fa1-43b7-9893-b830fcfab3de": {"doc_hash": "f57d6f5d50d81df4a7f2b87d539a8130d77cc636c353b8bf633997674a52e073", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "4ac0b80f-b80e-489c-b8de-d9856894aa8c": {"doc_hash": "fb29a30fdad0798c871a02d52313455e0f1f7dae7e0efde87616cb03ed5329b7", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f1c38983-8d4e-43fd-ae0c-bf32163cd896": {"doc_hash": "2b3f66446ee92edb599001f0695059fd0c5953597a8e3d4658d1fd6c92844501", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "adf5011f-2293-4bd2-8a97-4b361b4bb6c3": {"doc_hash": "47dc8ee82c54ef3b0a8247a0a069edcc4ca1ca4ec79206de788ddf13816e2dd4", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "7999f46f-e821-46e3-b203-d074345239e1": {"doc_hash": "76e19c4da37fdaa03d76d5df1da0e82671b070d8cd96db9e0fad0630d054470e", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e7e6f438-3001-43e9-85ce-4c954cc42ad9": {"doc_hash": "a3ad1e2db78ab68ba53a2e46a763b91e2486972998070786976ac9e47bcd884d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "cafb6e9c-8ab2-4de0-97e0-52c4f5f873c3": {"doc_hash": "a69884160b8a4e1e3f902ef1f6a7b1a99747bf6fd01b6e855a07d141ad98a706", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "1566bd9d-d0bc-4db5-b348-ff0f2b1504cd": {"doc_hash": "f76b0e06d50649c830cbb28549f4420b467bcae5bd4fed82cdeba838b393d7f5", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c3ace333-fec2-436f-b687-5f84638c3bf9": {"doc_hash": "c9ec0ec041787624bfe2bc319d3ba0511da26f26520efa50ab55742236de2b5e", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "01506521-f1d3-4197-a64f-34c6dbe53b75": {"doc_hash": "b7ac296a9c99141c18cdafe221b393d966843c63e113fed586a42c6132aafd49", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "8db70806-7aec-4ea4-9ebe-a055a49be4cc": {"doc_hash": "3aaee5433d242a9bd1c0b1b2efaa8346b480cae9d2065e769b6100378b69dfbd", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "5c73fba3-4b69-4c3c-bffd-da0e146648d1": {"doc_hash": "bc3049180ebc452bb670850919bdff34d201b1dfec7f7cd5f67ea94245ebc314", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "51fe30d5-c30f-4e90-8ccd-170665aa548b": {"doc_hash": "01cee481fc8856183ea1c63014aba0df9d43a8e485a79869b9704f737d432e4f", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d88b291d-e7e2-472e-a1cd-d8528e7b87c4": {"doc_hash": "4869f06fb7545de902a8bf4fac4853abf8346d8e4a58b5bdb7ede26352cf007d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "1de52656-dd9a-45c2-80ea-b3a7aad79d8f": {"doc_hash": "b08f434d2ccb4826f5aa61b6d877450cc87ef615fcd6a6096c33560678c8a783", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "70e3e75a-5eef-4a6c-b798-fa0f3ce85172": {"doc_hash": "8edf4ec791fb8dae340f048fa04e56b196d0cee0a49c5a8878294eed66af95e3", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "dc04308a-3eea-4418-ae92-d30d753a0d0d": {"doc_hash": "072fd4c412171dccd92a7080e40aa0a431295dda90ce82fe7b8aacd74df713df", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "1fe3ce0b-d366-4501-987a-4bfdf3acf64c": {"doc_hash": "cf59bb514be68cdc8403bca111824778a85ca425add3e50a1e96d9e54bdbb616", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c11f5be5-32c5-44b8-b3aa-869d75bd0a34": {"doc_hash": "1732504c75d2e89c6a63fd7eecfcde6f9f65438f2121aacbb1b8e4a71c795137", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "7d49b8f5-ab44-472e-90f5-ac68db726b50": {"doc_hash": "ae53cc340f5b04779de9097aeceec9db0d8df756111b72c605212fd656e862ef", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "a50b5997-c789-484c-892b-ca34806fd4b4": {"doc_hash": "344952e3bdda8381faa241b8abe78372e679e6ed0ab0202ab6a8790a7a00b623", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "6c2e8972-8180-4956-8458-2f5e2a3ae9fe": {"doc_hash": "398f1bdfc35fc7e946eda88200bb53a2f7df42461ebaf9f55495624d756abc38", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "7ca6856e-1e79-4780-9597-b70d983ccc81": {"doc_hash": "08a133eeeafc3298ca67703a4e68cadb8994d4a0021a4cd8cffb5f9da377c859", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c8470257-32dc-40c2-84af-1ce80a7b2311": {"doc_hash": "b6cd1a5cc9134b140b424ab8864d2666a1f022b9eab1d69b16b4bc4a39dabf65", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "3bf34f78-400a-4357-817e-ccbd99fabf43": {"doc_hash": "b43f5a6555202ecd439ecc4769ffcb52e498f70de5f52cf04454f50c6f74e882", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f456e7c2-6ee0-4349-a699-3d591248fe77": {"doc_hash": "fe7dce4c82c92db2b4c899aa5dc4e52bf4cfbf38610cf2bb812522dc63bf32be", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "69f22d16-cb3b-4044-833d-88b59cc6c693": {"doc_hash": "6dd5ac04886f4ec7178998d732f6f40ce44c7f49fdaff487073119fd4554a503", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "1b42ec54-8165-4702-bbca-52099bdf3c4f": {"doc_hash": "c567f5520868e5e52181f941ab35f31fd76755ec3e50ca9cb4aa56086e786028", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ef7c8c26-2e41-4bb4-a26e-50570b057687": {"doc_hash": "b3a2b49599ebc1dd67a880215a2cde94f188fcb6bf59cd07b363b42e5313b350", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "0e246a18-28de-48c0-a966-d09a06822fd5": {"doc_hash": "df4947e4c0e869ec0c823250dff48d922b2f1ef6e760732fc78861eb6482f3cc", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "fc174872-b179-44c1-8143-c7e59c96be01": {"doc_hash": "30ccf887da0c1f3b5de1a2a2625aaf1ddf8def345f829217fa1ae599de667220", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f184f6e9-9f46-4a2d-a412-9b8e398f2b00": {"doc_hash": "311fc0d79647e772a29bc1bb99dc3fd82c97a94ecf8de28c470eed25ac1c08dc", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "dacb713e-5773-4425-bb40-0accaaa094be": {"doc_hash": "a36e946f168ef478535fee08a4f25f25699c51fa79f3377c347712d589532d6b", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "1cb9fe24-627d-40fa-8b2c-4d5734d2eee0": {"doc_hash": "c5cc40ef9618ea1a0a46f66aa6932e9eee95bb58bfd5899ebad65a092a60b1b1", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "4980577f-97d2-41ef-a27a-761f41225875": {"doc_hash": "4279e290d737cfe4b18946158d502b778d6ba1e2c4f260fd5433011934cd2be7", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "89ca1f59-64b8-4a3f-a0bd-1dc4c18b9c51": {"doc_hash": "41fc679506946fc87a1e8f4835a0341424cd798369d593b2d91fd9089fe54ead", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "7412b6d1-756e-41ee-91d3-0f62943e3d09": {"doc_hash": "385ddb3c55b75019dffe3e463103b6af41044b7788544f47110a9e14a1f81224", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ac94e726-9fc9-4598-866c-be5eeb8a19e8": {"doc_hash": "e9308492cbfe6f212d940e41b60ce80b8e17d40ddfdf284d56ad506772d48634", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "533b5dd0-38da-4d13-9304-7938b016c0da": {"doc_hash": "dbb0d6d89ee4e729975225680f12809757e437e80e978adfc5f89f2646221436", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e29b52c9-9060-40ab-adb4-31d7d30491a9": {"doc_hash": "7f4aadeb285c678ac97e21deb9d6fd104e5a085328a2740dc5ea0653a1c05779", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "10cb0e8f-2c50-402c-b7b4-0a46cd655ba2": {"doc_hash": "16431fb49f390031dd91addf2db7afd1084e732d6aa4fa14031af99fe96924b7", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "5e7c3a27-ab1d-4162-8c57-410c678dc6de": {"doc_hash": "154829653b3426410bb8bfab963dca38de848d981c105626032028109f0c9ee0", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f5128987-775b-480e-a9b5-7f162afd1132": {"doc_hash": "09b5c60d61affa0c604389f5e0d9a197e57184299befa4e29888a2d910a911b8", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "7bbd5992-de2a-4648-8c84-c9ee77eeee49": {"doc_hash": "ae5637882cb531a5c2a192da145a031a669d761e1af0fa9e18c20e7f8332882c", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "dc34b97a-ab03-4082-8cff-a6445520e426": {"doc_hash": "9b5cfb0f7b59af376295b224f650d4115be2be719f881df020dec3a4d3d237a0", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e27f06d3-38b6-4362-bd97-8436a55a2414": {"doc_hash": "eb2b8d1e2cccaf9b499f3fb21e56188b42a10c68ef66c140b50f29f618873f10", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "5ae7250c-3613-4177-bd2e-498eb743de05": {"doc_hash": "0ee30fd79e320b7ce524e074c6fb9871210decdb0fd5cefb7351fa4b90c7a196", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "b52683be-a1cd-40d4-861e-fd619d8b79f5": {"doc_hash": "635ff87d65c677a1e870eb353cb15e64b42f93fb36eddcfc3a40e4d0b6f4c03c", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f79e69c1-9bac-4083-92a2-1c0e6bf0ee3f": {"doc_hash": "084563a05de4dfce818f8b347700227f3555b6a8d4b41a04d3892a9bbd852ba3", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "4442f3a1-3dfb-449c-a15d-852e24414c41": {"doc_hash": "fd795100e47c9e1fdf6ed6461f1184614a6cb91f250c1cff807d9850d6f44344", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "02668298-18e8-44bb-93d7-19da4b9b3790": {"doc_hash": "2cf47d1570f311c6c9cf957e0503b077929d432287d72d307d0527a589a91b58", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "55b09120-0922-4df4-ad14-50ae22a2f0e2": {"doc_hash": "41a54f74576861dca5e950f0d44e49afb58e2b45f8cc0e6ca567ce406066b17d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "26e4455f-0d4e-488e-a544-9f5625380731": {"doc_hash": "12f63ac88ecfa22b79216a25de91833873e5285847839e845400bf3fb13c61e3", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "509b1e58-b476-4a27-9ded-777abf739514": {"doc_hash": "8d92fe0cb17363a4ff2981d50a95516c31f64eff934d149b64d0cd910f824c18", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "33348eb5-0677-4387-b789-c9ff60480007": {"doc_hash": "278c73d86977d7ff45c039e2682d77b3a7c0f3bd4cacfe8ecf79db2e909f4998", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ff062373-d901-443d-b8e2-7171d9d6fab4": {"doc_hash": "72311bf02e0b273738a72d109659b0e7e20a33a54409094bedc77585dab94cfa", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "3771e800-f5e0-468b-bf9e-66c996acd849": {"doc_hash": "2b06d5ad9765906d5e2fe1f2cbb0151ff063f9934cd2639c75fda14c0285b108", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "337584ff-0a73-48fb-98ef-48c0246e2518": {"doc_hash": "70ca8fc7e21f6b522bd78ef04e8cce3dd6dd8d8478100c5cd79d704b00d721dc", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "2f780ae3-b5b8-4fab-ba53-5bc0e811f981": {"doc_hash": "6d4d468312286f383cb9bb2b760650e992369909eb6883f91b1242946dd4dd83", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f77e394c-7c29-4b63-81dc-af15bd0e66f3": {"doc_hash": "54741d5fab46ef98582e4e1f6df3f00e171a62ad9636aae65f5dd088398033ee", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c4b2c7ef-1930-4255-acf6-bc1f652dafdc": {"doc_hash": "d868291feae115b660ae91e50e8d9f3662040802b29ec25093cdd30863d5466a", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "13883121-5801-4bbc-84bf-5d235841e0fa": {"doc_hash": "e4739bf349c8f15b2f29a5e4c40aed2af93ec9a8935f6ff7c60e5cade53b77fe", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "6fc6cc15-ff76-46c1-bbd1-3e9458afb757": {"doc_hash": "be0757c24a787f7af8e6fa7ed26a310474ae8b6f222ee8949359db99e49b9c64", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ac8c847f-de9b-4eab-a8f0-66c4cd60c4e3": {"doc_hash": "bd489127f9867208baf78bb89e80db70285657a8830a301d8a4dd9ef99c37da4", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "7877ca51-85bd-40d2-96f7-2e6f9f2383b1": {"doc_hash": "37fd3b18d520de90733f08e586e4924fed601efbfa041c1ce241151df3e72dbc", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "46ab98fc-8d19-47df-9741-ecb36253fde1": {"doc_hash": "2ba6ec8876c4724e8b5f5c974076e8de745bfff30b6eb9d9878b422cf46db1dc", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "6bda768b-04d6-42e0-a0e0-61b6c2846b7a": {"doc_hash": "9cbbd3ba49863f944fde707727a5cb2da34a1237e640690cec1b2f138845f44f", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ae37413a-987a-45f1-ac83-85e86906dc24": {"doc_hash": "3fd662ba08799ba002cc937138a36657456107f041f7ec028c2bdd6e256fac8d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "3cec132b-2354-471e-b143-28f66c24ffda": {"doc_hash": "75c225e75a24259d749e6142176fda0d4394eef730d81784dbe99f79a954a744", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "784e4f95-3d47-4c94-8bcb-b3ffc2b20b99": {"doc_hash": "ff91c39e2b45460d8fbf66b1824f64d0b3ebe50648a59657c219853e076d9bf6", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "78b4572e-8d75-486c-b0cc-d001f906f947": {"doc_hash": "90b8e2718a19633c4f0adab865be53a48d5539846e74e359cf9ff6678798664e", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "9a3e3c8f-fbba-4417-8877-018258745278": {"doc_hash": "3460cea35a97d7ff70265040e90fcb1967a68ff239e96209e47d334bb74ce79d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ab98e195-eb5e-4ed6-9a70-d344757e63bf": {"doc_hash": "c23544a7bbfd3f4fa66f306068fc41bc824daa7eb1da477b1e1b997c5851418b", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d85a4458-1a16-4407-ade7-3c2b5aa33bdb": {"doc_hash": "f3b3748cd6f5a4a95d3a4b059d6f923dcdf5a8a306f20ba7144ae6069121e9a8", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "7952f00d-bbc1-4a84-9017-c477ea9100bc": {"doc_hash": "2c8f82408db27fff3b89d70d8e92a6886bbcc9ddd0797acbdf9c58b2ed0b3cb3", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e4ed83f7-38fa-4f45-9736-8eca5668e997": {"doc_hash": "12b0c5c47ca7930497d7bc81501d92cd9cd5ecb011b7a588a56c29eb20c7ff05", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "b1d619cb-53e3-46f0-b0ad-a4372afa43d0": {"doc_hash": "e87db552aa3c00d18da8e651f62d6ecc9b6c2113689d9837b0313983a118a315", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "8916e982-5a90-4d15-969c-65e7f0e0a16c": {"doc_hash": "9af8f12a132b8cfab1fbfa27f71f3928d2244b41d87b45684dbd95c71e42646a", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "0ae4b470-79c3-4f69-bdac-bd5915ee5223": {"doc_hash": "adf0741da91f017e0db8f3bfc1ac31a374aea49905d522ee809872c898d75f60", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d638a830-8ac5-4174-82a7-be5eaf341ee4": {"doc_hash": "40f611349cc5a2b2dcfbb799ae220e5d096a6003c51187b943093d3e726082b5", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "8605bedc-51ff-4e99-b9f0-86888e23332d": {"doc_hash": "d7561bf25f60f3e0215954c87ae3d697fae5d916a600c02371cd7e8973028465", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f05a8110-c1e8-44c1-8148-cf387813423c": {"doc_hash": "606ef049b3024885bdcda6f6082378f230135987c44828b0f0b540fd4357f515", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e426f93a-2cdd-4643-a68e-aed3ac84197f": {"doc_hash": "d60fe540dcef365dd4b6b3faad5a63d4d6b862730ba5bc0d65990d05077fbcd3", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "39f03018-d143-4b90-96e0-1c72f0a252fd": {"doc_hash": "255ebe8040fbbd1ea13fa67861762cb6ef6f4139fb754f22ae71c7508e4e72d0", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d31452c3-fad9-4265-a515-982d866fe71f": {"doc_hash": "c4f77977b8c6c4009b5f1c62b156a676cf2b7f057e3b24449cbba71282121926", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c8a98fbf-eb5b-49cf-ae46-79e8fa49ad83": {"doc_hash": "ca33fd32899d53edce10bdb11568ce3291c8df7f1872774447af9f7af454033f", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "8275affe-d885-49c8-8008-fa2f9a85e949": {"doc_hash": "ee60257c612318fcee7104009d34a95edf2d7aa376203d22c77e2437fd7bbd5d", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "99e02a18-40e1-41b6-96cf-c723ea00d9eb": {"doc_hash": "71bc5177e5cad3dc74ef8a86ad9b32a249693d7d2057c43709ce853726414800", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "f5130f5e-b5f9-4e70-b3f0-9f2013d4e2af": {"doc_hash": "0889a45af90d76a21102c69d5a4409791e338249df03ca1f3cd536cb069cd0d1", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "2f705498-ca27-4f7c-9fd5-5f770ca72e64": {"doc_hash": "f9ddb9fb32792131665d0f5c3b164a39cf75e14c8579f98c9fafe0be67a8c595", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e66b0dee-d1fd-4330-9d19-def6628417b8": {"doc_hash": "2666ed26db78e7139b21064276888fd85b02ec991fc25d96eee71ca500957190", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "73c3b4ce-76eb-412d-a7a7-a138434ac2eb": {"doc_hash": "1c510ba1a73583a9cb9d601871e9917e920aa47b0d584e90af94bcf911c7d4b6", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "46c2615c-9ce0-4efa-96fa-3678f0edf050": {"doc_hash": "a63c55afeb17076dfc5687a30f55d5e2231ed1e71b8a886e458c405f8a5f4775", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "728835ac-2a2d-4994-87c0-9468e82f4dba": {"doc_hash": "0d63882e6890027fe35b42fa94ec1cf354b8e598a56ef7074c311bedfdbdbe63", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "139e6c95-59e4-4b78-9e3e-9549c1d0722b": {"doc_hash": "bbbfa80fc3bfc78a1ac1f655aea3b924c3660fb99077dd0049b601cbaf2a2232", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "fbe01bbb-ff31-4480-84cf-3dae7be082dd": {"doc_hash": "f24b5f8ec11af2db0fbf3dffa21ccc8644d9b299f81fe0be05f9cdb893595db0", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "c30e5b3e-2ae3-4737-8921-3f3ea68877f1": {"doc_hash": "3c4d144a0beaf48b5b1dc95e878285a97302fd436e6b8a07eba748b2ec4e150b", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "97678d71-ea37-4e77-bb46-cdcf6b3bef75": {"doc_hash": "8e1401f0af55539f76f76835af9027151a76ce0d8b209b2b9292cc0609441a9c", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "4901693c-df30-4c8c-ab43-417154ba1e05": {"doc_hash": "883b62d834138acbd1c5237aed518acba0682c1a2873d3791ea172db38ebff84", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "a8b484a1-2343-493a-9b2c-50c2ebb5ec4b": {"doc_hash": "3c489162ab7d8cc131ba10076d7b3aaf5008a1a242c981d9c422fbc380ba14b9", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "0f5b974e-f657-4360-8ea7-6bd11d43c8e6": {"doc_hash": "953061b39c9bd05ddddc4a623718e527241178725fbdedb3e4874c2a64bb9053", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "38717897-3269-43f2-973e-540622079d25": {"doc_hash": "920cc5158d3c70370ce74be9d64e929c031399a852380197bab462576bc6fc98", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e6e7ca7d-bacf-44d9-9ca9-5923dffdfe93": {"doc_hash": "ab6b15776ef20824f954c3875fdd31c877006c0b97dfb75f74695503d2130626", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "0d6eb3be-a4ef-43dc-ba46-72e04779a732": {"doc_hash": "6f5a9a6884351f52d4a356d0296e521bb2db8f39564095bbf5760e401810832f", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "22abeffe-1304-407e-beb1-44c3a9fd4fa7": {"doc_hash": "aef1d0c5cf4ce4bf016fe98b9725b4acbb5418b75b7fc231c10dbc8ad586501e", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "20c5ad66-47b2-4351-a2d0-b2c4042f2ff5": {"doc_hash": "d103bb3cc2dfbd7c5718291fe92f1ee51001da0ca61747aff99ae0a145fb95b8", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "78bc3360-41e9-4d3e-a816-7e5d7914eabf": {"doc_hash": "a9b15ff3df39d5a4ebc3ed88dc3c515d579fdc37bbf5b37d2ccc75d199a44ad0", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "0d804174-3b08-4fd1-ac1d-eac32cc650f9": {"doc_hash": "98922793a002173a7000d485e71b80ec5320574fc725d3c7685fcf05e871b2b6", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "2a85ef71-2638-4918-9650-1ab5cdff23c8": {"doc_hash": "03ad55206420417683976e307b34f1f80ef632549e3d73b55f118e61591d6a29", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "8b85f05c-56eb-43f6-8072-33bc9783a316": {"doc_hash": "c8c421f2da5b1b9e50cebf1574ffcafbd330ac915934f4c325bfd59c480dfff7", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "558be939-068f-4390-945a-28cef910cbff": {"doc_hash": "e74b038e422c63a9ab993d4f75a5bea5282fc76773bc3bde38684c1a8e9c96fb", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ffda4781-e364-49ad-9903-36dec832e44e": {"doc_hash": "faad75540705e85373749048a0acacd6d9d22dcb2f6a47da5ad5eae78cda1e52", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "b9741048-0bcf-49fa-b8ee-ce7f6cea6a81": {"doc_hash": "255a301d62445904dfd082fdcd76b396526f2661f93fa065de709bbf4d9d4ec8", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "810c43b0-cfca-4998-8584-bb70ee120696": {"doc_hash": "d3659466edd7781d3b4e658a62c1527b27d6e0a11c3bf7e1d0ae3adece83a632", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ff63f380-3595-4180-b636-5a380e924651": {"doc_hash": "99765d891c9ec938d43eee577131f684c93a35aa881a01d9a04eaeefe2172fcf", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "47e1d198-bb83-44b4-b265-a42a3583f23f": {"doc_hash": "9b33ee7cb6b18841a204a3227900278142f40a661bef11d8663d4866b760ff56", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "13814057-a813-48ef-88a5-4ac5616376c8": {"doc_hash": "6016a73760c520a1830b2045d4fbf5ff1ef296c103a3e28f552ca7ac9f72c2ee", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "18abf32b-3d18-4271-9924-c50acf8154a6": {"doc_hash": "67d7ec6dfb1686bd8106b0cd4846f6a2f2f11dc7ed80e3e3c1f404a5a020f564", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "7d8532ed-9156-4344-8487-a8afb326ea52": {"doc_hash": "13e59297068490eec5b7d6a0cf807723e0ee850a7ef5ee6865de40b7897fae20", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "ebafaaf0-1b03-42af-b797-ac464052d90d": {"doc_hash": "ec2e1038879d4716b726fb9429920678520c00031d930f44c3234e4aec51242b", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "e237093e-779e-4c5b-9b17-93a82b6575dd": {"doc_hash": "7df280f4507916d09a4a2cd1071443dc56147033be8e04d9938a015348965e19", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "9cddb9dd-5b78-4d09-9172-3fa43c4dcd17": {"doc_hash": "042cd932a9b9197528f48cd95eb6683b3fb4fc7c584ddfec2c06ba61993f2b7a", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "d3182eb9-b7ca-4419-aed0-c1ed4b717f6d": {"doc_hash": "e416c81da06629b0c4a8899ab84646281762460de08f17d443abd90b30e6caf2", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "b655faac-56fc-4430-99cc-da0a5388efc8": {"doc_hash": "7499ba23a7a024fa97ad4e7b4dff7cfda8b3186098323601abd8df77e013d922", "ref_doc_id": "080a2c8d-8a7b-4159-8258-e093b9765f96"}, "db249a26-87b5-4afb-a1b8-a2e030b78e56": {"doc_hash": "da1b67262e56212dc7898cf18384a8e39d2a44aab093b09755c2d194db34b6a4", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "cc630bfb-bac1-40b2-87e0-7d7500de63c5": {"doc_hash": "e23394951f43da04bad39e40cc42828cdbbc3e7c08b69f108b9bdd6089cfb972", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "9f2b5105-17d5-46b8-b73c-9b7672e026b3": {"doc_hash": "be03fd97b06563bae1fcd3d306b00940631e397d5610ee902bcbe9780c56fb3f", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "88e12252-5fec-46c2-a2ae-6fc241f89a76": {"doc_hash": "3c45b330891265bd1c9e1909b6d484581f392cc3811ecc7652b838e79a27e597", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "9f48d3e2-790f-4aa5-a828-7d17ffbcf4de": {"doc_hash": "0a542dabfdd965760e0127e10fa41fb6b4063da88447a1e3fea916c0308a56f9", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "bb7534db-e25f-428a-8778-6cb5b6f5ad95": {"doc_hash": "182a79fe6e1d1ccefc83937560c25883e0d17d9acabae970e400e7d733cef54d", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "6df56ab1-fcff-4ae7-901a-9a5f555b123d": {"doc_hash": "27a59c5ab4b6fccb1f670fb18b2f2d58a2b596690bad8c622cd94e7ddf6e7391", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "0b48d73f-7b7d-48ee-b07c-c7803a538edd": {"doc_hash": "70ff16738ffbbd01dd90d5a35e8594cc952353abfa683af4723e228df28f2daa", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "09ea78b1-c474-4d8a-9cc4-c9bec8a117bd": {"doc_hash": "7bae6336d1987ef51f49a27907b1e437c612369799e9f7b3b455b6736d26c6b1", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "79a71cc3-8aed-40ab-a5c7-d4f66a8c59b5": {"doc_hash": "eabe9e88a8098b712d8494defdf592fbe801549145734a040b04500c1f8fe038", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "2855e277-9266-4da9-a41b-62970f13924a": {"doc_hash": "8bdb1d78714f66ef76ff3ffa7aa204566a0b14bcd9316c73cae4ede09ad93ff0", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "8401cdeb-6662-48aa-beae-b4bb5f06a885": {"doc_hash": "a4eabc3b1d8f7a3cd2161e90d0b9cc8e5554df1bd0f7f85b785d34398c25e8f4", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "14effdc0-fe79-40b8-ae47-1d97a86b2018": {"doc_hash": "1555fb3485e63369c352170c1a78d9a1972547e9d5cf674e4d25256875b186b5", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "9322dd63-adad-4546-91dc-b82fb1ea8fef": {"doc_hash": "d8666d1ca684ce64d01b3b7d84146221fa392c41b3c46f6815df71d0f248f8d5", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "76a288f9-53f4-4e84-8d97-b368d41bd698": {"doc_hash": "fecc2d7f7bae84392dde2ed06f90ae3f4ea884408d835ed41dfc00d26adbcfda", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "a513b767-e451-410c-b79a-380601bc5888": {"doc_hash": "9ca3fba71bd2a59a702b158eb82f6cf7e3b844f68c71ea9a1ef1ea16679defa5", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "9eaef3ff-f04f-444b-bb7f-84ada902b046": {"doc_hash": "cbfbb5c20011f3c74a4b3573d4f57738733679de7abeac24c76cbe88ad8dff4a", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "c7de7c6c-59fb-4f27-89fa-9799eb07a0dc": {"doc_hash": "0c8d4ec34b9da587f0a636d365250ca9f6aea0e2db0f31a78f1ac36bbcb254cb", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "70a88b27-013f-479f-b346-c5064d447678": {"doc_hash": "65e91ff86d44c7f7535d80f42c25b5abfe601773737cc89867d10e3a25c447de", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "5d5bbca1-6297-479e-814e-ffbb3f9f8d3b": {"doc_hash": "af6af039f529c9140d09609654c06352cc4e9b1c7a9d98dc9b0bd7918720dd8a", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "73b29e23-6efb-440b-858d-7846dd96e398": {"doc_hash": "3d336a2a0c7f290f7f7025c1c842744586786e7f64e766fa1da6be6953a5b0b4", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "d82c7612-c14c-464f-8df9-eb86619797d9": {"doc_hash": "9bfd7d9049c207c519041096ef30c2dfaee5b8d3b57e9660d962126e421d2343", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "627ef3fc-ccd5-4dc6-b333-7648af9b7bc1": {"doc_hash": "e5b26d8c4ad886ff3599f2f92f0376f9525fd43af5cf246212305240e1062fcb", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "b4ea218f-14e7-45ab-97c2-840461bf59e8": {"doc_hash": "7dbe599cce9ff6f03ce602f4563b215d270848f16159b476e43ef3c1d263b666", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "1acd86c1-984e-4c83-ac55-164400eade2b": {"doc_hash": "147f1ddce2154caed525cfd03a72f442abef5b49c4438ceeab06cb71cecbeb4f", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "32b0ab75-2189-4d14-9ca8-12078565de81": {"doc_hash": "b6428a7b8fb31512cdd87c0218f5cd5a464aa641a181f7efc957337e2f9d54be", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "141c92b1-0f36-4ebd-a1eb-169ede39eb38": {"doc_hash": "0d88ab7b7128b26976e596d77c23f1d96fa0d13016eb0c22b8ef7d72cdcf22d6", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "6366440f-4e3c-497d-972e-42a02ac199a7": {"doc_hash": "00d2af1f45513c9313913cc14403d34eb0cde4285eb1ae1be7728ab1f92a01f7", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "251a9d11-5ba7-4233-bf7a-46e9b4bd0325": {"doc_hash": "fb3d92b5d438b1777f4ceb068a810080f8da7c6fde0a1fa141f48389af4bbc41", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "e98eac31-9c3c-4ebe-8f13-59e55f710d10": {"doc_hash": "f34842178f284bdd920033e777bcda703f4cd37a34082567e3150b5c077befc6", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "fdb2e7f0-24e9-407c-8cf9-52243751ad4e": {"doc_hash": "9dc6a5ef52b10ef673ab42ce5e97a94791a1135fa84ca885eb1b79fe2094c4a4", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "2db9fece-00a1-4a6f-aaae-6a4933998147": {"doc_hash": "13a21813d82dc486e7c0ee215dfecd29f9f0a549e788f2ae9061aa0a48389918", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "66256c0e-8c94-488e-bf00-1da903703df0": {"doc_hash": "d7efc71e85a5778ebe99274f15d1e05edd6d5ead0060bd2c46b8293d29c1f7fd", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "e90dcff2-5517-43c2-a6a1-4ba1d21a4656": {"doc_hash": "7a4150933be90ff626d64b09d5a374adcb73b4cf32a9c4610679454308bd19b8", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "5693045b-afdf-4a0e-9505-33be4be69a3c": {"doc_hash": "53962d918b9957069a37b7c12bc31a8f625a5d35910391741bbd54421ce251fb", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "44085962-76ba-48da-90ee-697d9e7fc54a": {"doc_hash": "7b65151044a25a45a31fec966f520a5193b9bb9c7c97766790de90d0df53ed6d", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "2673e9dd-96d1-42f5-903c-bf289afc91a0": {"doc_hash": "a8545f7587481306e9b7875dcf76a5c981492d1982935aa4dabe94b797f26069", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "36f1afb1-b558-4531-9cdc-616558dcfaee": {"doc_hash": "7d0ff482cd40868ad8e6e23b26d466ca66e6df463c0bf4ef715c4bf09ad2b5b2", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "65eb96c0-affd-4497-9c15-0272053042e2": {"doc_hash": "a0c5362b364f623992cfbf4d6d56328b46fbd38bea3c9816f16a913bb9446e01", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "a1ca29c1-9e8d-484b-9415-dc3107357580": {"doc_hash": "e0f789e5bf63f30e28fdbf773c82c0604ac57b968ba27cfa9206c5e2b8022b80", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "e4dc984c-e3f2-4923-8645-5fcb9ab3e78e": {"doc_hash": "ca0c9799c503ef3a576738f3e98d032f3f7fabf9cb4442700e8ea372104afb5b", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "017ffcb0-64fd-4717-bfb4-dd0029d24a77": {"doc_hash": "5eb2fc09204437e3243291e8f0c784262d796f5b89fb084d9fe27f62b19ab29b", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "a0c428d4-9bdb-4837-84c4-0e4d1cc8c134": {"doc_hash": "5f6e38c07e38a72700d4ea31a88b1302cfa1ad2971b251ea5632f7ed1de43ef5", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "d938c1e9-40cf-4541-8f86-471f4f006481": {"doc_hash": "f14a5bdd381426bad4c2bf89470a62a80e0dc30f7a5ec6292b590c0249adb74a", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "5da3506c-fac9-4eb3-8288-0998c9026a57": {"doc_hash": "cf350e0c353f824820a4a3c35582a8ad22a95a8643f3fc364061cab41840aa56", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "1a93036f-9a6b-49b8-8e4e-85375e507a10": {"doc_hash": "d72155e07806e9b90f69aa4bb498e949e5ca532777e36531e4221023644b327b", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "f19243eb-b1ce-4903-b5a3-284412d9e872": {"doc_hash": "b0487fd24c9a076fac8e18d91c1b5eb693862f2ec51089b1c4326152fd205843", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "e7cfb727-258a-4e21-a9c5-0e0ae4195c18": {"doc_hash": "7d32e9a6328056239144240738c92be7248efc7b1ca877c10679b8008d51a742", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "18d5406c-5efd-4928-845a-25db3d586722": {"doc_hash": "b11ba17f02f2292eba8caebcbce0f361c1a343555f9b0a73f44d726ea18eed87", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "257f60ef-b0ad-4fbc-b605-6d181656a11a": {"doc_hash": "c5f787edb48a1e092ccda6b81b121e3d3737123d0a5a3fcb5dacf285cb356b7e", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "f4e57e09-98a3-45cf-9ebf-1c9897d4370b": {"doc_hash": "c25f1588b35d7b6176847d8febb6ba8596142925ac5270864fb90f5f63e2f671", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "55086b99-4947-4d9e-abb2-c96ba69ff0dd": {"doc_hash": "32acf87fb3a2ea01265c8216462d625fc322f3799d5faad711d84b5cf3f7f282", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "ebf6015f-27fd-481d-aa92-de46f7f861e3": {"doc_hash": "5e5ab5a987127a36b1b61a30d9db274b07eea9f16c9a0daea84dac8349b9b3fb", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "267f4c36-c2e6-42f9-8915-8ea6c18fed83": {"doc_hash": "f795d843d7a4446c19653a685a3ee875e1d7390abaeb7c0c078c3251ca2cc5b0", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "93c2b70a-135f-496e-b14e-45caa053bf73": {"doc_hash": "0f6809cad0cde45bce850bf264cf5ec0ef362b9a8ec9d39f5bde4ec8075485e1", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "67e94527-9263-4837-b131-a4799f7e51e9": {"doc_hash": "86ed56cacbf29ddefeca2dddd26d291df167d2eebc0769fd4134de20fec7801c", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "62923145-ce3a-40a8-b0c4-c499785f29a6": {"doc_hash": "ba6c7e4c0a01a5a846b05685f0665c677fc598ca9ea3cb44f462cfa94ebb114c", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "00cd7f5b-7518-4ade-81a2-63ab6f97aabc": {"doc_hash": "c1a7f67a675ec23774eaaafd81ca9bc45a3f0efeccde7c14376c5a854cb80a15", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "8038baa3-f888-4c86-9e5d-fb963c4ce5fd": {"doc_hash": "39561cc1e96e90d208a390cce7e3c7ab73e38d442eb198f038daeb6557b19058", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "61c8cea0-fafd-48a7-874d-f597795d15a8": {"doc_hash": "ffa99881c794af4692b8d9baf290df6737456bbdd1cc6088b39252cb903fb9ff", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "d5781ced-bcdf-46e5-8e63-877991d14207": {"doc_hash": "f31ac9efce8a11cd661fe95d564199e7dffb03837840ffe529ae806b97a78ba9", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "8af3a283-7382-4582-b416-6d0cef2edfa6": {"doc_hash": "af3396c87ecbef865995780da59f9d6acca3abd50f2a13a3f552ff4c9fc9217e", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "51918c55-025f-4906-bfb0-b0bfe491171c": {"doc_hash": "9a65f83ee7729c45b763576f3c1ea5d836e8fd51851e8f7c55a1ebba3a41b30c", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "870c0c78-3dc0-438e-a7c3-01243e73e58a": {"doc_hash": "3f35109a7c6ef6a3911023feec680d8ede1395f8fdf50d458abaaa356cd3ba6c", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "d8d747b8-d81a-419d-8083-7f8523d53feb": {"doc_hash": "01eb4db1289b82aebbce2640b6a9fc945fba513b9084ef646ff8dc649090736b", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "a8f1e88e-ff95-496f-81d6-17e468412c91": {"doc_hash": "660345f2eb69f9736b9620342ca1b721f04b20d76f854085f0ec4031bb49a45f", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "2b0058fc-1a45-474e-9544-ec4e9faae58c": {"doc_hash": "cd5f4e366a8c72394a60e1a74dd2e24af671ec8e09376e5b4639ae497bfc4090", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "96bdd5d3-a773-482d-a30d-06d7d77395aa": {"doc_hash": "02ca7df05dbcc6c428e2fc8f881f9f2f9db81a6bd698644e40af4d7bb7213509", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "ef94c2bc-3eb7-4146-85bc-5713adff1302": {"doc_hash": "d86af8e6ce1f5faf07f3c5cec10461c9f641984d3759cec799f4cf4421fb82c3", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "c05bca4c-5716-479f-9d85-6b9593fd13d8": {"doc_hash": "ebec9844273c29158cc58ad39cd18c573cfe030e9b38e87c9cffdc34c79be059", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "d3739567-9d85-4d3e-b562-9b18a0fe7718": {"doc_hash": "132d6970ade9590cadee98bd5339da2e134c0d53587626457248733b0c0daa2d", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "81b11a8d-9cd6-4b83-9dfd-d06fb630e5f3": {"doc_hash": "23c4e5efd02464a681340b480cfd74d6652caea60ecb0ade4ad34872adfd98af", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "47a07172-514d-4d6d-8d70-98c529ca03e7": {"doc_hash": "a83f4daec7f6c2ec04aa1243892fa4ac23407e7e633d58cdf6c98b82d3b36d34", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "49f949a8-0735-49af-870e-1ffde8de81c9": {"doc_hash": "a00bdb373f810b6c0b87550968f34a9312c9d6cc66e1a1985550e45a2af0dfb4", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "eedc9a90-b5d5-4912-9092-9d2490f79c24": {"doc_hash": "45b27161a44c9c16ff3bc8e4d0717baed81fb3dd9320fc94fe39a8b61da82dcb", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "7ab2825a-5f7c-4550-afe8-901081e154f6": {"doc_hash": "f60a1a0e28e6aa2624538a25745a41dcc55afcfeae19b167bb5a31f08fc12c7d", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "62c5299b-1bf0-4bf1-8c51-116c95825420": {"doc_hash": "342b0766cc37e05eb36d70d9f6fb4dcc134c081858945e8e5aa39b5b08540fa3", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "164847cd-f3fe-4ff4-a218-4c3272542352": {"doc_hash": "6ecbddfac184f530ef487d689a20d6dda7e19156b160906c84d5997772fe9749", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "7171672f-3d76-4671-b19a-0d002c808b11": {"doc_hash": "64a09a0aad6ba54aa74a453b28c713eda635fb4408a9140cd5afcdc9021bc5e5", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "07364ea6-e560-49e5-8f36-3d64a72d9f38": {"doc_hash": "597994176b73dabbb2fe9ebecf6e9ccdf290380fa2803e749763ac4f71d3306c", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "36cbc85e-6884-415e-8239-c4ad7ac472e1": {"doc_hash": "63309ba7ca7e8fafcddf5b12e8d279a4ef2a0691bb5c2a5b567985b2983a029b", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "04c2eed4-7b4c-46e4-a197-0a22bf5357eb": {"doc_hash": "dbe8d893a3e2e035d53491a12a4535036a150a9c6c3725a94e54f261a94947cf", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "71aa0155-3650-424b-80d3-d39b8c47f0f5": {"doc_hash": "2fe70c984e2d68ca5fac9c50a61d0f3fee7e0dbe74915a9dc190dbf9eacdcf01", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "e66d8f48-4744-4c7c-af37-f336f2106dc0": {"doc_hash": "d6069d2b3bee92f31f900be64f8f78089a8f37519c939a9c412e5aaab31fba7a", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "271872ae-f2e5-43c7-9ede-e4a01d149ada": {"doc_hash": "a7695702a51dcaf44547957d5ad937d95448b12de0e0cb24d142861ae1b17fe6", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "3d234c0b-4bc1-4565-8944-328cf3c2c90e": {"doc_hash": "bac9b358bd997f4bc5fdfa8469d46c9ba0ab1c0aa277ba4d4f4a981afe4941c2", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "67614e3e-03e1-4acb-adaf-edb0c6b8f21b": {"doc_hash": "f93705b4d4131ffabbb10171576dbdc7eb3bf10b63422bd2d68ae4ffcf1412ae", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "217fb68d-c222-405e-9cc5-530acc1d60cb": {"doc_hash": "85861688a31acf390eb7266bfaa533e3c5a0ec6070920d1339a9355d6c6ac52f", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "4b6e2f0c-cd70-401d-9c38-e4dd4a510006": {"doc_hash": "182e6447cec68b2b3157f167c876a96b8b5869d4fbd66aee4f5d71592c27f647", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "03872e73-1622-4624-9157-0cf489f0e13d": {"doc_hash": "5e5414423b0e95f87d85f0fc3e135f82a559d6f65907985c481d1a287a1cf4b6", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "cd528d2d-349b-4636-951e-7c63480b6a20": {"doc_hash": "ed63c946c35bec0fe5292ffacca6469a7b5ef2f06f1566450360fb6fc594ad31", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "a44a846e-1368-4dcf-b24e-cb249e06d290": {"doc_hash": "3c608367ba3d444a0c58914a2859368f349395dda7a9e86a497427852146b45b", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "fef7d2f7-47b0-4201-b0cd-bc66f8b983d4": {"doc_hash": "8d050b970df53d88be0217c7329d0af5cd8503c1ebb55983d4e510006a1b5d9c", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "f21d4276-a6c9-48b9-8169-ea1da2252944": {"doc_hash": "a7f0eea47288af766c26ad763c60322343abf2bce8f2a44c30a1a825a408d3ef", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "10beae5b-b1a9-488e-a38e-d20cf0f57c3a": {"doc_hash": "dc292c8e0106015b2b97f5490e260aafa017b557e40532e3416b70f7321d72d7", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "0f0324ce-b500-483f-8127-4ab86cd0b517": {"doc_hash": "0ceee1c8852c7c1ce4b337c3ba22664d5d85036ac3b1e8ed9d21848dc1215b4e", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "b0412f56-acb4-40b4-bb73-3eac0d4655fd": {"doc_hash": "34ca9058b91c3c440cdddf3caef0a413e40429077a60dddb19c134721c6757bc", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "0d008531-2a6c-4491-96b9-f8230675d5b3": {"doc_hash": "2e1fa76b59f3ea30d48c3ac0ef4b3772ffffa10c1e8afd1802f08dacbf9a6f04", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "d33b4179-66f9-4811-91c5-b2a7efd792ab": {"doc_hash": "f92cb8f3849db9ae098c72e9aaab161879da628033cce6318de9d36c95dd3535", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "9d1a25ea-00c8-4605-9954-1c1323e22e4b": {"doc_hash": "f3a4d9992e5e76352566e0be625d7e786e5f9858b655adbadcb40f17443b4ffc", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "c0a2b1ba-261c-4c16-b2ec-c27f47dd37d8": {"doc_hash": "7208968769f07154716299643195c116805312be26f21b7908c7b4da92622486", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "fc34b30e-072c-4512-8b77-e266c67ffeb4": {"doc_hash": "b76a4ce5c48222fbd350fa0fdbd8d152a4dd077ddd9cea6854081ceb07201cb1", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "1f3039bb-27da-4e34-b4e7-3b14bd2483e1": {"doc_hash": "fa83af922478610f7a3f047c2ba3f875dff7da935f7098e26592b12bb1bc91fc", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "4a409ce0-60b0-46a7-aac9-e0069a1d1a45": {"doc_hash": "4876779517db8ffb93ce76002a5cca93decbca7b7108858fc9315efcf60db82e", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "7ba4d891-959f-449e-8179-f1521d58278b": {"doc_hash": "4c296686d883703cf07d6ed42164179b88a558925876413fd13237469a3d9e0d", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "464a52ee-13cc-4b31-a684-7d9d56b077f4": {"doc_hash": "2ce1226a137e377d6b3d60eb0aa292f8f68530ce8bc1047459dd93eccb9fb6bb", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "f268ff23-4ef0-40d4-8930-334329d426ff": {"doc_hash": "9fc3cf5bc52772ff7ca38c287a4cf4efc526ddbd63e03e2d58b7b0ab2913cecb", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "5cf8fd08-0342-48d7-be27-4435c1996190": {"doc_hash": "68ac68210d2c52ab37af93d8dc19aba9cee40431127a12f1747d4be933f1bb9d", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "50efc748-fd69-4dc4-b5e9-67712fc6c1a1": {"doc_hash": "c3e5749741fdad34ca3532b840e358bcef184d65c97a5f6bf418f6c30c946906", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "3065ba83-65ce-469a-9bc9-569c22f7502b": {"doc_hash": "562e05ee180a042ae3d505a7b2233dae040b700e6955658776bc2bb79094e781", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "3cb07a26-fdd1-4774-b0f8-29aa21e8fb76": {"doc_hash": "fb2522fda9bfaf4f92dd8b4d34f75d9bc68f026bcd2b5b14c7aa2bcc2b5dbb11", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "2d95dc7b-2b64-4bb0-b581-6f0bb18ae0bd": {"doc_hash": "e193b64ec32adf2bea1c3ed747c20128c42fb71df5b55e2a1d80d3f71f484239", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "3e23d28c-240e-4d79-8cd6-4781172dfa54": {"doc_hash": "3a87d4002838e358cec2a202470f1809ff843126190f20912d7f0d17eb9b1f25", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "7c440d64-bcd6-4811-9a1f-f70a29f65c0d": {"doc_hash": "695c10eaf6b8ecee3547507eeb51be1ba39b1709f2ee7b7aa85b45c4c357f640", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "35d04f89-ee46-445b-8cc5-daf903360930": {"doc_hash": "70b5e3b1a11774627c42ff8ae8bf4b97dafe91db5ac8fca6a173e0c8d4cd3321", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "1cff163b-f8d9-49bf-8ec0-0c03e7994dd1": {"doc_hash": "115298f3d4e01a0fefcf7efe928d2a606c42351f239f58747fd2ec69c8066e3b", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "15199290-499d-482f-be5d-8846ec3f1177": {"doc_hash": "3cf578e50be6320ba77ead862663375efcf9a3ff4f859a15c187c83aafcc62db", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "84a1c9a3-0caa-42e1-961d-1d0e470a190c": {"doc_hash": "cdb3c98e9b028e40ae47975c0e0eb872f6fc2c49d00c896142d9b67e703a315e", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "7d225255-9701-49d2-ba99-d2880e6fe9af": {"doc_hash": "dcf4c78597690fefed349dd7856bf3168f17c05b30c2af7767b3a5457b4263ed", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "bcca71aa-7fe8-4348-bb1e-dfcb91db8b11": {"doc_hash": "0ed372ea79a37c26a6a423513d8cc35438fcb541238666731c303021f9653c6d", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "73a668b8-64b4-41bc-b4a8-add81af6742e": {"doc_hash": "014d94f43a5bac92a0c6291f2fe5101a7154a11595217b2671a69fc7ae7c0dea", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "997170d1-de96-48cf-872a-a344552bf671": {"doc_hash": "470cd2488de42eceb3dd897d5f45b36dac1c1f1da610f441a726a013ee6040ed", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "e1ad7bd8-097a-4a7a-b6e4-e2376ae31287": {"doc_hash": "431dbfab9eb6f5aaba57a41fd237fc01bd9f7ae7588d24fe15ea02094dfc28fa", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "a3a3f326-5eda-4989-a0db-fa043196b4b1": {"doc_hash": "d9967c12e563e2416a9962158e73451ef6013b8c7ead6614366fd2665138798d", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "0c9ac0ae-2d00-411b-a304-afe28d16351c": {"doc_hash": "954e56a0815d29ccdff0717b7023779ec37c759038e953dd7b6bbdd1d3b9a319", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "0be360c5-d140-4c86-9e9e-a91262c29e37": {"doc_hash": "7b4b71b1c8d5e2cb24e0b694cae1b4b7166313a12fe6a81a8c42d9c0cc777746", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "c6276074-770d-4609-983f-48d70e22f1a2": {"doc_hash": "9028f5416df8df0078ef77844fdca8d8b8e11ebd89bb49ec252bfe60cce2eabb", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "8496b7a0-8a46-41d8-9b48-77e0ff368d7d": {"doc_hash": "2d51d26604f39e90a05097c4f0c47ad107a4d59e9ee650277dcf71c59275c067", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "bd6ba406-0e33-4804-ac5b-d803b83b7056": {"doc_hash": "f7c70db9b2f0b831f223f30750ed2b672cc18dfc1f9f6130f6bdef3b9594a13e", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "5aa8a48e-ae16-45bd-a590-70eac1aff32a": {"doc_hash": "acfb3999afa2549aec543739aa9ac348473777819a6ea6fd9ba1891c7f12db07", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "a0058833-5ffc-4def-a6a3-10f5b4b8e3d9": {"doc_hash": "4a4d3853c4712dcf702571ab9a4bca5b686d735932c3375262b0c55132e08e1e", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "b1646404-4baa-4590-8141-d7b263da37c3": {"doc_hash": "d5e5f6c880a1fcf536178a06a10263d297d7a18704d301771e2113ecfb502084", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "d87ab588-a219-4943-b295-6d08dd265695": {"doc_hash": "19f7f04824cb6d6f68253269c5bab701d467a743cc88dc92126a3db4f05bfe62", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "d63182ae-cbbc-48bc-bee4-84141e90a007": {"doc_hash": "f152eee4a53ecdca4ef5134ec695a1ba10d45d7339a434c52c30ccdd55fc93dd", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "b69109bd-c8b2-4edd-b897-8e87f4471990": {"doc_hash": "b8dd67d84645e00478ab4d6e728d6f5b94cd86e01f0edebd011d0dc4a3a4240f", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "887cb2e6-de01-4bb8-bc57-4d41ac5b0ba0": {"doc_hash": "6c314e3e049e6f093d3b13f72d07c397f037e037d15ca9abf6119eebc033364b", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "3e470344-905e-404c-be6f-00abe4d2b2b6": {"doc_hash": "84d68506e8b949eb377bc80d0b9d43233365ba3f488b57292d269119efd3098e", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "e465497f-d5ce-4507-97c9-54f6f97de1aa": {"doc_hash": "70b733d0b86b4ca6f8c17cf0a342fa5a459e26c5b0625b7e5c1e6b77d32a1c2a", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "55ce4f5c-a49c-4a26-a4bc-8c8b6b707819": {"doc_hash": "64de707c031178f2ba346b314235e570c01d887002c83203ea0e0242702b28fd", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "f1478900-5b0a-4bd4-9d85-abc424f26e07": {"doc_hash": "45d14afcc2361e1156ab57b8e55a73aa34cdac10af228e4e25403f4bb03c0133", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "b42e1405-b66a-479b-a50d-5bea7c67af17": {"doc_hash": "8dbbe87db27ee1d29611ce04cad6cc302ffc46f708ae29567718fd7e3c801472", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "a1ea30e4-5351-450b-b44e-73c76ffd7ebe": {"doc_hash": "bc18898801ae76045bc342b5b7473fde8ec37bfdfd1cdce42c13154c203f0538", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "4187a558-80a6-4b38-816b-4cac854fa588": {"doc_hash": "fc780f9a42cc7ccc39a65e288e51e25eb181afe389d8e725b449ce5f0cfec001", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "7023420d-97a2-4e64-a5bf-9f8439a64480": {"doc_hash": "d1d6c885b6e29dc43365616d2e59b5b14501f1b55711665e6dc7f751231e59a8", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "17a841ee-8d41-49e6-83d7-7805e0dd04f0": {"doc_hash": "1bb42d9b96fff4e6b765d873be5d0887a5cb92be6f13227ca3f70d1aba4b983f", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "0d7eef55-7570-4adf-93e0-3d06c2e67332": {"doc_hash": "e41569588369ca5c5d732eedc48f024b6580f331c2813911bd30248112a2aa70", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "2f943d51-eb6d-4848-8089-c0a0e28601fa": {"doc_hash": "7a16eafbc71ece1f7138a2f0d7d17ac8b0c73182a3b498502f25f509fdf0e253", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "9acf4a38-5d34-4bca-a295-89c9a9090a4a": {"doc_hash": "bc60e066744338ea384d14479de5f298ebc52a75d20bb1c90aaaf8283440b2a5", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "11773835-8293-4686-9553-d6da84a99592": {"doc_hash": "57fa85f703379fe6a2afcba4715e4c115cf383d3d93f315e26bbd58ce78718c6", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "30797ee6-2932-4473-80c3-2e8d1208e985": {"doc_hash": "b96e8ad274f55e96ea7cf2c06b6ee1130d43f2cfdd088f2f3fefd9383f189e6d", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "0b57821d-7219-42b0-83c2-ff0325a4c990": {"doc_hash": "9dc7ccdf7fc2ca07252549b08334a56f1fb1635de05d90f78ef4c1e3813a7cf4", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "4ca57500-07b5-4caf-9a39-3f64fa046102": {"doc_hash": "97779e0670c47028e7ae63177feeeb8351c707636c98f39a9579e3c9b6742aab", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "c73260f9-0170-4dce-acbb-736406103253": {"doc_hash": "60c096c2e8a778ca934b69e60f88784b833cd1a9e1c4f589440eb4f87c70b5cc", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "b666278d-7080-4b1b-9cd7-012832fb4da6": {"doc_hash": "49d9f1a26b52ea2c884a91f5057d1cacae0a289dea60f3bc6f1c8bd5067526da", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "d400e284-1968-4a56-b582-1a7ea915454b": {"doc_hash": "78e3ff07d9fb61e0257066b69047cc6306cda998f9302402d76c86966b235e6c", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "99e6e0f4-ae35-4739-b72a-d33e07a14980": {"doc_hash": "872b01a30a4cab9f42e950ac49f0bf9500eb827d308f62a36b1d889706dcc281", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "5531d320-981a-45f3-8f77-66230ff82fa8": {"doc_hash": "bd6de047ea2373a4bc548daf53faf5b5765669b60bf24ca721335d02aa560fc8", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "3e836fb6-91d6-42df-b944-3da794785511": {"doc_hash": "0c96dfee9fd7b0879a76b6fea0ba1a283a4736349854d329b0c0f5421739a7f2", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "8dad0787-2ae6-4bef-9005-66adcdc84994": {"doc_hash": "4793ad76330006c08f5b6ac8f4c806903980b47f064f4d18032ce140060fd257", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "8e804274-1d30-47bb-b4a5-8b0a89e03a62": {"doc_hash": "06f2e614c62e3b05f0ede470493c551d01e1d279d078dc0b44baafa9f448cf5f", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "a771935f-a85c-494c-97d3-a661f287022e": {"doc_hash": "2ddf3151faf9f9d19c8e183c56bad576bf39bfad0302558bd6ffdc2c960778bf", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "6156d81a-4ba3-4105-8b9f-518ef11f9afa": {"doc_hash": "9961abe15aa59be598a479ae35c0dcead208a986034c9bb439e21c1dff3ee175", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "297b007f-5406-4c7f-8487-a28c962f0327": {"doc_hash": "9d026e2813c6307e7120b44f8db53735f6deb538a5e5026c6e0a4b15ab1aacd5", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "8a744631-c44b-46a3-aac3-3eccf8b259f6": {"doc_hash": "e97877e8e5b390b529a8ab06385532b9de1dc5d0128bf30ce80b52a25e30c257", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "0195271e-8992-41c3-a61b-4c63fbd03001": {"doc_hash": "f8f244fe8811316782bac254dfae84fee951481a6f5337e4f1e0c717285fbb37", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "ea125a9d-c4e2-45af-a637-1a75ee96d2ca": {"doc_hash": "c552b457987d45b12d5e42d80e7d0be20086b565c44400932481c5a423216a3a", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "33696f3a-b4ce-48c1-ae8e-080dfce4e3cf": {"doc_hash": "08283398a9be9dcdb013d07b0fd067f38b0d493d0672a1e7d00b764c1277958b", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "3e635e3b-99e8-4feb-b52b-b18aba01f8b3": {"doc_hash": "45c97fba212dac8cc7e5d90a61a219feb0fee0dcdb1e107e42fedcc86e6fdd65", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "9154054b-d97a-4a29-8150-47cc4cf374ab": {"doc_hash": "2a9a1a9129e95cf47e7cbf3f79ece724cfcdf960bffaae6912f5bb0182021089", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "dd2a5a00-5308-443c-867b-b9546f0db6e4": {"doc_hash": "aa4d5d06745a0b654658ae5a6a8f8dda42078584b0b91f24077c8c4f8252e3f3", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "7f8e0652-c27c-4561-8ab8-b898f10adaf4": {"doc_hash": "54a2bf7e74e710c06198d975cbb9fa13f953ef8e613b1f1cd239368d71efaf97", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "1c2e12c4-c6be-422f-b12c-46b753d6a1b0": {"doc_hash": "edbefc1349062fe3dcd15be9591c3af85965fab94deccd6e6d07bd9a556c22f9", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "5b0449d7-0e10-45af-87da-d7fe1a5218cf": {"doc_hash": "28026f500cd484ac6d52cd06526de0e4e51f5b2233162ba28f597863c373b757", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "4b4da0ab-e078-4eaa-bcf5-fe5eeb4fbf83": {"doc_hash": "15c5135700844b80080ee26a96b499b3177b2d060e7ee734ca9af76301255f8b", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "480ca554-3a44-4f15-8e9a-ce28ddce9817": {"doc_hash": "878ceae5e14f1cc76825885b9b6e75316b2e699aadebd3fd4246070d2a9ec466", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}, "1cf8f0db-ab6f-47cd-9406-0dd2f3071d2d": {"doc_hash": "66ed3bb8fcecd2c1cf5684668dee875122ec210309e43bad86719ab50de8b5d6", "ref_doc_id": "b75d0f2c-5cb0-44a5-838f-13f96df62c58"}}}