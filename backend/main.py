from fastapi import FastAPI, HTTPException, Query
from contextlib import asynccontextmanager
from typing import List, Dict
from app.models import (
    GenerationRequest, 
    GenerationResponse, 
    ArxivSearchRequest, 
    ArxivSearchResponse
)
from app.agents import generate_content
from app.arXiv import ArxivExtractor
from app.vector_store import ArxivVectorStore
from dotenv import load_dotenv
import os
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    print("üöÄ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    print("üìö –î–æ—Å—Ç—É–ø–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã:")
    print("   - POST /generate - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
    print("   - POST /arxiv/search - –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π (POST)")
    print("   - GET /arxiv/search - –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π (GET)")
    print("üìñ Swagger –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8001/docs")
    print("‚úÖ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ –∫ —Ä–∞–±–æ—Ç–µ!")
    
    yield
    
    # Shutdown
    print("üõë –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è...")

app = FastAPI(title="AI Content Generator", lifespan=lifespan)

@app.post("/generate", response_model=GenerationResponse)
def generate(req: GenerationRequest, provider: str = Query("groq", enum=["groq", "ollama"])):
    try:
        content = generate_content(req.platform, req.topic, provider=provider)
        return GenerationResponse(content=content)
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/arxiv/search", response_model=ArxivSearchResponse)
def search_arxiv_papers(req: ArxivSearchRequest):
    """
    –ü–æ–∏—Å–∫ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –≤ arXiv –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ
    
    Args:
        req: –ó–∞–ø—Ä–æ—Å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ–∏—Å–∫–∞
        
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    """
    print(f"üîç POST –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π: —Ç–µ–º–∞='{req.topic}', –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ={req.max_results}")
    
    try:
        # –°–æ–∑–¥–∞–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä arXiv
        extractor = ArxivExtractor()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        results = extractor.search_and_download(
            topic=req.topic,
            max_results=req.max_results,
            download_pdfs=req.download_pdfs,
            extract_text=req.extract_text,
            output_dir="arxiv_papers"
        )
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {results['total_found']} —Å—Ç–∞—Ç–µ–π –ø–æ —Ç–µ–º–µ '{req.topic}'")
        return ArxivSearchResponse(**results)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å—Ç–∞—Ç–µ–π: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å—Ç–∞—Ç–µ–π: {str(e)}")

@app.get("/arxiv/search")
def search_arxiv_papers_get(
    topic: str = Query(..., description="–¢–µ–º–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç–∞—Ç–µ–π"),
    max_results: int = Query(5, ge=1, le=50, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"),
    download_pdfs: bool = Query(False, description="–°–∫–∞—á–∏–≤–∞—Ç—å –ª–∏ PDF —Ñ–∞–π–ª—ã"),
    extract_text: bool = Query(False, description="–ò–∑–≤–ª–µ–∫–∞—Ç—å –ª–∏ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ PDF"),
    days_back: int = Query(365, ge=1, le=3650, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞"),
    categories: str = Query(None, description="–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ arXiv —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–Ω–∞–ø—Ä–∏–º–µ—Ä: cs.AI,quant-ph)")
):
    """
    GET —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –≤ arXiv
    
    Args:
        topic: –¢–µ–º–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        max_results: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (1-50)
        download_pdfs: –°–∫–∞—á–∏–≤–∞—Ç—å –ª–∏ PDF —Ñ–∞–π–ª—ã
        extract_text: –ò–∑–≤–ª–µ–∫–∞—Ç—å –ª–∏ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ PDF
        days_back: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞
        categories: –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ arXiv —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
        
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    """
    print(f"üîç GET –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π: —Ç–µ–º–∞='{topic}', –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ={max_results}")
    
    try:
        # –ü–∞—Ä—Å–∏–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
        category_list = None
        if categories:
            category_list = [cat.strip() for cat in categories.split(",")]
            print(f"üìÇ –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {category_list}")
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä arXiv
        extractor = ArxivExtractor()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        results = extractor.search_and_download(
            topic=topic,
            max_results=max_results,
            download_pdfs=download_pdfs,
            extract_text=extract_text,
            output_dir="arxiv_papers"
        )
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {results['total_found']} —Å—Ç–∞—Ç–µ–π –ø–æ —Ç–µ–º–µ '{topic}'")
        return results
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å—Ç–∞—Ç–µ–π: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å—Ç–∞—Ç–µ–π: {str(e)}")

@app.get("/")
def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ —Å–µ—Ä–≤–µ—Ä–∞"""
    return {
        "message": "AI Content Generator API —Ä–∞–±–æ—Ç–∞–µ—Ç!",
        "status": "running",
        "version": "1.0.0",
        "endpoints": {
            "generate": "/generate",
            "arxiv_search_post": "/arxiv/search (POST)",
            "arxiv_search_get": "/arxiv/search (GET)",
            "docs": "/docs",
            "redoc": "/redoc"
        }
    }

@app.get("/health")
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞"""
    return {"status": "healthy", "message": "–°–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ"}

# –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
vector_store = ArxivVectorStore(use_local_embeddings=True)

@app.post("/vector/add_articles")
def add_articles_to_vector_store(articles: List[Dict]):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—å–∏ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        articles: –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    print(f"üîç –î–æ–±–∞–≤–ª—è–µ–º {len(articles)} —Å—Ç–∞—Ç–µ–π –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É...")
    
    try:
        # –û—á–∏—â–∞–µ–º –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        cleaned_articles = []
        for article in articles:
            cleaned_article = {}
            for key, value in article.items():
                if isinstance(value, str):
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ –∏ –æ—á–∏—â–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                    if key == 'full_text':
                        cleaned_article[key] = value[:50000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 50KB
                    else:
                        cleaned_article[key] = value[:1000]   # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
                else:
                    cleaned_article[key] = value
            cleaned_articles.append(cleaned_article)
        
        results = vector_store.add_articles(cleaned_articles)
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {results['processed']} —Å—Ç–∞—Ç–µ–π, —Å–æ–∑–¥–∞–Ω–æ {results['chunks_created']} —á–∞–Ω–∫–æ–≤")
        return results
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–µ–π: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–µ–π: {str(e)}")

@app.get("/vector/search")
def search_vector_store(
    query: str = Query(..., description="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"),
    top_k: int = Query(5, ge=1, le=20, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"),
    similarity_threshold: float = Query(0.7, ge=0.0, le=1.0, description="–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏")
):
    """
    –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        similarity_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏
        
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é
    """
    print(f"üîç –ü–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ: '{query}'")
    
    try:
        results = vector_store.search_articles(
            query=query,
            top_k=top_k,
            similarity_threshold=similarity_threshold
        )
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
        return {
            "query": query,
            "total_found": len(results),
            "results": results
        }
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}")

@app.get("/vector/statistics")
def get_vector_store_statistics():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    
    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã
    """
    print("üìä –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã...")
    
    try:
        stats = vector_store.get_statistics()
        print(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–∞: {stats.get('total_documents', 0)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        return stats
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}")

@app.delete("/vector/clear")
def clear_vector_store():
    """
    –û—á–∏—â–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—á–∏—Å—Ç–∫–∏
    """
    print("üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    
    try:
        vector_store.clear_index()
        print("‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—á–∏—â–µ–Ω–∞")
        return {"message": "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—á–∏—â–µ–Ω–∞", "status": "success"}
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {str(e)}")

@app.post("/arxiv/search_and_vectorize")
def search_and_vectorize(
    topic: str = Query(..., description="–¢–µ–º–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç–∞—Ç–µ–π"),
    max_results: int = Query(5, ge=1, le=20, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"),
    download_pdfs: bool = Query(True, description="–°–∫–∞—á–∏–≤–∞—Ç—å –ª–∏ PDF —Ñ–∞–π–ª—ã"),
    extract_text: bool = Query(True, description="–ò–∑–≤–ª–µ–∫–∞—Ç—å –ª–∏ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ PDF"),
    add_to_vector_store: bool = Query(True, description="–î–æ–±–∞–≤–ª—è—Ç—å –ª–∏ —Å—Ç–∞—Ç—å–∏ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É")
):
    """
    –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç: –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É
    
    Args:
        topic: –¢–µ–º–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        max_results: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        download_pdfs: –°–∫–∞—á–∏–≤–∞—Ç—å PDF
        extract_text: –ò–∑–≤–ª–µ–∫–∞—Ç—å —Ç–µ–∫—Å—Ç
        add_to_vector_store: –î–æ–±–∞–≤–ª—è—Ç—å –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    print(f"üîç –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è: '{topic}'")
    
    try:
        # –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π
        extractor = ArxivExtractor()
        search_results = extractor.search_and_download(
            topic=topic,
            max_results=max_results,
            download_pdfs=download_pdfs,
            extract_text=extract_text,
            output_dir="arxiv_papers"
        )
        
        vector_results = None
        if add_to_vector_store and search_results['documents']:
            # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É
            cleaned_documents = []
            for doc in search_results['documents']:
                cleaned_doc = {}
                for key, value in doc.items():
                    if isinstance(value, str):
                        if key == 'full_text':
                            cleaned_doc[key] = value[:50000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 50KB
                        else:
                            cleaned_doc[key] = value[:1000]   # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
                    else:
                        cleaned_doc[key] = value
                cleaned_documents.append(cleaned_doc)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É
            vector_results = vector_store.add_articles(cleaned_documents)
        
        return {
            "search_results": search_results,
            "vector_results": vector_results,
            "topic": topic,
            "total_articles_found": search_results['total_found']
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º AI Content Generator API...")
    uvicorn.run("main:app", host="0.0.0.0", port=8001, reload=True)
